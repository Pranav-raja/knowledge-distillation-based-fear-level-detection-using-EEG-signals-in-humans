{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKc82F2l4aE6"
      },
      "source": [
        "## Read the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import the required libraries"
      ],
      "metadata": {
        "id": "UyXrFsyKQu6L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOjmsuZ-5Kw0",
        "outputId": "96bcca69-3006-4f00-e153-a6de258ecaa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (3.4.1)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.5.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.13.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (24.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.13.0\n",
            "Collecting np_utils\n",
            "  Downloading np_utils-0.6.0.tar.gz (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m935.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from np_utils) (1.26.4)\n",
            "Building wheels for collected packages: np_utils\n",
            "  Building wheel for np_utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for np_utils: filename=np_utils-0.6.0-py3-none-any.whl size=56437 sha256=9e1bb0e694a4e390d75e82b584a5318552d2e0b934f3f75a95d0cecfaf7ff595\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/c7/50/2307607f44366dd021209f660045f8d51cb976514d30be7cc7\n",
            "Successfully built np_utils\n",
            "Installing collected packages: np_utils\n",
            "Successfully installed np_utils-0.6.0\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import numpy\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, LSTM, Bidirectional, Dense, Dropout, Concatenate\n",
        "!pip install scikeras\n",
        "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "# from sklearn.preprocessing import StandardScalerac\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.models import load_model\n",
        "import joblib\n",
        "from keras import backend as K\n",
        "!pip install np_utils\n",
        "import np_utils\n",
        "from sklearn.model_selection import KFold\n",
        "import math\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import csv\n",
        "import os\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import f1_score\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import recall_score, precision_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to your google drive where DEAP dataset is extracted and stored"
      ],
      "metadata": {
        "id": "NTyOJcfJQnzL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv2JKd7L4Y4a",
        "outputId": "2f4f38fe-72d9-4fc1-b1b0-9c3a702f38ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8SICNfoC44Q"
      },
      "outputs": [],
      "source": [
        "# you can change the following directory\n",
        "directory = '/content/drive/MyDrive/Fear_level_classification/data_preprocessed_python'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocessing the data\n",
        "<ol>\n",
        "<li>Extracting only the required videos theat falls into the category of fear</li>"
      ],
      "metadata": {
        "id": "kEBsmlOFQ20P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmVHWgjA4fK_"
      },
      "outputs": [],
      "source": [
        "def mean(numbers, i, j):\n",
        "    sum=0\n",
        "    for k in range(i, j):\n",
        "        sum=sum+numbers[k]\n",
        "    return float(sum / (j-i))\n",
        "\n",
        "relaxation=[]\n",
        "low_fear=[]\n",
        "medium_fear=[]\n",
        "high_fear=[]\n",
        "averaged=[]\n",
        "nr_relaxation=0\n",
        "nr_low_fear=0\n",
        "nr_medium_fear=0\n",
        "nr_high_fear=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLLtdnr341kF",
        "outputId": "6ee9cdcf-a123-4ec5-bcf4-6aeac774df83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "60\n",
            "42\n",
            "35\n"
          ]
        }
      ],
      "source": [
        "for j in range(1, 33):\n",
        "    filename = 's' + str(j) + '.dat'\n",
        "    filepath = os.path.join(directory, filename)\n",
        "    with open(filepath, 'rb') as file:\n",
        "      x = pickle.load(file, encoding='latin1')\n",
        "\n",
        "      for i in range (0, 40):\n",
        "          if x[\"labels\"][i][0]>=7 and  x[\"labels\"][i][0]<=9 and x[\"labels\"][i][1]>=1 and  x[\"labels\"][i][1]<3 and x[\"labels\"][i][2]>=7 and  x[\"labels\"][i][2]<=9:\n",
        "              relaxation.append(x[\"data\"][i])\n",
        "              newrow = []\n",
        "              for k in range (1, 8065):\n",
        "                  newrow.append(0) #label for relaxation\n",
        "              #This line appends the newrow to the data associated with the current relaxation trial.\n",
        "              relaxation[nr_relaxation] = np.append(relaxation[nr_relaxation], [newrow], axis=0)\n",
        "              limit1=0\n",
        "              limit2=672\n",
        "              while limit2<8065:\n",
        "                  newrow=[]\n",
        "                  for k in range (0, 41):\n",
        "                     # Calculating the mean of the EEG data within each time window serves as a way to summarize the EEG activity over a specific duration of time.\n",
        "                      newrow.append(mean(relaxation[nr_relaxation][k], limit1, limit2))\n",
        "                  averaged.append(newrow)\n",
        "                  limit1=limit1+672\n",
        "                  limit2=limit2+672\n",
        "              nr_relaxation=nr_relaxation+1\n",
        "\n",
        "          if x[\"labels\"][i][0]>=5 and  x[\"labels\"][i][0]<7 and x[\"labels\"][i][1]>=3 and  x[\"labels\"][i][1]<5 and x[\"labels\"][i][2]>=5 and  x[\"labels\"][i][2]<7:\n",
        "              #print(x[\"data\"][i])\n",
        "              low_fear.append(x[\"data\"][i])\n",
        "              newrow = []\n",
        "              for k in range (1, 8065):\n",
        "                  newrow.append(1)\n",
        "              low_fear[nr_low_fear] = np.append(low_fear[nr_low_fear], [newrow], axis=0)\n",
        "              limit1=0\n",
        "              limit2=672\n",
        "              while limit2<8065:\n",
        "                  newrow=[]\n",
        "                  for k in range (0, 41):\n",
        "                      newrow.append(mean(low_fear[nr_low_fear][k], limit1, limit2))\n",
        "                  averaged.append(newrow)\n",
        "                  limit1=limit1+672\n",
        "                  limit2=limit2+672\n",
        "              nr_low_fear=nr_low_fear+1\n",
        "\n",
        "          if x[\"labels\"][i][0]>=3 and  x[\"labels\"][i][0]<5 and x[\"labels\"][i][1]>=5 and  x[\"labels\"][i][1]<7 and x[\"labels\"][i][2]>=3 and  x[\"labels\"][i][2]<5:\n",
        "              #print(x[\"data\"][i])\n",
        "              medium_fear.append(x[\"data\"][i])\n",
        "              newrow = []\n",
        "              for k in range (1, 8065):\n",
        "                  newrow.append(2)\n",
        "              medium_fear[nr_medium_fear] = np.append(medium_fear[nr_medium_fear], [newrow], axis=0)\n",
        "              limit1=0\n",
        "              limit2=672\n",
        "              while limit2<8065:\n",
        "                  newrow=[]\n",
        "                  for k in range (0, 41):\n",
        "                      newrow.append(mean(medium_fear[nr_medium_fear][k], limit1, limit2))\n",
        "                  averaged.append(newrow)\n",
        "                  limit1=limit1+672\n",
        "                  limit2=limit2+672\n",
        "              nr_medium_fear=nr_medium_fear+1\n",
        "\n",
        "          if x[\"labels\"][i][0]>=1 and  x[\"labels\"][i][0]<3 and x[\"labels\"][i][1]>=7 and  x[\"labels\"][i][1]<=9 and x[\"labels\"][i][2]>=1 and  x[\"labels\"][i][2]<3:\n",
        "              #print(x[\"data\"][i])\n",
        "              high_fear.append(x[\"data\"][i])\n",
        "              newrow = []\n",
        "              for k in range (1, 8065):\n",
        "                  newrow.append(3)\n",
        "              #print(newrow)\n",
        "              high_fear[nr_high_fear] = np.append(high_fear[nr_high_fear], [newrow], axis=0)\n",
        "              limit1=0\n",
        "              limit2=672\n",
        "              while limit2<8065:\n",
        "                  newrow=[]\n",
        "                  for k in range (0, 41):\n",
        "                      newrow.append(mean(high_fear[nr_high_fear][k], limit1, limit2))\n",
        "                  averaged.append(newrow)\n",
        "                  limit1=limit1+672\n",
        "                  limit2=limit2+672\n",
        "              nr_high_fear=nr_high_fear+1\n",
        "\n",
        "\n",
        "# this prints the selected number of videos for each feal levels\n",
        "# the combined data is stored by downsampling the selected data.\n",
        "print(nr_relaxation)\n",
        "print(nr_low_fear)\n",
        "print(nr_medium_fear)\n",
        "print(nr_high_fear)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7Gkc2yQ6u77"
      },
      "outputs": [],
      "source": [
        "relax = np.array(relaxation)\n",
        "low = np.array(low_fear)\n",
        "medium = np.array(medium_fear)\n",
        "high = np.array(high_fear)\n",
        "averaged = np.array(averaged)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6fNXZKH65vC",
        "outputId": "7bd792ae-c2b5-438d-8273-152203367224"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7, 41, 8064)\n",
            "(60, 41, 8064)\n",
            "(42, 41, 8064)\n",
            "(35, 41, 8064)\n",
            "(1728, 41)\n"
          ]
        }
      ],
      "source": [
        "print(relax.shape)\n",
        "print(low.shape)\n",
        "print(medium.shape)\n",
        "print(high.shape)\n",
        "print(averaged.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BXm3F-OMTx3"
      },
      "outputs": [],
      "source": [
        "x = np.array(averaged[:,:-1])\n",
        "y = np.array(averaged[:,-1])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbWACDnpMh6f",
        "outputId": "87a28e5a-1940-4661-f933-79d64fd0b235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1382, 40)\n",
            "(346, 40)\n",
            "(1382,)\n",
            "(346,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtVV_LYfe8JI"
      },
      "source": [
        "##SNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tu_c2oXpIgLN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SpikingNeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SpikingNeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Parameters for LIF neuron model\n",
        "        self.tau_m = 20.0  # Membrane time constant in ms\n",
        "        self.v_threshold = 1.0  # Spike threshold\n",
        "        self.v_reset = 0.0  # Reset potential after spike\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize membrane potential and spike history\n",
        "        v_mem = torch.zeros(x.size(0), self.hidden_size).to(x.device)\n",
        "        spikes = []\n",
        "\n",
        "        # Iterate over time steps (assuming x is shaped [batch_size, time_steps, input_size])\n",
        "        for t in range(x.size(1)):\n",
        "            # Calculate membrane potential using LIF dynamics\n",
        "            v_mem += (-v_mem + F.relu(self.fc1(x[:, t]))) / self.tau_m\n",
        "\n",
        "            # Check for spikes\n",
        "            spike = (v_mem >= self.v_threshold).float()\n",
        "            v_mem[spike.bool()] = self.v_reset  # Reset potential after spike\n",
        "\n",
        "            spikes.append(spike)\n",
        "\n",
        "        # Convert list of spikes to tensor and average over time steps\n",
        "        spikes_tensor = torch.stack(spikes, dim=1)  # Shape: [batch_size, time_steps, hidden_size]\n",
        "\n",
        "        # Pass through second layer and apply softmax activation for classification\n",
        "        output = F.softmax(self.fc2(spikes_tensor.sum(dim=1)), dim=1)  # Sum spikes over time\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrotFWo9IpSX"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "input_size = 32   # Number of input features (e.g., EEG signals)\n",
        "hidden_size = 64  # Number of neurons in hidden layer\n",
        "output_size = 4   # Number of classes\n",
        "num_epochs = 10   # Number of training epochs\n",
        "\n",
        "# Instantiate the model and define optimizer and loss function.\n",
        "model = SpikingNeuralNetwork(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# Assuming X_train and y_train are numpy arrays\n",
        "batch_size = 32\n",
        "buffer_size = 1000  # Optional, for shuffling\n",
        "\n",
        "# Convert numpy arrays to PyTorch tensors\n",
        "# X_train = torch.from_numpy(X_train).float()\n",
        "# y_train = torch.from_numpy(y_train).long()\n",
        "\n",
        "# Create a dataset from the arrays\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "\n",
        "# Shuffle the dataset and batch it\n",
        "train_loader = train_dataset.shuffle(buffer_size).batch(batch_size)\n",
        "\n",
        "# Optional: You can also prefetch to improve performance\n",
        "train_loader = train_loader.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Example training loop (assuming train_loader is defined)\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)  # Forward pass through SNN\n",
        "\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()             # Backward pass\n",
        "        optimizer.step()            # Update weights\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_DlrTuhe-xo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the model with dropout\n",
        "class SparseNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SparseNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(p=0.5)  # Dropout with probability 0.5\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convert sparse input to dense if needed\n",
        "        x = x.to_dense() if x.is_sparse else x\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Sample input parameters\n",
        "input_size = 40  # Example input size (adjust as per your data)\n",
        "hidden_size = 128       # Number of neurons in hidden layer\n",
        "output_size = 4  # Number of output classes\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = SparseNN(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # L2 regularization\n",
        "\n",
        "# Placeholder for your EEG data and labels\n",
        "# eeg_data_flattened should be of shape (num_samples, input_size)\n",
        "# labels should be of shape (num_samples,) with class labels\n",
        "# # Assume eeg_data_flattened and labels are already available as tensors\n",
        "# eeg_data_flattened = torch.randn(1000, input_size)  # Replace with actual data\n",
        "# labels = torch.randint(0, output_size, (1000,))    # Replace with actual labels\n",
        "eeg_data_flattened = torch.from_numpy(X_train).float()\n",
        "labels = torch.from_numpy(y_train).long()\n",
        "\n",
        "# Training loop parameters\n",
        "num_epochs = 100\n",
        "batch_size = 64\n",
        "\n",
        "# Store the loss values for plotting\n",
        "train_losses = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Mini-batch training\n",
        "    for i in range(0, eeg_data_flattened.shape[0], batch_size):\n",
        "        # Get mini-batch inputs and targets\n",
        "        inputs = eeg_data_flattened[i:i + batch_size]\n",
        "        targets = labels[i:i + batch_size]\n",
        "\n",
        "        # Convert inputs to sparse tensors\n",
        "        inputs_sparse = inputs.to_sparse()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs_sparse)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()  # Clear previous gradients\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update model parameters\n",
        "\n",
        "        # Accumulate the loss for this mini-batch\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    # Compute average loss for this epoch\n",
        "    avg_loss = running_loss / eeg_data_flattened.shape[0]\n",
        "    train_losses.append(avg_loss)\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "\n",
        "# Plot the training loss curve\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9lDphUoRsAu"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "# Assuming test data and test labels are available as tensors\n",
        "# Replace `test_data_flattened` and `test_labels` with actual test data and labels\n",
        "test_data_flattened = torch.from_numpy(X_train).float()\n",
        "test_labels = torch.from_numpy(y_train).long()\n",
        "\n",
        "# Switch model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Placeholder to store model predictions\n",
        "all_preds = []\n",
        "\n",
        "# No gradient calculation needed during inference\n",
        "with torch.no_grad():\n",
        "    for i in range(0, test_data_flattened.shape[0], batch_size):\n",
        "        inputs = test_data_flattened[i:i + batch_size]\n",
        "\n",
        "        # Convert inputs to sparse tensors if necessary\n",
        "        inputs_sparse = inputs.to_sparse()\n",
        "\n",
        "        # Forward pass (prediction)\n",
        "        outputs = model(inputs_sparse)\n",
        "\n",
        "        # Get predicted class (argmax over the output probabilities)\n",
        "        _, predicted_classes = torch.max(outputs, 1)\n",
        "\n",
        "        # Collect predictions\n",
        "        all_preds.append(predicted_classes)\n",
        "\n",
        "# Concatenate all predictions into a single tensor\n",
        "all_preds = torch.cat(all_preds)\n",
        "\n",
        "# Convert tensors to numpy arrays for metric computation\n",
        "y_true = test_labels.numpy()\n",
        "y_pred = all_preds.numpy()\n",
        "\n",
        "# Calculate accuracy, F1-score, confusion matrix, and classification report\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "class_report = classification_report(y_true, y_pred)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZJKv1zJEbiB"
      },
      "source": [
        "## Knowledge distillation\n",
        "\n",
        "<p>what if we train the model only with the 8 physiological signals with true ground labels will it give better result? So we will train the light weight student model with and without Knowledge Distillation</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3_7OJOeraAc"
      },
      "source": [
        "### Simple neural network model\n",
        "Using 40 channels for both the teacher model and the student model\n",
        "\n",
        "<p>Teacher Model accuracy: 51</p>\n",
        "<p>Student Model accuracy: 53</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnM-arkxp6p8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, losses, optimizers, metrics\n",
        "\n",
        "# Define the Teacher model\n",
        "teacher_model = models.Sequential([\n",
        "    layers.Input(shape=(40,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the Teacher model\n",
        "teacher_model.compile(\n",
        "    optimizer=optimizers.Adam(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sADQpnNp9nH"
      },
      "outputs": [],
      "source": [
        "# Train the Teacher model\n",
        "teacher_history = teacher_model.fit(X_train, y_train, epochs=35, validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwjqPU65qBgw"
      },
      "outputs": [],
      "source": [
        "# Freeze the Teacher model\n",
        "teacher_model.trainable = False\n",
        "\n",
        "# Define the Student model\n",
        "student_model = models.Sequential([\n",
        "    layers.Input(shape=(40,)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "# Knowledge distillation loss\n",
        "def distillation_loss(y_true, y_pred, teacher_pred, alpha=0.1, temperature=3):\n",
        "    student_loss = losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
        "    distillation_loss = losses.KLDivergence()(\n",
        "        tf.nn.softmax(teacher_pred / temperature),\n",
        "        tf.nn.softmax(y_pred / temperature)\n",
        "    )\n",
        "    return alpha * student_loss + (1 - alpha) * distillation_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eNQRQolqH53"
      },
      "outputs": [],
      "source": [
        "# Define a custom training step for the Student model\n",
        "class DistillationModel(tf.keras.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super(DistillationModel, self).__init__()\n",
        "        self.student = student\n",
        "        self.teacher = teacher\n",
        "\n",
        "    def compile(self, optimizer, metrics, alpha=0.1, temperature=3):\n",
        "        super(DistillationModel, self).compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "        self.student_loss = losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        teacher_pred = self.teacher(x, training=False)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            student_pred = self.student(x, training=True)\n",
        "            loss = distillation_loss(y, student_pred, teacher_pred, self.alpha, self.temperature)\n",
        "\n",
        "        gradients = tape.gradient(loss, self.student.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.student.trainable_variables))\n",
        "\n",
        "        self.compiled_metrics.update_state(y, student_pred)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        y_pred = self.student(x, training=False)\n",
        "        loss = self.student_loss(y, y_pred)\n",
        "\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "# Compile the Student model with distillation\n",
        "distillation_model = DistillationModel(student_model, teacher_model)\n",
        "distillation_model.compile(\n",
        "    optimizer=optimizers.Adam(),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        "    alpha=0.1,\n",
        "    temperature=3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LHcePkvjqp9Q"
      },
      "outputs": [],
      "source": [
        "print(teacher_model.summary())\n",
        "print(student_model.summary())\n",
        "print(distillation_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtRKiytrpz1v"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train the Student model\n",
        "student_history= distillation_model.fit(X_train, y_train, epochs=35, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the Student model\n",
        "distillation_model.evaluate(X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxIYq11PUhQW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCG_pqz_UogH"
      },
      "outputs": [],
      "source": [
        "# Plotting function for training and validation loss\n",
        "def plot_loss(teacher_history, student_history):\n",
        "    # Extract loss from the training history\n",
        "    teacher_loss = teacher_history.history['loss']\n",
        "    teacher_val_loss = teacher_history.history['val_loss']\n",
        "    student_loss = student_history.history['loss']\n",
        "    student_val_loss = student_history.history['val_loss']\n",
        "\n",
        "    # Define number of epochs\n",
        "    epochs_range = range(len(teacher_loss))\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Plot teacher model loss\n",
        "    plt.plot(epochs_range, teacher_loss, label='Teacher Training Loss', color='blue')\n",
        "    plt.plot(epochs_range, teacher_val_loss, label='Teacher Validation Loss', color='blue', linestyle='dashed')\n",
        "\n",
        "    # Plot student model loss\n",
        "    plt.plot(epochs_range, student_loss, label='Student Training Loss', color='green')\n",
        "    plt.plot(epochs_range, student_val_loss, label='Student Validation Loss', color='green', linestyle='dashed')\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.title('Epochs vs Loss for Teacher and Student Models')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Call the plotting function\n",
        "plot_loss(teacher_history, student_history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLbE0sgLVNcV"
      },
      "outputs": [],
      "source": [
        "# Plotting function for training and validation accuracy\n",
        "def plot_accuracy(teacher_history, student_history):\n",
        "    # Extract accuracy from the training history\n",
        "    teacher_accuracy = teacher_history.history['sparse_categorical_accuracy']\n",
        "    teacher_val_accuracy = teacher_history.history['val_sparse_categorical_accuracy']\n",
        "    student_accuracy = student_history.history['sparse_categorical_accuracy']\n",
        "    student_val_accuracy = student_history.history['val_sparse_categorical_accuracy']\n",
        "\n",
        "    # Define number of epochs\n",
        "    epochs_range = range(len(teacher_accuracy))\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Plot teacher model accuracy\n",
        "    plt.plot(epochs_range, teacher_accuracy, label='Teacher Training Accuracy', color='blue')\n",
        "    plt.plot(epochs_range, teacher_val_accuracy, label='Teacher Validation Accuracy', color='blue', linestyle='dashed')\n",
        "\n",
        "    # Plot student model accuracy\n",
        "    plt.plot(epochs_range, student_accuracy, label='Student Training Accuracy', color='green')\n",
        "    plt.plot(epochs_range, student_val_accuracy, label='Student Validation Accuracy', color='green', linestyle='dashed')\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.title('Epochs vs Accuracy for Teacher and Student Models')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Call the plotting function\n",
        "plot_accuracy(teacher_history, student_history)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(teacher_model.summary())\n",
        "print(student_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "zSlcYLtdAtwQ",
        "outputId": "a6cf296a-ebdc-4da4-ee34-700b90572f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,624\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m260\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,624</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,044\u001b[0m (27.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,044</span> (27.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,044\u001b[0m (27.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,044</span> (27.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m1,312\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m1,056\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m132\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,500\u001b[0m (9.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,500</span> (9.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,500\u001b[0m (9.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,500</span> (9.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ojp4KR9wsYb3"
      },
      "source": [
        "### Student with 8 physiological signals\n",
        "Using simple neural netword model, where the teacher is trained with 40 input channels and the student model is trained with 8 physiological signals and knowledge is transfered from the teacher model\n",
        "\n",
        "\n",
        "<p>Teacher Model accuracy: 56</p>\n",
        "<p>Student Model Accuracy: 49.71, F1 Score: 47.87</p>\n",
        "<p>Without KD student model performance:</p>\n",
        "<p>Accuracy: 0.4538</p>\n",
        "<p>F1 Score: 0.4588</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_cEibkpVsfYk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def create_teacher_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=(40,)),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(4, activation='softmax')   # Output layer for four classes\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "teacher_model = create_teacher_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnF9QfJRs37q"
      },
      "outputs": [],
      "source": [
        "teacher_history = teacher_model.fit(X_train, y_train, epochs=50, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2NY9xQHc0HB"
      },
      "outputs": [],
      "source": [
        "teacher_accuracy = teacher_model.evaluate(X_test, y_test)\n",
        "print(f'Student Model Accuracy: {teacher_accuracy[1] * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Z_Qu4aNviuP"
      },
      "outputs": [],
      "source": [
        "def create_student_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=(8,)),   # Only taking last 8 features for student model\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(4, activation='softmax')   # Output layer for four classes\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "student_model = create_student_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tgoY7L9YyLOT"
      },
      "outputs": [],
      "source": [
        "# Training the light weight student model with soft targets from teacher model\n",
        "\n",
        "\n",
        "# Get soft predictions from teacher (using temperature scaling)\n",
        "def get_soft_labels(model, X):\n",
        "    logits = model.predict(X)\n",
        "    temperature = 3.0   # Temperature parameter for softening probabilities\n",
        "    soft_labels = tf.nn.softmax(logits / temperature).numpy()\n",
        "    return soft_labels\n",
        "\n",
        "# Generate soft labels from teacher's predictions on training data (using first half of features)\n",
        "soft_labels_train = get_soft_labels(teacher_model, X_train)\n",
        "\n",
        "# Generate soft labels from teacher's predictions on test data (using last half of features)\n",
        "soft_labels_test = get_soft_labels(teacher_model, X_test)\n",
        "\n",
        "# Convert soft_labels_train to one-hot encoding\n",
        "soft_labels_train_one_hot = tf.keras.utils.to_categorical(np.argmax(soft_labels_train, axis=1), num_classes=4)\n",
        "\n",
        "# Update student model to use categorical crossentropy\n",
        "student_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the student model with one-hot encoded soft labels\n",
        "student_model.fit(X_train[:, -8:], soft_labels_train_one_hot, epochs=100, batch_size=32)\n",
        "\n",
        "# Convert soft_labels_train to one-hot encoding\n",
        "soft_labels_test_one_hot = tf.keras.utils.to_categorical(np.argmax(soft_labels_test, axis=1), num_classes=4)\n",
        "\n",
        "student_accuracy = student_model.evaluate(X_test[:, -8:], soft_labels_test_one_hot)\n",
        "print(f'Student Model Evaluation Accuracy: {student_accuracy[1] * 100:.2f}%')\n",
        "\n",
        "# Make predictions\n",
        "y_pred = student_model.predict(X_test[:,-8:])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Get the class with the highest probability\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "class_report = classification_report(y_test, y_pred_classes)\n",
        "\n",
        "# Print metrics\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print('Confusion Matrix:\\n', conf_matrix)\n",
        "print('Classification Report:\\n', class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeK8-TRSdDTD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "1290f8c6-e459-43e1-c952-4f51208da962"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,624\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m132\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,624</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,836\u001b[0m (18.89 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,836</span> (18.89 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,836\u001b[0m (18.89 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,836</span> (18.89 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m288\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m132\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m420\u001b[0m (1.64 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> (1.64 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m420\u001b[0m (1.64 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> (1.64 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(teacher_model.summary())\n",
        "print(student_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lni-KMOial1M"
      },
      "outputs": [],
      "source": [
        "# Training the light weight student model with groung true labels (y_train)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the model\n",
        "def create_student_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=(8,)),  # Only taking last 8 features for student model\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(4, activation='softmax')  # Output layer for four classes\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create and train the model\n",
        "model = create_student_model()\n",
        "student_history = model.fit(X_train[:,-8:], y_train, epochs=50, batch_size=10, validation_split=0.2)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test[:,-8:])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Get the class with the highest probability\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "class_report = classification_report(y_test, y_pred_classes)\n",
        "\n",
        "# Print metrics\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print('Confusion Matrix:\\n', conf_matrix)\n",
        "print('Classification Report:\\n', class_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ml_7JqfYatoc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ux5aLKOXzAq"
      },
      "outputs": [],
      "source": [
        "# Plotting function for training and validation loss\n",
        "def plot_loss(teacher_history, student_history):\n",
        "    # Extract loss from the training history\n",
        "    teacher_loss = teacher_history.history['loss']\n",
        "    #teacher_val_loss = teacher_history.history['val_loss']\n",
        "    student_loss = student_history.history['loss']\n",
        "    #student_val_loss = student_history.history['val_loss']\n",
        "\n",
        "    # Define the range for epochs\n",
        "    teacher_epochs_range = range(len(teacher_loss))\n",
        "    student_epochs_range = range(len(student_loss))\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Plot teacher model loss\n",
        "    plt.plot(teacher_epochs_range, teacher_loss, label='Teacher Training Loss', color='blue')\n",
        "    #plt.plot(teacher_epochs_range, teacher_val_loss, label='Teacher Validation Loss', color='blue', linestyle='dashed')\n",
        "\n",
        "    # Plot student model loss\n",
        "    plt.plot(student_epochs_range, student_loss, label='Student Training Loss', color='green')\n",
        "    #plt.plot(student_epochs_range, student_val_loss, label='Student Validation Loss', color='green', linestyle='dashed')\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.title('Epochs vs Loss for Teacher and Student Models')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Call the plotting function\n",
        "plot_loss(teacher_history, student_history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fOTqSVFYu40"
      },
      "outputs": [],
      "source": [
        "# Plotting function for training and validation accuracy\n",
        "def plot_accuracy(teacher_history, student_history):\n",
        "    # Extract accuracy from the training history\n",
        "    teacher_accuracy = teacher_history.history['accuracy']\n",
        "    #teacher_val_accuracy = teacher_history.history['val_accuracy']\n",
        "    student_accuracy = student_history.history['accuracy']\n",
        "    #student_val_accuracy = student_history.history['val_accuracy']\n",
        "\n",
        "    # Define the range for epochs\n",
        "    teacher_epochs_range = range(len(teacher_accuracy))\n",
        "    student_epochs_range = range(len(student_accuracy))\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Plot teacher model accuracy\n",
        "    plt.plot(teacher_epochs_range, teacher_accuracy, label='Teacher Training Accuracy', color='blue')\n",
        "    #plt.plot(teacher_epochs_range, teacher_val_accuracy, label='Teacher Validation Accuracy', color='blue', linestyle='dashed')\n",
        "\n",
        "    # Plot student model accuracy\n",
        "    plt.plot(student_epochs_range, student_accuracy, label='Student Training Accuracy', color='green')\n",
        "    #plt.plot(student_epochs_range, student_val_accuracy, label='Student Validation Accuracy', color='green', linestyle='dashed')\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.title('Epochs vs Accuracy for Teacher and Student Models')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Call the plotting function\n",
        "plot_accuracy(teacher_history, student_history)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGxIYv0PlQwD"
      },
      "source": [
        "### Using DNN 300 model\n",
        "\n",
        "<p>Teacher Model: Accuracy: 69.36, F1 Score: 68.51</p>\n",
        "<p>Student Model: Accuracy: 61.27, F1 Score: 60.37</p>\n",
        "<p>Model trained with only 8 physiological signals:<br>Accuracy: 63.29\n",
        "F1 Score: 62.68</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5RihUVEmSvG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7Y87fngmyQa"
      },
      "outputs": [],
      "source": [
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTJ7ZENum5z7"
      },
      "outputs": [],
      "source": [
        "def create_teacher_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(300, input_dim=40, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(4, kernel_initializer='normal', activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_student_model_dnn300():\n",
        "    model = Sequential()\n",
        "    # Only using 8 physiological signals as input\n",
        "    model.add(Dense(300, input_dim=8, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    # Output layer remains same since we have 4 classes\n",
        "    model.add(Dense(4, kernel_initializer='normal', activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RM5FodsBnDFy"
      },
      "outputs": [],
      "source": [
        "# Train Teacher Model\n",
        "teacher_model = create_teacher_model()\n",
        "teacher_history= teacher_model.fit(X_train, y_train_cat, epochs=100, batch_size=32)\n",
        "\n",
        "# Generate soft targets from Teacher Model for Student Training\n",
        "soft_targets = teacher_model.predict(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jS2Pl92f5j6",
        "outputId": "80295c2f-ac1c-406e-ccb9-f70eadca0531"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Accuracy: 0.6965\n",
            "F1 Score: 0.6876\n",
            "Confusion Matrix:\n",
            " [[  8   4   1   3]\n",
            " [  1 126   9  15]\n",
            " [  1  38  51  15]\n",
            " [  0  10   8  56]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.50      0.62        16\n",
            "         1.0       0.71      0.83      0.77       151\n",
            "         2.0       0.74      0.49      0.59       105\n",
            "         3.0       0.63      0.76      0.69        74\n",
            "\n",
            "    accuracy                           0.70       346\n",
            "   macro avg       0.72      0.64      0.66       346\n",
            "weighted avg       0.70      0.70      0.69       346\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Make predictions\n",
        "y_pred = teacher_model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Get the class with the highest probability\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "class_report = classification_report(y_test, y_pred_classes)\n",
        "\n",
        "# Print metrics\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print('Confusion Matrix:\\n', conf_matrix)\n",
        "print('Classification Report:\\n', class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EhLgNeeRnOqL"
      },
      "outputs": [],
      "source": [
        "# Train Student Model using soft targets from Teacher Model\n",
        "\n",
        "\n",
        "student_model = create_student_model_dnn300()\n",
        "student_history= student_model.fit(X_train[:, -8:], soft_targets, epochs=100, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PrUm2Wknc4u",
        "outputId": "40b62d18-bfda-4a4b-9266-9438dbf0bed3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8396 - loss: 0.8435 \n",
            "EVALUATION RESULT:\n",
            "Student Model Loss: 0.8838009834289551, Accuracy: 0.8439306616783142\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Accuracy: 0.6763\n",
            "F1 Score: 0.6665\n",
            "Confusion Matrix:\n",
            " [[  9   5   0   2]\n",
            " [  0 127  13  11]\n",
            " [  0  44  48  13]\n",
            " [  0  16   8  50]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.56      0.72        16\n",
            "         1.0       0.66      0.84      0.74       151\n",
            "         2.0       0.70      0.46      0.55       105\n",
            "         3.0       0.66      0.68      0.67        74\n",
            "\n",
            "    accuracy                           0.68       346\n",
            "   macro avg       0.75      0.63      0.67       346\n",
            "weighted avg       0.69      0.68      0.67       346\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Student Model on Test Data\n",
        "test_soft_targets = teacher_model.predict(X_test)\n",
        "student_loss_and_metrics = student_model.evaluate(X_test[:, -8:], test_soft_targets)\n",
        "print(f\"EVALUATION RESULT:\\nStudent Model Loss: {student_loss_and_metrics[0]}, Accuracy: {student_loss_and_metrics[1]}\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = student_model.predict(X_test[:,-8:])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Get the class with the highest probability\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "class_report = classification_report(y_test, y_pred_classes)\n",
        "\n",
        "# Print metrics\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print('Confusion Matrix:\\n', conf_matrix)\n",
        "print('Classification Report:\\n', class_report)\n",
        "# print(student_loss_and_metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUsP_YHSrei-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "outputId": "8985b41c-b94d-47ac-86b7-7d04e94de342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m12,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │           \u001b[38;5;34m1,204\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,204</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m374,704\u001b[0m (1.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">374,704</span> (1.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m374,704\u001b[0m (1.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">374,704</span> (1.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │           \u001b[38;5;34m2,700\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │           \u001b[38;5;34m1,204\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,700</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,204</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m274,804\u001b[0m (1.05 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">274,804</span> (1.05 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m274,804\u001b[0m (1.05 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">274,804</span> (1.05 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "teacher_model = create_teacher_model()\n",
        "student_model = create_student_model_dnn300()\n",
        "\n",
        "print(teacher_model.summary())\n",
        "print(student_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GxGdjUlIr16f"
      },
      "outputs": [],
      "source": [
        "# Training the light weight student model with groung true labels (y_train)\n",
        "\n",
        "\n",
        "temp_model = create_student_model_dnn300()\n",
        "temp_history= temp_model.fit(X_train[:, -8:], y_train_cat, epochs=100, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkDNgVh-sSZZ"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred = temp_model.predict(X_test[:,-8:])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Get the class with the highest probability\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "class_report = classification_report(y_test, y_pred_classes)\n",
        "\n",
        "# Print metrics\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print('Confusion Matrix:\\n', conf_matrix)\n",
        "print('Classification Report:\\n', class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sh1LCpJ6XYS6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGGEXJyIcOK8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to plot the training loss for both Teacher and Student models\n",
        "def plot_loss(teacher_history, student_history, temp_history):\n",
        "    # Extract loss for each model\n",
        "    teacher_loss = teacher_history.history['loss']\n",
        "    student_loss = student_history.history['loss']\n",
        "    temp_loss = temp_history.history['loss']\n",
        "\n",
        "    # Define the range of epochs\n",
        "    teacher_epochs = range(len(teacher_loss))\n",
        "    student_epochs = range(len(student_loss))\n",
        "    temp_epochs = range(len(temp_loss))\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Plot teacher model loss\n",
        "    plt.plot(teacher_epochs, teacher_loss, label='Teacher Model Loss', color='blue')\n",
        "\n",
        "    # Plot student model loss (trained with soft targets)\n",
        "    plt.plot(student_epochs, student_loss, label='Student Model Loss (Soft Targets)', color='green')\n",
        "\n",
        "    # Plot temp student model loss (trained directly with 8 physiological signals)\n",
        "    plt.plot(temp_epochs, temp_loss, label='Student Model Loss (8 Signals)', color='red')\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.title('Epochs vs Loss for Teacher and Student Models')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Call the plotting function\n",
        "plot_loss(teacher_history, student_history, temp_history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zI3SJsqcfOA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to plot the training accuracy for both Teacher and Student models\n",
        "def plot_accuracy(teacher_history, student_history, temp_history):\n",
        "    # Extract accuracy for each model\n",
        "    teacher_accuracy = teacher_history.history['accuracy']\n",
        "    student_accuracy = student_history.history['accuracy']\n",
        "    temp_accuracy = temp_history.history['accuracy']\n",
        "\n",
        "    # Define the range of epochs\n",
        "    teacher_epochs = range(len(teacher_accuracy))\n",
        "    student_epochs = range(len(student_accuracy))\n",
        "    temp_epochs = range(len(temp_accuracy))\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Plot teacher model accuracy\n",
        "    plt.plot(teacher_epochs, teacher_accuracy, label='Teacher Model Accuracy', color='blue')\n",
        "\n",
        "    # Plot student model accuracy (trained with soft targets)\n",
        "    plt.plot(student_epochs, student_accuracy, label='Student Model Accuracy (Soft Targets)', color='green')\n",
        "\n",
        "    # Plot temp student model accuracy (trained directly with 8 physiological signals)\n",
        "    plt.plot(temp_epochs, temp_accuracy, label='Student Model Accuracy (8 Signals)', color='red')\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.title('Epochs vs Accuracy for Teacher and Student Models')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Call the plotting function\n",
        "plot_accuracy(teacher_history, student_history, temp_history)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA4B8MGOrEzW"
      },
      "source": [
        "### DNN 300 with cross validation\n",
        "\n",
        "Teacher Model: Accuracy: 75.43,\n",
        "F1_score: 75.28\n",
        "\n",
        "Student Model: Accuracy: 73.12,\n",
        "F1_score: 72.95\n",
        "\n",
        "without KD: Accuracy: 75.43,\n",
        "F1 Score: 75.24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLtR-tIArIpU"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import numpy as np1\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "n_splits = 5  # Number of folds\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uE9coOwpru-V"
      },
      "outputs": [],
      "source": [
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-MaR5byrxCB"
      },
      "outputs": [],
      "source": [
        "def create_teacher_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(300, input_dim=40, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(4, kernel_initializer='normal', activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_student_model_dnn300():\n",
        "    model = Sequential()\n",
        "    # Only using 8 physiological signals as input\n",
        "    model.add(Dense(300, input_dim=8, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    # Output layer remains same since we have 4 classes\n",
        "    model.add(Dense(4, kernel_initializer='normal', activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inZ7JrT_rdeQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73544dbc-8fa9-4fd6-8d1a-9a1ae295653e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Fold 1 Teacher Model\n",
            "Accuracy: 0.7003610108303249\n",
            "F1 Score: 0.6976419464563985\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Fold 2 Teacher Model\n",
            "Accuracy: 0.7256317689530686\n",
            "F1 Score: 0.7206563842560073\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Fold 3 Teacher Model\n",
            "Accuracy: 0.7282608695652174\n",
            "F1 Score: 0.7287987696034681\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Fold 4 Teacher Model\n",
            "Accuracy: 0.782608695652174\n",
            "F1 Score: 0.7781564809467689\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Fold 5 Teacher Model\n",
            "Accuracy: 0.782608695652174\n",
            "F1 Score: 0.781337263266611\n",
            "Teacher Model Cross-Validation Accuracy: 0.74 ± 0.03\n",
            "Teacher Model Cross-Validation F1 Score: 0.74 ± 0.03\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Teacher Model Cross-Validation with Confusion Matrix and Classification Report\n",
        "teacher_accuracies = []\n",
        "teacher_f1_scores = []\n",
        "\n",
        "teacher_model = create_teacher_model()\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(X_train, y_train), 1):\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train_cat[train_index], y_train_cat[val_index]\n",
        "\n",
        "    # Create and train the teacher model\n",
        "    teacher_history= teacher_model.fit(X_train_fold, y_train_fold, epochs=100, batch_size=32, verbose=0)\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    val_preds = teacher_model.predict(X_val_fold)\n",
        "    val_preds_classes = np.argmax(val_preds, axis=1)\n",
        "    y_val_classes = np.argmax(y_val_fold, axis=1)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_val_classes, val_preds_classes)\n",
        "    f1 = f1_score(y_val_classes, val_preds_classes, average='weighted')\n",
        "    print(f\"Fold {fold} Teacher Model\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"F1 Score: {f1}\")\n",
        "\n",
        "    teacher_accuracies.append(accuracy)\n",
        "    teacher_f1_scores.append(f1)\n",
        "\n",
        "    # Print confusion matrix and classification report for the current fold\n",
        "    # print(f\"Fold {fold} Teacher Model\")\n",
        "    # print(\"Confusion Matrix:\")\n",
        "    # print(confusion_matrix(y_val_classes, val_preds_classes))\n",
        "    # print(\"Classification Report:\")\n",
        "    # print(classification_report(y_val_classes, val_preds_classes))\n",
        "\n",
        "print(f\"Teacher Model Cross-Validation Accuracy: {np.mean(teacher_accuracies):.2f} ± {np.std(teacher_accuracies):.2f}\")\n",
        "print(f\"Teacher Model Cross-Validation F1 Score: {np.mean(teacher_f1_scores):.2f} ± {np.std(teacher_f1_scores):.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEKCnBxiOvyZ"
      },
      "outputs": [],
      "source": [
        "val_preds = teacher_model.predict(X_test)\n",
        "val_preds_classes = np.argmax(val_preds, axis=1)\n",
        "y_val_classes = np.argmax(y_test_cat, axis=1)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_val_classes, val_preds_classes)\n",
        "f1 = f1_score(y_val_classes, val_preds_classes, average='weighted')\n",
        "\n",
        "# Print confusion matrix and classification report for the current fold\n",
        "print(f\"TEST RESULT:\\nAccuracy: {accuracy}\\nf1_score: {f1}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val_classes, val_preds_classes))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val_classes, val_preds_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJApQZfyYezR"
      },
      "outputs": [],
      "source": [
        "eeg_signals_train = X_train[:, :32]\n",
        "phys_signals_train = X_train[:, 32:]\n",
        "eeg_signals_test = X_test[:, :32]\n",
        "phys_signals_test = X_test[:, 32:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mToilIoEXMQq"
      },
      "outputs": [],
      "source": [
        "#For DNN 300\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import losses, optimizers\n",
        "\n",
        "def distill_teacher_to_student(teacher_model, student_model,X_train_fold, X_train_phys, y_train, temperature=3, alpha=0.5, epochs=10, batch_size=32):\n",
        "    # Convert labels to categorical (soft labels not needed for distillation)\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=4)\n",
        "    print(\"started\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        for i in range(0, len(X_train_phys), batch_size):\n",
        "            # Get batch data\n",
        "            X_batch = X_train_phys[i:i+batch_size]\n",
        "            y_batch = y_train[i:i+batch_size]\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Get teacher model predictions (soft labels)\n",
        "                teacher_logits = teacher_model([X_train_fold[i:i+batch_size]], training=False)\n",
        "                teacher_probs = tf.nn.softmax(teacher_logits / temperature)\n",
        "                # print(\"passed 1\")\n",
        "\n",
        "                # Get student model predictions\n",
        "                student_logits = student_model(X_batch, training=True)\n",
        "                student_probs = tf.nn.softmax(student_logits / temperature)\n",
        "                # print( \"passed 2\")\n",
        "\n",
        "                # Distillation loss (between soft targets from teacher and student)\n",
        "                distillation_loss = tf.reduce_mean(\n",
        "                    losses.categorical_crossentropy(teacher_probs, student_probs)\n",
        "                )\n",
        "                # print(\"passed 3.1\")\n",
        "\n",
        "                # print(y_batch.shape)\n",
        "                # print(y_batch)\n",
        "                # print(student_logits)\n",
        "                # # student_logits = to_categorical(student_logits)\n",
        "                # print(student_logits.shape)\n",
        "\n",
        "                # Hard target loss (between true labels and student outputs)\n",
        "                hard_loss = tf.reduce_mean(\n",
        "                    losses.categorical_crossentropy(y_batch, student_logits)\n",
        "                )\n",
        "                # print(\"passed 3.2\")\n",
        "\n",
        "                # Combined loss\n",
        "                loss = alpha * distillation_loss + (1 - alpha) * hard_loss\n",
        "                # print(\"passed 3.3\")\n",
        "\n",
        "            # Compute gradients\n",
        "            grads = tape.gradient(loss, student_model.trainable_weights)\n",
        "            optimizers.Adam().apply_gradients(zip(grads, student_model.trainable_weights))\n",
        "            # print(\"passed 4\")\n",
        "\n",
        "        print(f\"Loss: {loss.numpy()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePNwo5LFZb6r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d5007d6-fe86-44e0-9d30-26fbcd5c41f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "student_model = create_student_model_dnn300()\n",
        "student_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qODEsEqcrog1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c89478-7542-4456-e873-295bab00d583"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Fold 1 Student Model\n",
            "Accuracy: 0.7003610108303249\n",
            "F1 Score: 0.6988412835800883\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Fold 2 Student Model\n",
            "Accuracy: 0.7148014440433214\n",
            "F1 Score: 0.7130134034639867\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Fold 3 Student Model\n",
            "Accuracy: 0.7644927536231884\n",
            "F1 Score: 0.7654689386606234\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Fold 4 Student Model\n",
            "Accuracy: 0.7789855072463768\n",
            "F1 Score: 0.7764728106221955\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Fold 5 Student Model\n",
            "Accuracy: 0.7971014492753623\n",
            "F1 Score: 0.7957090952998881\n",
            "Student Model Cross-Validation Accuracy: 0.75 ± 0.04\n",
            "Student Model Cross-Validation F1 Score: 0.75 ± 0.04\n"
          ]
        }
      ],
      "source": [
        "# Training the light weight student model with groung true labels (y_train) and with KD\n",
        "# Caution!: both code are in this file, comment the respective thing to run the code, currently commented the KD section\n",
        "\n",
        "# Student Model Cross-Validation with Confusion Matrix and Classification Report\n",
        "student_accuracies = []\n",
        "student_f1_scores = []\n",
        "\n",
        "student_model = create_student_model_dnn300()\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(X_train, y_train), 1):\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train_cat[train_index], y_train_cat[val_index]\n",
        "\n",
        "    # # Train teacher model to generate soft targets with KD\n",
        "    # teacher_model = create_teacher_model()\n",
        "    # teacher_model.fit(X_train_fold, y_train_fold, epochs=50, batch_size=32, verbose=0)\n",
        "    # soft_targets = teacher_model.predict(X_train_fold)\n",
        "\n",
        "    # # Create and train the student model with KD\n",
        "    # student_history= student_model.fit(X_train_fold[:, -8:], soft_targets, epochs=100, batch_size=32, verbose=0)\n",
        "\n",
        "    # without KD\n",
        "    student_history= student_model.fit(X_train_fold[:, -8:], y_train_fold, epochs=100, batch_size=32, verbose=0)\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    val_preds = student_model.predict(X_val_fold[:, -8:])\n",
        "    val_preds_classes = np.argmax(val_preds, axis=1)\n",
        "    y_val_classes = np.argmax(y_val_fold, axis=1)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_val_classes, val_preds_classes)\n",
        "    f1 = f1_score(y_val_classes, val_preds_classes, average='weighted')\n",
        "\n",
        "    print(f\"Fold {fold} Student Model\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"F1 Score: {f1}\")\n",
        "\n",
        "    student_accuracies.append(accuracy)\n",
        "    student_f1_scores.append(f1)\n",
        "\n",
        "    # Print confusion matrix and classification report for the current fold\n",
        "    # print(f\"Fold {fold} Student Model\")\n",
        "    # print(\"Confusion Matrix:\")\n",
        "    # print(confusion_matrix(y_val_classes, val_preds_classes))\n",
        "    # print(\"Classification Report:\")\n",
        "    # print(classification_report(y_val_classes, val_preds_classes))\n",
        "\n",
        "print(f\"Student Model Cross-Validation Accuracy: {np.mean(student_accuracies):.2f} ± {np.std(student_accuracies):.2f}\")\n",
        "print(f\"Student Model Cross-Validation F1 Score: {np.mean(student_f1_scores):.2f} ± {np.std(student_f1_scores):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uwKBXHhsQ8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c7970f9-d9db-4717-a172-120582bdc528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "TEST RESULT:\n",
            "Accuracy: 0.7341040462427746\n",
            "f1_score: 0.7338367890578626\n",
            "Confusion Matrix:\n",
            "[[ 10   3   1   2]\n",
            " [  6 118  23   4]\n",
            " [  2  23  68  12]\n",
            " [  0   8   8  58]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.62      0.59        16\n",
            "           1       0.78      0.78      0.78       151\n",
            "           2       0.68      0.65      0.66       105\n",
            "           3       0.76      0.78      0.77        74\n",
            "\n",
            "    accuracy                           0.73       346\n",
            "   macro avg       0.69      0.71      0.70       346\n",
            "weighted avg       0.73      0.73      0.73       346\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Student Model on Test Data\n",
        "# test_soft_targets = teacher_model.predict(X_test)\n",
        "# student_loss_and_metrics = student_model.evaluate(X_test[:, -8:], test_soft_targets)\n",
        "# print(f\"EVALUATION RESULT:\\nStudent Model Loss: {student_loss_and_metrics[0]}, Accuracy: {student_loss_and_metrics[1]}\\n\\n\")\n",
        "\n",
        "val_preds = student_model.predict(X_test[:, -8:])\n",
        "val_preds_classes = np.argmax(val_preds, axis=1)\n",
        "y_val_classes = np.argmax(y_test_cat, axis=1)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_val_classes, val_preds_classes)\n",
        "f1 = f1_score(y_val_classes, val_preds_classes, average='weighted')\n",
        "\n",
        "# Print confusion matrix and classification report for the current fold\n",
        "print(f\"TEST RESULT:\\nAccuracy: {accuracy}\\nf1_score: {f1}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val_classes, val_preds_classes))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val_classes, val_preds_classes))\n",
        "\n",
        "#student model with 8 with kd\n",
        "# Accuracy: 0.7023121387283237\n",
        "# f1_score: 0.6983952768813754\n",
        "\n",
        "#student model with 8 and without kd\n",
        "# Accuracy: 0.7341040462427746\n",
        "# f1_score: 0.7338367890578626"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(teacher_model.summary())\n",
        "print(student_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "Y_em4jtCgUdl",
        "outputId": "7983f666-e544-4295-d8af-36e6f084c886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_22\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_22\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_66 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m12,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_67 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_68 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_69 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_70 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_71 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │           \u001b[38;5;34m1,204\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,204</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,124,114\u001b[0m (4.29 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,124,114</span> (4.29 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m374,704\u001b[0m (1.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">374,704</span> (1.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m749,410\u001b[0m (2.86 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">749,410</span> (2.86 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_25\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_25\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_82 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │           \u001b[38;5;34m2,700\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_83 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_84 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_85 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_86 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │           \u001b[38;5;34m1,204\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,700</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,204</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m824,414\u001b[0m (3.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">824,414</span> (3.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m274,804\u001b[0m (1.05 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">274,804</span> (1.05 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m549,610\u001b[0m (2.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">549,610</span> (2.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Now trainig the student model with 40 channels"
      ],
      "metadata": {
        "id": "-M_RLf_3U9Po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_student_model_dnn300():\n",
        "    model = Sequential()\n",
        "    # Only using 8 physiological signals as input\n",
        "    model.add(Dense(300, input_dim=40, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    # Output layer remains same since we have 4 classes\n",
        "    model.add(Dense(4, kernel_initializer='normal', activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "F9wcyoA7hRmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the light weight student model with groung true labels (y_train) and with KD\n",
        "# Caution!: both code are in this file, comment the respective thing to run the code, currently commented the KD section\n",
        "\n",
        "# Student Model Cross-Validation with Confusion Matrix and Classification Report with 40 channels\n",
        "student_accuracies = []\n",
        "student_f1_scores = []\n",
        "\n",
        "student_model = create_student_model_dnn300()\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(X_train, y_train), 1):\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train_cat[train_index], y_train_cat[val_index]\n",
        "\n",
        "    # Train teacher model to generate soft targets\n",
        "    # teacher_model = create_teacher_model()\n",
        "    # teacher_model.fit(X_train_fold, y_train_fold, epochs=50, batch_size=32, verbose=0)\n",
        "    # soft_targets = teacher_model.predict(X_train_fold)\n",
        "\n",
        "    # Create and train the student model\n",
        "    # student_history= student_model.fit(X_train_fold[:, -8:], soft_targets, epochs=100, batch_size=32, verbose=0)\n",
        "\n",
        "    #without KD\n",
        "    student_history= student_model.fit(X_train_fold, y_train_fold, epochs=100, batch_size=32, verbose=0)\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    val_preds = student_model.predict(X_val_fold)\n",
        "    val_preds_classes = np.argmax(val_preds, axis=1)\n",
        "    y_val_classes = np.argmax(y_val_fold, axis=1)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_val_classes, val_preds_classes)\n",
        "    f1 = f1_score(y_val_classes, val_preds_classes, average='weighted')\n",
        "\n",
        "    print(f\"Fold {fold} Student Model\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"F1 Score: {f1}\")\n",
        "\n",
        "    student_accuracies.append(accuracy)\n",
        "    student_f1_scores.append(f1)\n",
        "\n",
        "print(f\"Student Model Cross-Validation Accuracy: {np.mean(student_accuracies):.2f} ± {np.std(student_accuracies):.2f}\")\n",
        "print(f\"Student Model Cross-Validation F1 Score: {np.mean(student_f1_scores):.2f} ± {np.std(student_f1_scores):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CR6mrwJuhYGi",
        "outputId": "41bfd67e-b905-4761-d920-81f257b2bcc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Fold 1 Student Model\n",
            "Accuracy: 0.6642599277978339\n",
            "F1 Score: 0.655431892451553\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Fold 2 Student Model\n",
            "Accuracy: 0.7472924187725631\n",
            "F1 Score: 0.7451344805986464\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Fold 3 Student Model\n",
            "Accuracy: 0.8043478260869565\n",
            "F1 Score: 0.8039709211416837\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Fold 4 Student Model\n",
            "Accuracy: 0.7427536231884058\n",
            "F1 Score: 0.7401561465811597\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Fold 5 Student Model\n",
            "Accuracy: 0.7898550724637681\n",
            "F1 Score: 0.7881543613020399\n",
            "Student Model Cross-Validation Accuracy: 0.75 ± 0.05\n",
            "Student Model Cross-Validation F1 Score: 0.75 ± 0.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(student_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "kfAY3hnPjkHn",
        "outputId": "6cd665e1-d62e-4469-d20b-2302ab524234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_27\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_27\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_92 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m12,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_93 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_94 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_95 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_96 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │           \u001b[38;5;34m1,204\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_92 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_96 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,204</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m853,214\u001b[0m (3.25 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">853,214</span> (3.25 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m284,404\u001b[0m (1.08 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">284,404</span> (1.08 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m568,810\u001b[0m (2.17 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">568,810</span> (2.17 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGdv2HNmmmGf"
      },
      "outputs": [],
      "source": [
        "# Student Model Cross-Validation with Confusion Matrix and Classification Report \"without Knowledge Distillation\" - temp\n",
        "student_accuracies = []\n",
        "student_f1_scores = []\n",
        "print(\"Student model without knowledge distillation\\n\\n\")\n",
        "\n",
        "temp_model = create_student_model_dnn300()\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(X_train, y_train), 1):\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train_cat[train_index], y_train_cat[val_index]\n",
        "\n",
        "    # Train teacher model to generate soft targets\n",
        "    # teacher_model = create_teacher_model()\n",
        "    # teacher_model.fit(X_train_fold, y_train_fold, epochs=50, batch_size=32, verbose=0)\n",
        "    # soft_targets = teacher_model.predict(X_train_fold)\n",
        "\n",
        "    # Create and train the student model\n",
        "    temp_history= temp_model.fit(X_train_fold[:, -8:], y_train_fold, epochs=100, batch_size=32, verbose=0)\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    val_preds = temp_model.predict(X_val_fold[:, -8:])\n",
        "    val_preds_classes = np.argmax(val_preds, axis=1)\n",
        "    y_val_classes = np.argmax(y_val_fold, axis=1)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_val_classes, val_preds_classes)\n",
        "    f1 = f1_score(y_val_classes, val_preds_classes, average='weighted')\n",
        "\n",
        "    print(f\"Fold {fold} Student Model\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"F1 Score: {f1}\")\n",
        "\n",
        "    student_accuracies.append(accuracy)\n",
        "    student_f1_scores.append(f1)\n",
        "\n",
        "    # Print confusion matrix and classification report for the current fold\n",
        "    # print(f\"Fold {fold} Student Model\")\n",
        "    # print(\"Confusion Matrix:\")\n",
        "    # print(confusion_matrix(y_val_classes, val_preds_classes))\n",
        "    # print(\"Classification Report:\")\n",
        "    # print(classification_report(y_val_classes, val_preds_classes))\n",
        "\n",
        "print(f\"Student Model Cross-Validation Accuracy: {np.mean(student_accuracies):.2f} ± {np.std(student_accuracies):.2f}\")\n",
        "print(f\"Student Model Cross-Validation F1 Score: {np.mean(student_f1_scores):.2f} ± {np.std(student_f1_scores):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "se0nzPGrnM38"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred = temp_model.predict(X_test[:,-8:])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Get the class with the highest probability\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "class_report = classification_report(y_test, y_pred_classes)\n",
        "\n",
        "# Print metrics\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print('Confusion Matrix:\\n', conf_matrix)\n",
        "print('Classification Report:\\n', class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "yu5AA1lql1e6",
        "outputId": "39362a59-a3f6-4af3-988e-6db7f821af0b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to plot the training loss for both Teacher and Student models\n",
        "def plot_loss(teacher_history, student_history, temp_history):\n",
        "    # Extract loss for each model\n",
        "    teacher_loss = teacher_history.history['loss']\n",
        "    student_loss = student_history.history['loss']\n",
        "    temp_loss = temp_history.history['loss']\n",
        "\n",
        "    # Define the range of epochs\n",
        "    teacher_epochs = range(len(teacher_loss))\n",
        "    student_epochs = range(len(student_loss))\n",
        "    temp_epochs = range(len(temp_loss))\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Plot teacher model loss\n",
        "    plt.plot(teacher_epochs, teacher_loss, label='Teacher Model Loss', color='blue')\n",
        "\n",
        "    # Plot student model loss (trained with soft targets)\n",
        "    plt.plot(student_epochs, student_loss, label='Student Model Loss (Soft Targets)', color='green')\n",
        "\n",
        "    # Plot temp student model loss (trained directly with 8 physiological signals)\n",
        "    plt.plot(temp_epochs, temp_loss, label='Student Model Loss (8 Signals)', color='red')\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.title('Epochs vs Loss for Teacher and Student Models')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Call the plotting function\n",
        "plot_loss(teacher_history, student_history, temp_history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "yVkjKuMem_Yy",
        "outputId": "ecefe4d0-d860-4d81-d13a-3b118236e17f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Function to plot accuracy over epochs\n",
        "def plot_accuracy(teacher_history, student_history, temp_history):\n",
        "    # Get accuracy from each model's history\n",
        "    teacher_acc = teacher_history.history['accuracy']\n",
        "    student_acc = student_history.history['accuracy']\n",
        "    temp_acc = temp_history.history['accuracy']\n",
        "\n",
        "    # Get the number of epochs\n",
        "    epochs = range(1, len(teacher_acc) + 1)\n",
        "\n",
        "    # Plot the accuracy over epochs for each model\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    plt.plot(epochs, teacher_acc, 'b-', label='Teacher Model Accuracy')\n",
        "    plt.plot(epochs, student_acc, 'g-', label='Student Model (Distillation) Accuracy')\n",
        "    plt.plot(epochs, temp_acc, 'r-', label='Student Model (No Distillation) Accuracy')\n",
        "\n",
        "    # Add title and labels\n",
        "    plt.title('Accuracy over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "\n",
        "    # Display the legend\n",
        "    plt.legend()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Assuming you have already captured the history objects:\n",
        "# teacher_history, student_history, temp_history\n",
        "plot_accuracy(teacher_history, student_history, temp_history)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKQl9qLEsyNg"
      },
      "source": [
        "### Using DNN 150 neurons\n",
        "\n",
        "<p>Teacher Model: Accuracy: 69.94\n",
        "F1 Score: 69.16</p>\n",
        "<p>Student Model: Accuracy: 58.09\n",
        "F1 Score: 57.36</p>\n",
        "<p>Without KD: Accuracy: 67.63,\n",
        "F1 Score: 67.50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekXvtIo5tS8N"
      },
      "outputs": [],
      "source": [
        "def create_teacher_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(150, input_dim=40, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(150, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(150, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(4, kernel_initializer='normal', activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_student_model():\n",
        "    model = Sequential()\n",
        "    # Only using 8 physiological signals as input\n",
        "    model.add(Dense(150, input_dim=8, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(150, kernel_initializer='normal', activation='relu'))\n",
        "    # Output layer remains same since we have 4 classes\n",
        "    model.add(Dense(4, kernel_initializer='normal', activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_NVQUMMtv50"
      },
      "outputs": [],
      "source": [
        "# Train Teacher Model\n",
        "teacher_model_dnn150 = create_teacher_model()\n",
        "teacher_history= teacher_model_dnn150.fit(X_train, y_train_cat, epochs=100, batch_size=32)\n",
        "\n",
        "# Generate soft targets from Teacher Model for Student Training\n",
        "soft_targets = teacher_model_dnn150.predict(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lX9GyQRho2lj"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred = teacher_model_dnn150.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Get the class with the highest probability\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "class_report = classification_report(y_test, y_pred_classes)\n",
        "\n",
        "# Print metrics\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print('Confusion Matrix:\\n', conf_matrix)\n",
        "print('Classification Report:\\n', class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fol4R3Ggt9JS",
        "outputId": "f311ad97-16de-4f47-b67c-416c4abf66cf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3341 - loss: 57.7502\n",
            "Epoch 2/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4680 - loss: 18.9253\n",
            "Epoch 3/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4853 - loss: 13.4377\n",
            "Epoch 4/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5385 - loss: 9.7041 \n",
            "Epoch 5/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5574 - loss: 7.6740\n",
            "Epoch 6/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5382 - loss: 9.7699 \n",
            "Epoch 7/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5466 - loss: 7.6108\n",
            "Epoch 8/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6183 - loss: 3.2077\n",
            "Epoch 9/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6439 - loss: 2.9485\n",
            "Epoch 10/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6339 - loss: 2.8759\n",
            "Epoch 11/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6439 - loss: 3.2919\n",
            "Epoch 12/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6259 - loss: 3.0828\n",
            "Epoch 13/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6601 - loss: 2.7218\n",
            "Epoch 14/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6631 - loss: 2.3322\n",
            "Epoch 15/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7270 - loss: 1.3393\n",
            "Epoch 16/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6666 - loss: 2.4644\n",
            "Epoch 17/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6228 - loss: 4.2228\n",
            "Epoch 18/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6530 - loss: 2.1366\n",
            "Epoch 19/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6704 - loss: 2.7507\n",
            "Epoch 20/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6807 - loss: 2.3549\n",
            "Epoch 21/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6685 - loss: 1.9717\n",
            "Epoch 22/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7379 - loss: 0.9561\n",
            "Epoch 23/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7054 - loss: 1.1663\n",
            "Epoch 24/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7211 - loss: 1.2586\n",
            "Epoch 25/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7187 - loss: 1.1472\n",
            "Epoch 26/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7833 - loss: 0.8032\n",
            "Epoch 27/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7540 - loss: 0.8641\n",
            "Epoch 28/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7867 - loss: 0.7546\n",
            "Epoch 29/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7931 - loss: 0.7498\n",
            "Epoch 30/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7566 - loss: 1.0112\n",
            "Epoch 31/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7626 - loss: 0.8850\n",
            "Epoch 32/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.5987\n",
            "Epoch 33/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8126 - loss: 0.6569\n",
            "Epoch 34/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7887 - loss: 0.7619\n",
            "Epoch 35/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7125 - loss: 1.2807\n",
            "Epoch 36/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7504 - loss: 0.8672\n",
            "Epoch 37/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7978 - loss: 0.8440\n",
            "Epoch 38/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7569 - loss: 0.8524\n",
            "Epoch 39/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7802 - loss: 0.8657\n",
            "Epoch 40/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7830 - loss: 0.8319\n",
            "Epoch 41/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8156 - loss: 0.6698\n",
            "Epoch 42/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8193 - loss: 0.5997\n",
            "Epoch 43/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7965 - loss: 0.7638\n",
            "Epoch 44/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8060 - loss: 0.6380\n",
            "Epoch 45/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8161 - loss: 0.9439\n",
            "Epoch 46/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8554 - loss: 0.5123\n",
            "Epoch 47/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.5283\n",
            "Epoch 48/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.6159\n",
            "Epoch 49/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8211 - loss: 0.6267\n",
            "Epoch 50/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8390 - loss: 0.5352\n",
            "Epoch 51/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8458 - loss: 0.4961\n",
            "Epoch 52/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8464 - loss: 0.5031\n",
            "Epoch 53/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8266 - loss: 0.5670\n",
            "Epoch 54/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8449 - loss: 0.5634\n",
            "Epoch 55/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7740 - loss: 1.2731\n",
            "Epoch 56/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8451 - loss: 0.5209\n",
            "Epoch 57/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8465 - loss: 0.5257\n",
            "Epoch 58/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8256 - loss: 0.6069\n",
            "Epoch 59/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8437 - loss: 0.5245\n",
            "Epoch 60/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8488 - loss: 0.4883\n",
            "Epoch 61/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8658 - loss: 0.4918\n",
            "Epoch 62/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8659 - loss: 0.4580\n",
            "Epoch 63/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8512 - loss: 0.4792\n",
            "Epoch 64/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8891 - loss: 0.4388\n",
            "Epoch 65/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8810 - loss: 0.4161\n",
            "Epoch 66/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8924 - loss: 0.4164\n",
            "Epoch 67/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8488 - loss: 0.4947\n",
            "Epoch 68/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8752 - loss: 0.4774\n",
            "Epoch 69/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8832 - loss: 0.4213\n",
            "Epoch 70/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8963 - loss: 0.4093\n",
            "Epoch 71/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9237 - loss: 0.3604\n",
            "Epoch 72/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8959 - loss: 0.4103\n",
            "Epoch 73/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8847 - loss: 0.4735\n",
            "Epoch 74/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8440 - loss: 0.5346\n",
            "Epoch 75/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8403 - loss: 0.5609\n",
            "Epoch 76/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8654 - loss: 0.4589\n",
            "Epoch 77/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8671 - loss: 0.5553\n",
            "Epoch 78/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8630 - loss: 0.4816\n",
            "Epoch 79/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8670 - loss: 0.4831\n",
            "Epoch 80/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8356 - loss: 0.5315\n",
            "Epoch 81/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8376 - loss: 0.5441\n",
            "Epoch 82/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8615 - loss: 0.4715\n",
            "Epoch 83/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8417 - loss: 0.5009\n",
            "Epoch 84/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8625 - loss: 0.4683\n",
            "Epoch 85/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8544 - loss: 0.4636\n",
            "Epoch 86/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8368 - loss: 0.4947\n",
            "Epoch 87/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8798 - loss: 0.4332\n",
            "Epoch 88/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8769 - loss: 0.4350\n",
            "Epoch 89/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8875 - loss: 0.4284\n",
            "Epoch 90/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8994 - loss: 0.3771\n",
            "Epoch 91/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8981 - loss: 0.3920\n",
            "Epoch 92/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8847 - loss: 0.4970\n",
            "Epoch 93/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8827 - loss: 0.4202\n",
            "Epoch 94/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8844 - loss: 0.4199\n",
            "Epoch 95/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8840 - loss: 0.4554\n",
            "Epoch 96/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.4122\n",
            "Epoch 97/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8777 - loss: 0.4633\n",
            "Epoch 98/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8802 - loss: 0.4203\n",
            "Epoch 99/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8756 - loss: 0.4634\n",
            "Epoch 100/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8754 - loss: 0.4499\n"
          ]
        }
      ],
      "source": [
        "# Train Student Model using soft targets from Teacher Model\n",
        "student_model_dnn150 = create_student_model()\n",
        "student_history= student_model_dnn150.fit(X_train[:, -8:], soft_targets, epochs=100, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwMmDM3LuLk2",
        "outputId": "53e0a1f2-e7d7-47ed-ad24-44e3e26b82c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7593 - loss: 1.1173  \n",
            "Student Model Loss: 1.0656723976135254, Accuracy: 0.7543352842330933\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Accuracy: 0.6705\n",
            "F1 Score: 0.6711\n",
            "Confusion Matrix:\n",
            " [[ 11   5   0   0]\n",
            " [ 10 116  14  11]\n",
            " [  9  32  54  10]\n",
            " [  2  14   7  51]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.34      0.69      0.46        16\n",
            "         1.0       0.69      0.77      0.73       151\n",
            "         2.0       0.72      0.51      0.60       105\n",
            "         3.0       0.71      0.69      0.70        74\n",
            "\n",
            "    accuracy                           0.67       346\n",
            "   macro avg       0.62      0.66      0.62       346\n",
            "weighted avg       0.69      0.67      0.67       346\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Student Model on Test Data\n",
        "test_soft_targets = teacher_model_dnn150.predict(X_test)\n",
        "student_loss_and_metrics = student_model_dnn150.evaluate(X_test[:, -8:], test_soft_targets)\n",
        "print(f\"Student Model Loss: {student_loss_and_metrics[0]}, Accuracy: {student_loss_and_metrics[1]}\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = student_model_dnn150.predict(X_test[:,-8:])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Get the class with the highest probability\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "class_report = classification_report(y_test, y_pred_classes)\n",
        "\n",
        "# Print metrics\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print('Confusion Matrix:\\n', conf_matrix)\n",
        "print('Classification Report:\\n', class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM0Esb7RuwSo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "outputId": "4db2f4c3-cd7c-434f-bf62-8f9fe2939384"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 │           \u001b[38;5;34m6,150\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 │          \u001b[38;5;34m22,650\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 │          \u001b[38;5;34m22,650\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m604\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,150</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">22,650</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">22,650</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">604</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m52,054\u001b[0m (203.34 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,054</span> (203.34 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m52,054\u001b[0m (203.34 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,054</span> (203.34 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 │           \u001b[38;5;34m1,350\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 │          \u001b[38;5;34m22,650\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m604\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,350</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">22,650</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">604</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,604\u001b[0m (96.11 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,604</span> (96.11 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,604\u001b[0m (96.11 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,604</span> (96.11 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "teacher_model_dnn150 = create_teacher_model()\n",
        "student_model_dnn150 = create_student_model()\n",
        "\n",
        "print(teacher_model_dnn150.summary())\n",
        "print(student_model_dnn150.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMZu8HiLpzPO",
        "outputId": "555f3878-1f93-42bb-95da-67e9a7666ff8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3329 - loss: 59.7954\n",
            "Epoch 2/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4207 - loss: 23.0099\n",
            "Epoch 3/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5146 - loss: 14.5498\n",
            "Epoch 4/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4677 - loss: 23.2025\n",
            "Epoch 5/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4682 - loss: 28.9931\n",
            "Epoch 6/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4773 - loss: 18.4729\n",
            "Epoch 7/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5395 - loss: 8.4500\n",
            "Epoch 8/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5654 - loss: 6.6615\n",
            "Epoch 9/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5914 - loss: 4.7306\n",
            "Epoch 10/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5710 - loss: 4.9568\n",
            "Epoch 11/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5843 - loss: 3.9264\n",
            "Epoch 12/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6000 - loss: 3.8626\n",
            "Epoch 13/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6195 - loss: 4.4997\n",
            "Epoch 14/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5766 - loss: 4.2523\n",
            "Epoch 15/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6334 - loss: 3.0043\n",
            "Epoch 16/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6707 - loss: 2.2980\n",
            "Epoch 17/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6523 - loss: 2.4252\n",
            "Epoch 18/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6594 - loss: 2.3573\n",
            "Epoch 19/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6579 - loss: 2.9525\n",
            "Epoch 20/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6611 - loss: 2.0989\n",
            "Epoch 21/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6621 - loss: 2.6798\n",
            "Epoch 22/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6592 - loss: 2.0771\n",
            "Epoch 23/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6598 - loss: 3.0261\n",
            "Epoch 24/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6670 - loss: 2.7465\n",
            "Epoch 25/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6916 - loss: 1.9781\n",
            "Epoch 26/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6887 - loss: 1.9731\n",
            "Epoch 27/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7119 - loss: 1.7506\n",
            "Epoch 28/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7320 - loss: 1.5567\n",
            "Epoch 29/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7215 - loss: 1.5545\n",
            "Epoch 30/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7100 - loss: 1.3165\n",
            "Epoch 31/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7119 - loss: 1.1747\n",
            "Epoch 32/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6703 - loss: 2.9840\n",
            "Epoch 33/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7045 - loss: 1.8255\n",
            "Epoch 34/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7193 - loss: 1.5228\n",
            "Epoch 35/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7119 - loss: 1.5435\n",
            "Epoch 36/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6498 - loss: 4.0012\n",
            "Epoch 37/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6605 - loss: 4.4522\n",
            "Epoch 38/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6997 - loss: 1.8629\n",
            "Epoch 39/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6977 - loss: 2.5790\n",
            "Epoch 40/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7363 - loss: 1.0942\n",
            "Epoch 41/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7288 - loss: 1.3943\n",
            "Epoch 42/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7295 - loss: 1.1115\n",
            "Epoch 43/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7231 - loss: 1.0437\n",
            "Epoch 44/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7092 - loss: 1.8055\n",
            "Epoch 45/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7468 - loss: 0.8210\n",
            "Epoch 46/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7398 - loss: 1.0836\n",
            "Epoch 47/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7747 - loss: 0.6049\n",
            "Epoch 48/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7517 - loss: 0.7462\n",
            "Epoch 49/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8049 - loss: 0.5184\n",
            "Epoch 50/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7493 - loss: 1.1421\n",
            "Epoch 51/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7734 - loss: 0.6111\n",
            "Epoch 52/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7971 - loss: 0.5430\n",
            "Epoch 53/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8007 - loss: 0.4980\n",
            "Epoch 54/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7936 - loss: 0.5046\n",
            "Epoch 55/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7923 - loss: 0.5366\n",
            "Epoch 56/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8009 - loss: 0.5100\n",
            "Epoch 57/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8300 - loss: 0.4400\n",
            "Epoch 58/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8220 - loss: 0.4179\n",
            "Epoch 59/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8219 - loss: 0.4352\n",
            "Epoch 60/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8450 - loss: 0.3844\n",
            "Epoch 61/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8298 - loss: 0.4030\n",
            "Epoch 62/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8171 - loss: 0.5480\n",
            "Epoch 63/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8193 - loss: 0.4678\n",
            "Epoch 64/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8053 - loss: 0.5082\n",
            "Epoch 65/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8324 - loss: 0.4118\n",
            "Epoch 66/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.4092\n",
            "Epoch 67/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8399 - loss: 0.4465\n",
            "Epoch 68/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8448 - loss: 0.4125\n",
            "Epoch 69/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8250 - loss: 0.7055\n",
            "Epoch 70/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7873 - loss: 0.6568\n",
            "Epoch 71/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7931 - loss: 0.5968\n",
            "Epoch 72/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8209 - loss: 0.4059\n",
            "Epoch 73/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8196 - loss: 0.4624\n",
            "Epoch 74/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8054 - loss: 0.5690\n",
            "Epoch 75/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7808 - loss: 0.7520\n",
            "Epoch 76/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7654 - loss: 0.6412\n",
            "Epoch 77/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8079 - loss: 0.5057\n",
            "Epoch 78/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8271 - loss: 0.4305\n",
            "Epoch 79/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.4623\n",
            "Epoch 80/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8267 - loss: 0.4088\n",
            "Epoch 81/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8250 - loss: 0.4256\n",
            "Epoch 82/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8474 - loss: 0.4054\n",
            "Epoch 83/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8493 - loss: 0.3921\n",
            "Epoch 84/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8497 - loss: 0.3899\n",
            "Epoch 85/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8422 - loss: 0.4224\n",
            "Epoch 86/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8459 - loss: 0.4165\n",
            "Epoch 87/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8545 - loss: 0.3477\n",
            "Epoch 88/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8173 - loss: 0.4660\n",
            "Epoch 89/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8096 - loss: 0.5495\n",
            "Epoch 90/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8452 - loss: 0.4272\n",
            "Epoch 91/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8352 - loss: 0.4015\n",
            "Epoch 92/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8223 - loss: 0.7907\n",
            "Epoch 93/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7738 - loss: 0.6533\n",
            "Epoch 94/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8373 - loss: 0.4245\n",
            "Epoch 95/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8171 - loss: 0.5186\n",
            "Epoch 96/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8028 - loss: 0.5421\n",
            "Epoch 97/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7982 - loss: 0.5424\n",
            "Epoch 98/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8387 - loss: 0.3983\n",
            "Epoch 99/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8281 - loss: 0.4860\n",
            "Epoch 100/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8334 - loss: 0.3809\n"
          ]
        }
      ],
      "source": [
        "# Train Student Model without using soft targets from Teacher Model\n",
        "temp_model = create_student_model()\n",
        "temp_history= temp_model.fit(X_train[:, -8:], y_train_cat, epochs=100, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SiRiijCqH9d",
        "outputId": "7179357d-f183-4f03-ef49-abbca25df0aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Accuracy: 0.6965\n",
            "F1 Score: 0.6922\n",
            "Confusion Matrix:\n",
            " [[  8   4   2   2]\n",
            " [  1 124  14  12]\n",
            " [  4  31  60  10]\n",
            " [  2  14   9  49]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.53      0.50      0.52        16\n",
            "         1.0       0.72      0.82      0.77       151\n",
            "         2.0       0.71      0.57      0.63       105\n",
            "         3.0       0.67      0.66      0.67        74\n",
            "\n",
            "    accuracy                           0.70       346\n",
            "   macro avg       0.66      0.64      0.64       346\n",
            "weighted avg       0.70      0.70      0.69       346\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Make predictions\n",
        "y_pred = temp_model.predict(X_test[:,-8:])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Get the class with the highest probability\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "class_report = classification_report(y_test, y_pred_classes)\n",
        "\n",
        "# Print metrics\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print('Confusion Matrix:\\n', conf_matrix)\n",
        "print('Classification Report:\\n', class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niXCxUKrfT7-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss(teacher_history, student_history, temp_history):\n",
        "    # Extract loss for each model\n",
        "    teacher_loss = teacher_history.history['loss']\n",
        "    student_loss = student_history.history['loss']\n",
        "    temp_loss = temp_history.history['loss']\n",
        "\n",
        "    # Define the range of epochs\n",
        "    teacher_epochs = range(len(teacher_loss))\n",
        "    student_epochs = range(len(student_loss))\n",
        "    temp_epochs = range(len(temp_loss))\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Plot teacher model loss\n",
        "    plt.plot(teacher_epochs, teacher_loss, label='Teacher Model Loss', color='blue')\n",
        "\n",
        "    # Plot student model loss (trained with soft targets)\n",
        "    plt.plot(student_epochs, student_loss, label='Student Model Loss (Soft Targets)', color='green')\n",
        "\n",
        "    # Plot temp student model loss (trained directly with 8 physiological signals)\n",
        "    plt.plot(temp_epochs, temp_loss, label='Student Model Loss (8 Signals)', color='red')\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.title('Epochs vs Loss for Teacher and Student Models')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Call the plotting function\n",
        "plot_loss(teacher_history, student_history, temp_history)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlTSIkTgkpAV"
      },
      "outputs": [],
      "source": [
        "# Function to plot accuracy over epochs\n",
        "def plot_accuracy(teacher_history, student_history, temp_history):\n",
        "    # Get accuracy from each model's history\n",
        "    teacher_acc = teacher_history.history['accuracy']\n",
        "    student_acc = student_history.history['accuracy']\n",
        "    temp_acc = temp_history.history['accuracy']\n",
        "\n",
        "    # Get the number of epochs\n",
        "    epochs = range(1, len(teacher_acc) + 1)\n",
        "\n",
        "    # Plot the accuracy over epochs for each model\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    plt.plot(epochs, teacher_acc, 'b-', label='Teacher Model Accuracy')\n",
        "    plt.plot(epochs, student_acc, 'g-', label='Student Model (Distillation) Accuracy')\n",
        "    plt.plot(epochs, temp_acc, 'r-', label='Student Model (No Distillation) Accuracy')\n",
        "\n",
        "    # Add title and labels\n",
        "    plt.title('Accuracy over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "\n",
        "    # Display the legend\n",
        "    plt.legend()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Assuming you have already captured the history objects:\n",
        "# teacher_history, student_history, temp_history\n",
        "plot_accuracy(teacher_history, student_history, temp_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEUShNeKvRvS"
      },
      "source": [
        "### using LSTM model for knowledge distillation\n",
        "<p>Teacher model: Accuracy: 51.16\n",
        "F1 Score: 42.67</p>\n",
        "<p>Student model: accuracy - 47.40, f1 score - 35.85</p>\n",
        "<p>student model without KD: Accuracy - 47.69, F1-score - 39.04</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0DXapSyvWY8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.losses import KLDivergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay4_5sRcvZzE"
      },
      "outputs": [],
      "source": [
        "# Splitting features for teacher and student models\n",
        "X_teacher = X_train  # All features for teacher model (40 features)\n",
        "X_student = X_train[:, -8:]  # Only last 8 features for student model (8 physiological signals)\n",
        "\n",
        "y_train_one_hot = tf.keras.utils.to_categorical(y_train)\n",
        "y_test_one_hot = tf.keras.utils.to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSAjNcEZvedw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e2c3a52-125b-4ee0-c0be-553e9208c8c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "def create_teacher_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, input_shape=input_shape))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4, activation='softmax'))  # Output layer for four classes\n",
        "    return model\n",
        "\n",
        "teacher_model = create_teacher_model((X_teacher.shape[1], 1))\n",
        "teacher_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wziLo-giv_OH",
        "outputId": "2bf14f0e-35a9-4a1f-c5ec-55e13e3134ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.2896 - loss: 1.5594\n",
            "Epoch 2/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.3456 - loss: 1.3711\n",
            "Epoch 3/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.3518 - loss: 1.3448\n",
            "Epoch 4/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.3749 - loss: 1.3046\n",
            "Epoch 5/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.4056 - loss: 1.2577\n",
            "Epoch 6/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.3887 - loss: 1.2610\n",
            "Epoch 7/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.3674 - loss: 1.2653\n",
            "Epoch 8/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4187 - loss: 1.2455\n",
            "Epoch 9/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4000 - loss: 1.2588\n",
            "Epoch 10/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4144 - loss: 1.2234\n",
            "Epoch 11/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.3847 - loss: 1.2609\n",
            "Epoch 12/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3813 - loss: 1.2611\n",
            "Epoch 13/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.4037 - loss: 1.2111\n",
            "Epoch 14/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3837 - loss: 1.2279\n",
            "Epoch 15/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4148 - loss: 1.2121\n",
            "Epoch 16/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4090 - loss: 1.2371\n",
            "Epoch 17/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4392 - loss: 1.2103\n",
            "Epoch 18/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4454 - loss: 1.1942\n",
            "Epoch 19/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4082 - loss: 1.2279\n",
            "Epoch 20/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4227 - loss: 1.2031\n",
            "Epoch 21/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4254 - loss: 1.1988\n",
            "Epoch 22/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4129 - loss: 1.2267\n",
            "Epoch 23/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4148 - loss: 1.2174\n",
            "Epoch 24/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4284 - loss: 1.1814\n",
            "Epoch 25/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4232 - loss: 1.1779\n",
            "Epoch 26/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4188 - loss: 1.2134\n",
            "Epoch 27/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.4398 - loss: 1.2001\n",
            "Epoch 28/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.4590 - loss: 1.1707\n",
            "Epoch 29/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.4388 - loss: 1.1828\n",
            "Epoch 30/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.4300 - loss: 1.2006\n",
            "Epoch 31/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.4406 - loss: 1.1816\n",
            "Epoch 32/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4355 - loss: 1.1980\n",
            "Epoch 33/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4197 - loss: 1.1942\n",
            "Epoch 34/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4617 - loss: 1.1878\n",
            "Epoch 35/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4621 - loss: 1.1652\n",
            "Epoch 36/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4424 - loss: 1.1793\n",
            "Epoch 37/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4262 - loss: 1.1945\n",
            "Epoch 38/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4558 - loss: 1.1976\n",
            "Epoch 39/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4520 - loss: 1.1783\n",
            "Epoch 40/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4163 - loss: 1.1890\n",
            "Epoch 41/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4223 - loss: 1.1859\n",
            "Epoch 42/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.4481 - loss: 1.1535\n",
            "Epoch 43/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4535 - loss: 1.1757\n",
            "Epoch 44/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4335 - loss: 1.1733\n",
            "Epoch 45/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4579 - loss: 1.1709\n",
            "Epoch 46/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4617 - loss: 1.1518\n",
            "Epoch 47/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4476 - loss: 1.1639\n",
            "Epoch 48/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4637 - loss: 1.1492\n",
            "Epoch 49/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4598 - loss: 1.1475\n",
            "Epoch 50/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4532 - loss: 1.1600\n",
            "Epoch 51/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4298 - loss: 1.1783\n",
            "Epoch 52/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4160 - loss: 1.2050\n",
            "Epoch 53/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.4588 - loss: 1.1544\n",
            "Epoch 54/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.4713 - loss: 1.1321\n",
            "Epoch 55/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4424 - loss: 1.1578\n",
            "Epoch 56/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4701 - loss: 1.1331\n",
            "Epoch 57/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4534 - loss: 1.1651\n",
            "Epoch 58/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4437 - loss: 1.1637\n",
            "Epoch 59/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4511 - loss: 1.1571\n",
            "Epoch 60/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4659 - loss: 1.1487\n",
            "Epoch 61/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4800 - loss: 1.1209\n",
            "Epoch 62/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4556 - loss: 1.1917\n",
            "Epoch 63/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4447 - loss: 1.2075\n",
            "Epoch 64/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.4580 - loss: 1.1587\n",
            "Epoch 65/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.4510 - loss: 1.1673\n",
            "Epoch 66/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.4309 - loss: 1.1656\n",
            "Epoch 67/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4433 - loss: 1.1612\n",
            "Epoch 68/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4341 - loss: 1.1686\n",
            "Epoch 69/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4642 - loss: 1.1462\n",
            "Epoch 70/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4575 - loss: 1.1592\n",
            "Epoch 71/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4449 - loss: 1.1539\n",
            "Epoch 72/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4607 - loss: 1.1562\n",
            "Epoch 73/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4565 - loss: 1.1482\n",
            "Epoch 74/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4544 - loss: 1.1684\n",
            "Epoch 75/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4642 - loss: 1.1478\n",
            "Epoch 76/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4510 - loss: 1.1575\n",
            "Epoch 77/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4371 - loss: 1.1751\n",
            "Epoch 78/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4342 - loss: 1.1716\n",
            "Epoch 79/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4491 - loss: 1.1608\n",
            "Epoch 80/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4553 - loss: 1.1351\n",
            "Epoch 81/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4735 - loss: 1.1466\n",
            "Epoch 82/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4654 - loss: 1.1384\n",
            "Epoch 83/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4776 - loss: 1.1298\n",
            "Epoch 84/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4601 - loss: 1.1290\n",
            "Epoch 85/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4633 - loss: 1.1286\n",
            "Epoch 86/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4741 - loss: 1.1449\n",
            "Epoch 87/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4665 - loss: 1.1344\n",
            "Epoch 88/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4649 - loss: 1.1101\n",
            "Epoch 89/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4837 - loss: 1.1113\n",
            "Epoch 90/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4799 - loss: 1.1247\n",
            "Epoch 91/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4573 - loss: 1.1419\n",
            "Epoch 92/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4732 - loss: 1.1391\n",
            "Epoch 93/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4522 - loss: 1.1589\n",
            "Epoch 94/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4526 - loss: 1.1339\n",
            "Epoch 95/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4589 - loss: 1.1451\n",
            "Epoch 96/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4605 - loss: 1.1471\n",
            "Epoch 97/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4680 - loss: 1.1093\n",
            "Epoch 98/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4686 - loss: 1.1289\n",
            "Epoch 99/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4831 - loss: 1.1242\n",
            "Epoch 100/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4819 - loss: 1.1038\n"
          ]
        }
      ],
      "source": [
        "# Reshape input data for LSTM [samples, time steps, features]\n",
        "X_teacher_reshaped = X_teacher.reshape((X_teacher.shape[0], X_teacher.shape[1], 1))\n",
        "\n",
        "teacher_history= teacher_model.fit(X_teacher_reshaped, y_train_one_hot, epochs=100, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jin5ozUtbuXp",
        "outputId": "55314124-5c9f-44d3-e837-c2d7d702c3eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
            "Accuracy: 0.4827\n",
            "F1 Score: 0.3722\n",
            "Confusion Matrix:\n",
            " [[  0  16   0   0]\n",
            " [  0 146   1   4]\n",
            " [  0  87   6  12]\n",
            " [  0  56   3  15]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        16\n",
            "         1.0       0.48      0.97      0.64       151\n",
            "         2.0       0.60      0.06      0.10       105\n",
            "         3.0       0.48      0.20      0.29        74\n",
            "\n",
            "    accuracy                           0.48       346\n",
            "   macro avg       0.39      0.31      0.26       346\n",
            "weighted avg       0.49      0.48      0.37       346\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Make predictions\n",
        "y_pred = teacher_model.predict(X_test_reshaped)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Get the class with the highest probability\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "class_report = classification_report(y_test, y_pred_classes)\n",
        "\n",
        "# Print metrics\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print('Confusion Matrix:\\n', conf_matrix)\n",
        "print('Classification Report:\\n', class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pNmx3sSwLxv"
      },
      "outputs": [],
      "source": [
        "def create_student_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(32, input_shape=input_shape))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "student_model = create_student_model((X_student.shape[1], 1))\n",
        "student_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "V277SZJ9wcEz",
        "outputId": "c7377743-cf5c-4cec-a0e7-4ee1a28892e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8873 - loss: 1.6142\n",
            "Epoch 2/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8524 - loss: 1.4576\n",
            "Epoch 3/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8403 - loss: 1.4239\n",
            "Epoch 4/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8519 - loss: 1.4101\n",
            "Epoch 5/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8289 - loss: 1.4024\n",
            "Epoch 6/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8569 - loss: 1.3961\n",
            "Epoch 7/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8529 - loss: 1.3926\n",
            "Epoch 8/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8517 - loss: 1.3893\n",
            "Epoch 9/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8507 - loss: 1.3872\n",
            "Epoch 10/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8437 - loss: 1.3866\n",
            "Epoch 11/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8490 - loss: 1.3850\n",
            "Epoch 12/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8585 - loss: 1.3834\n",
            "Epoch 13/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8640 - loss: 1.3827\n",
            "Epoch 14/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8548 - loss: 1.3812\n",
            "Epoch 15/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8607 - loss: 1.3802\n",
            "Epoch 16/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8531 - loss: 1.3802\n",
            "Epoch 17/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8552 - loss: 1.3800\n",
            "Epoch 18/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8673 - loss: 1.3792\n",
            "Epoch 19/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8601 - loss: 1.3796\n",
            "Epoch 20/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8739 - loss: 1.3795\n",
            "Epoch 21/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8775 - loss: 1.3781\n",
            "Epoch 22/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8551 - loss: 1.3777\n",
            "Epoch 23/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8547 - loss: 1.3782\n",
            "Epoch 24/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8776 - loss: 1.3776\n",
            "Epoch 25/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8783 - loss: 1.3772\n",
            "Epoch 26/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8810 - loss: 1.3775\n",
            "Epoch 27/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8796 - loss: 1.3773\n",
            "Epoch 28/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8677 - loss: 1.3770\n",
            "Epoch 29/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8673 - loss: 1.3771\n",
            "Epoch 30/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8800 - loss: 1.3765\n",
            "Epoch 31/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8752 - loss: 1.3775\n",
            "Epoch 32/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8992 - loss: 1.3763\n",
            "Epoch 33/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8706 - loss: 1.3768\n",
            "Epoch 34/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8881 - loss: 1.3760\n",
            "Epoch 35/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8760 - loss: 1.3771\n",
            "Epoch 36/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8685 - loss: 1.3772\n",
            "Epoch 37/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8673 - loss: 1.3765\n",
            "Epoch 38/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8773 - loss: 1.3769\n",
            "Epoch 39/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8660 - loss: 1.3773\n",
            "Epoch 40/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8858 - loss: 1.3766\n",
            "Epoch 41/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8867 - loss: 1.3771\n",
            "Epoch 42/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8749 - loss: 1.3765\n",
            "Epoch 43/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8897 - loss: 1.3759\n",
            "Epoch 44/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8838 - loss: 1.3767\n",
            "Epoch 45/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8804 - loss: 1.3764\n",
            "Epoch 46/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8896 - loss: 1.3758\n",
            "Epoch 47/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8785 - loss: 1.3762\n",
            "Epoch 48/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8827 - loss: 1.3765\n",
            "Epoch 49/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8854 - loss: 1.3759\n",
            "Epoch 50/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8881 - loss: 1.3759\n",
            "Epoch 51/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8731 - loss: 1.3758\n",
            "Epoch 52/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9115 - loss: 1.3755\n",
            "Epoch 53/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9068 - loss: 1.3754\n",
            "Epoch 54/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8941 - loss: 1.3755\n",
            "Epoch 55/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8858 - loss: 1.3763\n",
            "Epoch 56/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8912 - loss: 1.3756\n",
            "Epoch 57/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8860 - loss: 1.3756\n",
            "Epoch 58/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8765 - loss: 1.3753\n",
            "Epoch 59/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8977 - loss: 1.3761\n",
            "Epoch 60/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8782 - loss: 1.3761\n",
            "Epoch 61/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8900 - loss: 1.3756\n",
            "Epoch 62/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8872 - loss: 1.3765\n",
            "Epoch 63/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8943 - loss: 1.3755\n",
            "Epoch 64/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8952 - loss: 1.3755\n",
            "Epoch 65/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8972 - loss: 1.3748\n",
            "Epoch 66/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8951 - loss: 1.3748\n",
            "Epoch 67/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9045 - loss: 1.3749\n",
            "Epoch 68/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8908 - loss: 1.3753\n",
            "Epoch 69/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8954 - loss: 1.3757\n",
            "Epoch 70/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8943 - loss: 1.3754\n",
            "Epoch 71/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9104 - loss: 1.3753\n",
            "Epoch 72/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8851 - loss: 1.3756\n",
            "Epoch 73/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8889 - loss: 1.3747\n",
            "Epoch 74/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9128 - loss: 1.3748\n",
            "Epoch 75/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8926 - loss: 1.3753\n",
            "Epoch 76/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8917 - loss: 1.3748\n",
            "Epoch 77/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9092 - loss: 1.3745\n",
            "Epoch 78/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9013 - loss: 1.3751\n",
            "Epoch 79/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8885 - loss: 1.3749\n",
            "Epoch 80/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8880 - loss: 1.3752\n",
            "Epoch 81/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8981 - loss: 1.3753\n",
            "Epoch 82/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9056 - loss: 1.3753\n",
            "Epoch 83/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8989 - loss: 1.3750\n",
            "Epoch 84/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9046 - loss: 1.3749\n",
            "Epoch 85/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8952 - loss: 1.3745\n",
            "Epoch 86/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8851 - loss: 1.3746\n",
            "Epoch 87/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8910 - loss: 1.3754\n",
            "Epoch 88/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8974 - loss: 1.3745\n",
            "Epoch 89/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8973 - loss: 1.3750\n",
            "Epoch 90/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9073 - loss: 1.3750\n",
            "Epoch 91/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8913 - loss: 1.3752\n",
            "Epoch 92/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9007 - loss: 1.3751\n",
            "Epoch 93/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9088 - loss: 1.3739\n",
            "Epoch 94/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9049 - loss: 1.3745\n",
            "Epoch 95/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9040 - loss: 1.3753\n",
            "Epoch 96/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8922 - loss: 1.3747\n",
            "Epoch 97/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8952 - loss: 1.3745\n",
            "Epoch 98/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8871 - loss: 1.3753\n",
            "Epoch 99/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8969 - loss: 1.3750\n",
            "Epoch 100/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8841 - loss: 1.3748\n"
          ]
        }
      ],
      "source": [
        "# Get soft labels from teacher's predictions\n",
        "teacher_predictions = teacher_model.predict(X_teacher_reshaped)\n",
        "soft_labels = tf.nn.softmax(teacher_predictions).numpy()\n",
        "\n",
        "# Train student with soft labels and true labels combined (optional)\n",
        "student_history= student_model.fit(X_student.reshape((X_student.shape[0], X_student.shape[1], 1)),\n",
        "                  soft_labels,\n",
        "                  epochs=100,\n",
        "                  batch_size=32)\n",
        "\n",
        "# Get soft labels from teacher's predictions\n",
        "# teacher_predictions = teacher_model.evaluate(X_teacher.reshape((X_teacher.shape[0], X_teacher.shape[1], 1))) # Reshape X_teacher to match the expected input shape for the LSTM model\n",
        "# soft_labels = tf.nn.softmax(teacher_predictions).numpy()\n",
        "\n",
        "# # Train student with soft labels and true labels combined (optional)\n",
        "# student_model.fit(X_student.reshape((X_student.shape[0], X_student.shape[1], 1)),\n",
        "#                   soft_labels,\n",
        "#                   epochs=50,\n",
        "#                   batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XD1pyslXr-jR",
        "outputId": "c5836a53-fd88-44de-db4e-be63a1a75145"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.20876965 0.28638878 0.25875688 0.24608468]\n",
            " [0.20773788 0.2891073  0.25944337 0.24371144]\n",
            " [0.18373758 0.1900123  0.21558523 0.41066483]\n",
            " ...\n",
            " [0.19995128 0.31788942 0.25400057 0.22815868]\n",
            " [0.1780517  0.45415467 0.18966408 0.17812958]\n",
            " [0.20876965 0.28638878 0.25875688 0.24608468]]\n"
          ]
        }
      ],
      "source": [
        "print(soft_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "id": "v-JqoeV8x82f",
        "outputId": "5a179ac7-fa09-421d-d63a-f0e86a230d37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Accuracy of Student Model: 47.11\n",
            "Testing F1 Score: 34.66\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        16\n",
            "         1.0       0.46      0.97      0.63       151\n",
            "         2.0       1.00      0.03      0.06       105\n",
            "         3.0       0.54      0.18      0.27        74\n",
            "\n",
            "    accuracy                           0.47       346\n",
            "   macro avg       0.50      0.29      0.24       346\n",
            "weighted avg       0.62      0.47      0.35       346\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import seaborn as sns\n",
        "\n",
        "# Prepare test data for student model (only physiological signals)\n",
        "X_test_student = X_test[:, -8:].reshape((X_test.shape[0], -1, 1))\n",
        "\n",
        "# Get predictions from the student model\n",
        "y_pred_prob = student_model.predict(X_test_student)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)*100\n",
        "print(f'Accuracy of Student Model: {accuracy:.2f}')\n",
        "\n",
        "test_f1 = f1_score(y_test, y_pred, average='weighted') * 100\n",
        "print(f\"Testing F1 Score: {test_f1:.2f}\")\n",
        "\n",
        "# Generate classification report\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", class_report)\n",
        "\n",
        "# Create confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plotting confusion matrix using seaborn heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Relax', 'Low Fear', 'Medium Fear', 'High Fear'],\n",
        "            yticklabels=['Relax', 'Low Fear', 'Medium Fear', 'High Fear'])\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMsLlEEQtLM6",
        "outputId": "792ca1db-c94c-454b-9915-82d1fa71030f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Reshape student data for LSTM input (batch_size, time_steps, features)\n",
        "X_student_reshaped = X_student.reshape((X_student.shape[0], X_student.shape[1], 1))\n",
        "\n",
        "# Create and compile student model\n",
        "student_model = create_student_model((X_student.shape[1], 1))  # (8 time steps, 1 feature)\n",
        "student_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PigIPdqmrVlr",
        "outputId": "105e6502-05e3-4927-c752-40f81a685b8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - accuracy: 0.2488 - loss: 1.4704 - val_accuracy: 0.4855 - val_loss: 1.3100\n",
            "Epoch 2/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.3736 - loss: 1.3405 - val_accuracy: 0.4538 - val_loss: 1.2647\n",
            "Epoch 3/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3986 - loss: 1.2829 - val_accuracy: 0.4653 - val_loss: 1.2291\n",
            "Epoch 4/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3897 - loss: 1.2828 - val_accuracy: 0.4509 - val_loss: 1.2186\n",
            "Epoch 5/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.3656 - loss: 1.2727 - val_accuracy: 0.4566 - val_loss: 1.2093\n",
            "Epoch 6/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.3867 - loss: 1.2523 - val_accuracy: 0.4566 - val_loss: 1.2034\n",
            "Epoch 7/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4181 - loss: 1.2292 - val_accuracy: 0.4913 - val_loss: 1.1906\n",
            "Epoch 8/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4173 - loss: 1.2244 - val_accuracy: 0.4769 - val_loss: 1.1800\n",
            "Epoch 9/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4044 - loss: 1.2237 - val_accuracy: 0.4740 - val_loss: 1.1791\n",
            "Epoch 10/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4144 - loss: 1.2155 - val_accuracy: 0.4769 - val_loss: 1.1757\n",
            "Epoch 11/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4079 - loss: 1.2317 - val_accuracy: 0.4682 - val_loss: 1.1840\n",
            "Epoch 12/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4165 - loss: 1.2049 - val_accuracy: 0.4711 - val_loss: 1.1731\n",
            "Epoch 13/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4017 - loss: 1.2391 - val_accuracy: 0.4740 - val_loss: 1.1738\n",
            "Epoch 14/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4220 - loss: 1.2180 - val_accuracy: 0.4711 - val_loss: 1.1712\n",
            "Epoch 15/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4190 - loss: 1.2243 - val_accuracy: 0.4624 - val_loss: 1.1710\n",
            "Epoch 16/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4240 - loss: 1.2200 - val_accuracy: 0.4624 - val_loss: 1.1665\n",
            "Epoch 17/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4240 - loss: 1.2280 - val_accuracy: 0.4595 - val_loss: 1.1685\n",
            "Epoch 18/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4356 - loss: 1.2054 - val_accuracy: 0.4624 - val_loss: 1.1649\n",
            "Epoch 19/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4403 - loss: 1.2012 - val_accuracy: 0.4682 - val_loss: 1.1666\n",
            "Epoch 20/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4311 - loss: 1.2062 - val_accuracy: 0.4682 - val_loss: 1.1645\n",
            "Epoch 21/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4089 - loss: 1.2044 - val_accuracy: 0.4711 - val_loss: 1.1582\n",
            "Epoch 22/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4216 - loss: 1.1874 - val_accuracy: 0.4653 - val_loss: 1.1608\n",
            "Epoch 23/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4400 - loss: 1.2252 - val_accuracy: 0.4682 - val_loss: 1.1613\n",
            "Epoch 24/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4268 - loss: 1.2160 - val_accuracy: 0.4682 - val_loss: 1.1604\n",
            "Epoch 25/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4231 - loss: 1.2209 - val_accuracy: 0.4711 - val_loss: 1.1624\n",
            "Epoch 26/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4402 - loss: 1.1816 - val_accuracy: 0.4740 - val_loss: 1.1584\n",
            "Epoch 27/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4384 - loss: 1.1780 - val_accuracy: 0.4682 - val_loss: 1.1569\n",
            "Epoch 28/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4428 - loss: 1.1694 - val_accuracy: 0.4653 - val_loss: 1.1570\n",
            "Epoch 29/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4426 - loss: 1.1851 - val_accuracy: 0.4682 - val_loss: 1.1534\n",
            "Epoch 30/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4105 - loss: 1.2106 - val_accuracy: 0.4624 - val_loss: 1.1534\n",
            "Epoch 31/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4510 - loss: 1.1633 - val_accuracy: 0.4682 - val_loss: 1.1518\n",
            "Epoch 32/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4367 - loss: 1.1726 - val_accuracy: 0.4653 - val_loss: 1.1509\n",
            "Epoch 33/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4086 - loss: 1.2170 - val_accuracy: 0.4711 - val_loss: 1.1493\n",
            "Epoch 34/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4394 - loss: 1.1809 - val_accuracy: 0.4711 - val_loss: 1.1490\n",
            "Epoch 35/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4496 - loss: 1.1975 - val_accuracy: 0.4682 - val_loss: 1.1527\n",
            "Epoch 36/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4579 - loss: 1.1655 - val_accuracy: 0.4682 - val_loss: 1.1501\n",
            "Epoch 37/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4362 - loss: 1.1741 - val_accuracy: 0.4653 - val_loss: 1.1476\n",
            "Epoch 38/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4308 - loss: 1.1841 - val_accuracy: 0.4740 - val_loss: 1.1460\n",
            "Epoch 39/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4649 - loss: 1.1611 - val_accuracy: 0.4769 - val_loss: 1.1460\n",
            "Epoch 40/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4398 - loss: 1.1994 - val_accuracy: 0.4711 - val_loss: 1.1465\n",
            "Epoch 41/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4539 - loss: 1.1797 - val_accuracy: 0.4769 - val_loss: 1.1450\n",
            "Epoch 42/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4249 - loss: 1.2106 - val_accuracy: 0.4769 - val_loss: 1.1434\n",
            "Epoch 43/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4352 - loss: 1.1804 - val_accuracy: 0.4711 - val_loss: 1.1437\n",
            "Epoch 44/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4509 - loss: 1.1713 - val_accuracy: 0.4711 - val_loss: 1.1417\n",
            "Epoch 45/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4657 - loss: 1.1607 - val_accuracy: 0.4740 - val_loss: 1.1401\n",
            "Epoch 46/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4521 - loss: 1.1642 - val_accuracy: 0.4711 - val_loss: 1.1399\n",
            "Epoch 47/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4660 - loss: 1.1583 - val_accuracy: 0.4769 - val_loss: 1.1385\n",
            "Epoch 48/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4390 - loss: 1.1630 - val_accuracy: 0.4769 - val_loss: 1.1375\n",
            "Epoch 49/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4616 - loss: 1.1660 - val_accuracy: 0.4798 - val_loss: 1.1339\n",
            "Epoch 50/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4507 - loss: 1.1720 - val_accuracy: 0.4827 - val_loss: 1.1343\n",
            "Epoch 51/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4269 - loss: 1.1923 - val_accuracy: 0.4740 - val_loss: 1.1365\n",
            "Epoch 52/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4384 - loss: 1.1590 - val_accuracy: 0.4798 - val_loss: 1.1364\n",
            "Epoch 53/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4547 - loss: 1.1568 - val_accuracy: 0.4740 - val_loss: 1.1402\n",
            "Epoch 54/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4539 - loss: 1.1581 - val_accuracy: 0.4827 - val_loss: 1.1411\n",
            "Epoch 55/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4540 - loss: 1.1564 - val_accuracy: 0.4769 - val_loss: 1.1383\n",
            "Epoch 56/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4532 - loss: 1.1623 - val_accuracy: 0.4769 - val_loss: 1.1379\n",
            "Epoch 57/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4401 - loss: 1.1578 - val_accuracy: 0.4769 - val_loss: 1.1366\n",
            "Epoch 58/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4592 - loss: 1.1391 - val_accuracy: 0.4798 - val_loss: 1.1328\n",
            "Epoch 59/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4505 - loss: 1.1646 - val_accuracy: 0.4740 - val_loss: 1.1312\n",
            "Epoch 60/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4597 - loss: 1.1610 - val_accuracy: 0.4827 - val_loss: 1.1338\n",
            "Epoch 61/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4231 - loss: 1.1754 - val_accuracy: 0.4798 - val_loss: 1.1318\n",
            "Epoch 62/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4600 - loss: 1.1363 - val_accuracy: 0.4855 - val_loss: 1.1303\n",
            "Epoch 63/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4552 - loss: 1.1623 - val_accuracy: 0.4884 - val_loss: 1.1345\n",
            "Epoch 64/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4610 - loss: 1.1527 - val_accuracy: 0.4769 - val_loss: 1.1295\n",
            "Epoch 65/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4841 - loss: 1.1478 - val_accuracy: 0.4855 - val_loss: 1.1306\n",
            "Epoch 66/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4332 - loss: 1.1762 - val_accuracy: 0.4798 - val_loss: 1.1366\n",
            "Epoch 67/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4444 - loss: 1.1547 - val_accuracy: 0.4855 - val_loss: 1.1320\n",
            "Epoch 68/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4557 - loss: 1.1484 - val_accuracy: 0.4798 - val_loss: 1.1352\n",
            "Epoch 69/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4187 - loss: 1.1859 - val_accuracy: 0.4884 - val_loss: 1.1371\n",
            "Epoch 70/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4455 - loss: 1.1817 - val_accuracy: 0.4913 - val_loss: 1.1324\n",
            "Epoch 71/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4432 - loss: 1.1604 - val_accuracy: 0.4798 - val_loss: 1.1341\n",
            "Epoch 72/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4559 - loss: 1.1506 - val_accuracy: 0.4798 - val_loss: 1.1324\n",
            "Epoch 73/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4562 - loss: 1.1621 - val_accuracy: 0.4827 - val_loss: 1.1308\n",
            "Epoch 74/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4445 - loss: 1.1530 - val_accuracy: 0.4798 - val_loss: 1.1314\n",
            "Epoch 75/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4541 - loss: 1.1678 - val_accuracy: 0.4798 - val_loss: 1.1294\n",
            "Epoch 76/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4674 - loss: 1.1235 - val_accuracy: 0.4682 - val_loss: 1.1333\n",
            "Epoch 77/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4530 - loss: 1.1378 - val_accuracy: 0.4884 - val_loss: 1.1287\n",
            "Epoch 78/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4520 - loss: 1.1653 - val_accuracy: 0.4884 - val_loss: 1.1318\n",
            "Epoch 79/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4467 - loss: 1.1639 - val_accuracy: 0.4769 - val_loss: 1.1300\n",
            "Epoch 80/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4483 - loss: 1.1470 - val_accuracy: 0.4855 - val_loss: 1.1354\n",
            "Epoch 81/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4528 - loss: 1.1679 - val_accuracy: 0.4769 - val_loss: 1.1261\n",
            "Epoch 82/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4465 - loss: 1.1356 - val_accuracy: 0.4798 - val_loss: 1.1241\n",
            "Epoch 83/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4778 - loss: 1.1207 - val_accuracy: 0.4855 - val_loss: 1.1167\n",
            "Epoch 84/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4735 - loss: 1.1205 - val_accuracy: 0.4827 - val_loss: 1.1191\n",
            "Epoch 85/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4599 - loss: 1.1364 - val_accuracy: 0.4740 - val_loss: 1.1200\n",
            "Epoch 86/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4630 - loss: 1.1541 - val_accuracy: 0.4942 - val_loss: 1.1210\n",
            "Epoch 87/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4513 - loss: 1.1296 - val_accuracy: 0.4913 - val_loss: 1.1176\n",
            "Epoch 88/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4759 - loss: 1.1182 - val_accuracy: 0.4827 - val_loss: 1.1236\n",
            "Epoch 89/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4812 - loss: 1.1061 - val_accuracy: 0.4855 - val_loss: 1.1285\n",
            "Epoch 90/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4743 - loss: 1.1402 - val_accuracy: 0.4711 - val_loss: 1.1263\n",
            "Epoch 91/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4566 - loss: 1.1491 - val_accuracy: 0.4682 - val_loss: 1.1239\n",
            "Epoch 92/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4814 - loss: 1.1313 - val_accuracy: 0.4711 - val_loss: 1.1204\n",
            "Epoch 93/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4663 - loss: 1.1369 - val_accuracy: 0.4798 - val_loss: 1.1264\n",
            "Epoch 94/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4515 - loss: 1.1684 - val_accuracy: 0.4827 - val_loss: 1.1239\n",
            "Epoch 95/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4659 - loss: 1.1334 - val_accuracy: 0.4827 - val_loss: 1.1206\n",
            "Epoch 96/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4711 - loss: 1.1300 - val_accuracy: 0.4798 - val_loss: 1.1174\n",
            "Epoch 97/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4426 - loss: 1.1752 - val_accuracy: 0.4827 - val_loss: 1.1138\n",
            "Epoch 98/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4675 - loss: 1.1291 - val_accuracy: 0.4827 - val_loss: 1.1113\n",
            "Epoch 99/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4662 - loss: 1.1424 - val_accuracy: 0.4769 - val_loss: 1.1178\n",
            "Epoch 100/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4718 - loss: 1.1259 - val_accuracy: 0.4884 - val_loss: 1.1197\n"
          ]
        }
      ],
      "source": [
        "# def create_student_model(input_shape):\n",
        "#     model = Sequential()\n",
        "#     model.add(LSTM(32, input_shape=input_shape))  # LSTM layer\n",
        "#     model.add(Dropout(0.5))  # Dropout layer for regularization\n",
        "#     model.add(Dense(16, activation='relu'))  # Dense layer\n",
        "#     model.add(Dropout(0.5))  # Another Dropout layer\n",
        "#     model.add(Dense(4, activation='softmax'))  # Output layer for 4 classes\n",
        "#     return model\n",
        "\n",
        "# without KD\n",
        "\n",
        "# Train the student model with ground tru labels\n",
        "temp_history= student_model.fit(X_student_reshaped, y_train_one_hot, epochs=100, batch_size=32, validation_data=(X_test[:, -8:].reshape((X_test.shape[0], 8, 1)), y_test_one_hot))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXEbX7fjtZwC",
        "outputId": "e12ab473-2018-440a-9035-a1d2b0fb6152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Accuracy of Student Model: 48.84\n",
            "F1-score of Student Model: 39.71\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        16\n",
            "         1.0       0.48      0.94      0.63       151\n",
            "         2.0       0.63      0.11      0.19       105\n",
            "         3.0       0.52      0.20      0.29        74\n",
            "\n",
            "    accuracy                           0.49       346\n",
            "   macro avg       0.41      0.31      0.28       346\n",
            "weighted avg       0.51      0.49      0.40       346\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import seaborn as sns\n",
        "\n",
        "# Prepare test data for student model (only physiological signals)\n",
        "X_test_student = X_test[:, -8:].reshape((X_test.shape[0], -1, 1))\n",
        "\n",
        "# Get predictions from the student model\n",
        "y_pred_prob = student_model.predict(X_test_student)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)*100\n",
        "print(f'Accuracy of Student Model: {accuracy:.2f}')\n",
        "\n",
        "test_f1 = f1_score(y_test, y_pred, average='weighted') * 100\n",
        "print(f'F1-score of Student Model: {test_f1:.2f}')\n",
        "\n",
        "# Generate classification report\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", class_report)\n",
        "\n",
        "# # Create confusion matrix\n",
        "# conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# # Plotting confusion matrix using seaborn heatmap\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "#             xticklabels=['Relax', 'Low Fear', 'Medium Fear', 'High Fear'],\n",
        "#             yticklabels=['Relax', 'Low Fear', 'Medium Fear', 'High Fear'])\n",
        "# plt.ylabel('Actual')\n",
        "# plt.xlabel('Predicted')\n",
        "# plt.title('Confusion Matrix')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDMk6vdjF_DV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss(teacher_history, student_history, temp_history):\n",
        "    # Extract loss for each model\n",
        "    teacher_loss = teacher_history.history['loss']\n",
        "    student_loss = student_history.history['loss']\n",
        "    temp_loss = temp_history.history['loss']\n",
        "\n",
        "    # Define the range of epochs\n",
        "    teacher_epochs = range(len(teacher_loss))\n",
        "    student_epochs = range(len(student_loss))\n",
        "    temp_epochs = range(len(temp_loss))\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Plot teacher model loss\n",
        "    plt.plot(teacher_epochs, teacher_loss, label='Teacher Model Loss', color='blue')\n",
        "\n",
        "    # Plot student model loss (trained with soft targets)\n",
        "    plt.plot(student_epochs, student_loss, label='Student Model Loss (Soft Targets)', color='green')\n",
        "\n",
        "    # Plot temp student model loss (trained directly with 8 physiological signals)\n",
        "    plt.plot(temp_epochs, temp_loss, label='Student Model Loss (8 Signals)', color='red')\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.title('Epochs vs Loss for Teacher and Student Models')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Call the plotting function\n",
        "plot_loss(teacher_history, student_history, temp_history)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UVLxOwtGvlV"
      },
      "outputs": [],
      "source": [
        "# Function to plot accuracy over epochs\n",
        "def plot_accuracy(teacher_history, student_history, temp_history):\n",
        "    # Get accuracy from each model's history\n",
        "    teacher_acc = teacher_history.history['accuracy']\n",
        "    student_acc = student_history.history['accuracy']\n",
        "    temp_acc = temp_history.history['accuracy']\n",
        "\n",
        "    # Get the number of epochs\n",
        "    epochs = range(1, len(teacher_acc) + 1)\n",
        "\n",
        "    # Plot the accuracy over epochs for each model\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    plt.plot(epochs, teacher_acc, 'b-', label='Teacher Model Accuracy')\n",
        "    plt.plot(epochs, student_acc, 'g-', label='Student Model (Distillation) Accuracy')\n",
        "    plt.plot(epochs, temp_acc, 'r-', label='Student Model (No Distillation) Accuracy')\n",
        "\n",
        "    # Add title and labels\n",
        "    plt.title('Accuracy over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "\n",
        "    # Display the legend\n",
        "    plt.legend()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Assuming you have already captured the history objects:\n",
        "# teacher_history, student_history, temp_history\n",
        "plot_accuracy(teacher_history, student_history, temp_history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(teacher_model.summary())\n",
        "print(student_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "E6qLsffLI9N7",
        "outputId": "fe003da7-ffa2-4909-cc55-cf6f0fee4ea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m16,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │              \u001b[38;5;34m68\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,572\u001b[0m (76.45 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,572</span> (76.45 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,572\u001b[0m (76.45 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,572</span> (76.45 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m4,352\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │              \u001b[38;5;34m68\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,948\u001b[0m (19.33 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,948</span> (19.33 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,948\u001b[0m (19.33 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,948</span> (19.33 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gq-Qkhk09po"
      },
      "source": [
        "### Using Temporal CNN\n",
        "\n",
        "<p>Teacher model with 40 channels: accuracy- 92.49, f1 score - 92.45</p>\n",
        "<p>student model with 40 channels and KD: accuracy - 93.35, f1 score - 93.35</p>\n",
        "<p>student model with 40 channels and without KD: accuracy - 92.77, f1 score - 92.76</p>\n",
        "\n",
        "<p>student model with 8 channels and KD: accuracy - 76.01, f1 score - 76.02</p>\n",
        "<p>student model with 8 channels and without KD: accuracy - 79.19, f1 score - 79.08</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZAvaLXAmu6s"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, Dense, Flatten, InputLayer\n",
        "from keras.utils import to_categorical\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.models import Sequential\n",
        "from keras.layers import InputLayer, Conv1D, Flatten, Dense\n",
        "from keras.callbacks import Callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VY2SXwgNmyro"
      },
      "outputs": [],
      "source": [
        "# Custom transformer to flatten the input data\n",
        "class FlattenTransformer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Define your TCN-like model using Conv1D layers\n",
        "def create_tcn_model():\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer(input_shape=(40, 1)))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, dilation_rate=1, activation='relu'))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, dilation_rate=2, activation='relu'))\n",
        "    # model.add(Conv1D(filters=64, kernel_size=3, dilation_rate=4, activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(4, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iqOxouQJmlRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ff47e89-5d83-4fec-c26f-41728f20ad95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4543 - loss: 1.2016\n",
            "Epoch 2/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6355 - loss: 0.8362\n",
            "Epoch 3/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7535 - loss: 0.6192\n",
            "Epoch 4/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8196 - loss: 0.4756\n",
            "Epoch 5/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8542 - loss: 0.4461\n",
            "Epoch 6/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8820 - loss: 0.3244\n",
            "Epoch 7/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8819 - loss: 0.3263\n",
            "Epoch 8/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9098 - loss: 0.2738\n",
            "Epoch 9/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9277 - loss: 0.2402\n",
            "Epoch 10/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9338 - loss: 0.2096\n",
            "Epoch 11/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9061 - loss: 0.2609\n",
            "Epoch 12/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9634 - loss: 0.1324\n",
            "Epoch 13/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9655 - loss: 0.1226\n",
            "Epoch 14/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9665 - loss: 0.1228\n",
            "Epoch 15/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9790 - loss: 0.0869\n",
            "Epoch 16/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9844 - loss: 0.0856\n",
            "Epoch 17/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9888 - loss: 0.0614\n",
            "Epoch 18/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9725 - loss: 0.0975\n",
            "Epoch 19/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9769 - loss: 0.0843\n",
            "Epoch 20/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9767 - loss: 0.1106\n",
            "Epoch 21/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9916 - loss: 0.0463\n",
            "Epoch 22/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9960 - loss: 0.0325\n",
            "Epoch 23/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9933 - loss: 0.0329\n",
            "Epoch 24/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9948 - loss: 0.0209\n",
            "Epoch 25/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9921 - loss: 0.0259\n",
            "Epoch 26/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9967 - loss: 0.0196\n",
            "Epoch 27/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0130\n",
            "Epoch 28/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9950 - loss: 0.0412\n",
            "Epoch 29/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0114\n",
            "Epoch 30/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0214\n",
            "Epoch 31/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0086\n",
            "Epoch 32/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9973 - loss: 0.0147\n",
            "Epoch 33/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0322\n",
            "Epoch 34/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9983 - loss: 0.0113\n",
            "Epoch 35/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9948 - loss: 0.0371\n",
            "Epoch 36/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0069\n",
            "Epoch 37/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0257\n",
            "Epoch 38/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 0.0065\n",
            "Epoch 39/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0093\n",
            "Epoch 40/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9997 - loss: 0.0064\n",
            "Epoch 41/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9981 - loss: 0.0053\n",
            "Epoch 42/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9998 - loss: 0.0032\n",
            "Epoch 43/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9988 - loss: 0.0048\n",
            "Epoch 44/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0019\n",
            "Epoch 45/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 46/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0022\n",
            "Epoch 47/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 48/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 49/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9975 - loss: 0.0054\n",
            "Epoch 50/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.5981e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.8997e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.9630e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.2376e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.1224e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.0099e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.3533e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.1843e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.5253e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.1182e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m55/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.1404e-04"
          ]
        }
      ],
      "source": [
        "# Define the pipeline with flattening and scaling\n",
        "pipeline_teacher = Pipeline([\n",
        "    ('flatten', FlattenTransformer()),\n",
        "    ('standardize', StandardScaler()),\n",
        "    ('tcn', KerasClassifier(model=create_tcn_model(), epochs=100, batch_size=20, verbose=1))\n",
        "])\n",
        "\n",
        "y_encoded = to_categorical(y_train)\n",
        "y_encoded_test = to_categorical(y_test)\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline_teacher.fit(X_train, y_encoded)\n",
        "\n",
        "# 70/70 ━━━━━━━━━━━━━━━━━━━━ 1s 7ms/step\n",
        "# Training Accuracy: 100.00%\n",
        "# Training F1 Score: 100.00\n",
        "# Training Recall Score: 1.00\n",
        "# Training Precision Score: 1.00\n",
        "# 18/18 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step\n",
        "# Testing Accuracy: 92.49%\n",
        "# Testing F1 Score: 92.45\n",
        "# Testing Recall Score: 0.92\n",
        "# Testing Precision Score: 0.93"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZn0bUKkv9bO",
        "outputId": "54a39792-4c1a-4a52-a7a6-bd80151a9119",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4593 - loss: 1.1921\n",
            "Epoch 2/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6731 - loss: 0.8242\n",
            "Epoch 3/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7764 - loss: 0.6306\n",
            "Epoch 4/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8133 - loss: 0.5043\n",
            "Epoch 5/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8384 - loss: 0.4486\n",
            "Epoch 6/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8723 - loss: 0.3802\n",
            "Epoch 7/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8980 - loss: 0.3058\n",
            "Epoch 8/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9324 - loss: 0.2486\n",
            "Epoch 9/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9343 - loss: 0.2157\n",
            "Epoch 10/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9261 - loss: 0.2334\n",
            "Epoch 11/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9682 - loss: 0.1337\n",
            "Epoch 12/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9645 - loss: 0.1376\n",
            "Epoch 13/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9706 - loss: 0.1161\n",
            "Epoch 14/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9652 - loss: 0.1243\n",
            "Epoch 15/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9554 - loss: 0.1213\n",
            "Epoch 16/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9636 - loss: 0.1593\n",
            "Epoch 17/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9730 - loss: 0.1048\n",
            "Epoch 18/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9868 - loss: 0.0557\n",
            "Epoch 19/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9914 - loss: 0.0518\n",
            "Epoch 20/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9917 - loss: 0.0464\n",
            "Epoch 21/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9882 - loss: 0.0571\n",
            "Epoch 22/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.9846 - loss: 0.0534\n",
            "Epoch 23/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9946 - loss: 0.0242\n",
            "Epoch 24/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9980 - loss: 0.0246\n",
            "Epoch 25/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9917 - loss: 0.0358\n",
            "Epoch 26/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9945 - loss: 0.0341\n",
            "Epoch 27/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9990 - loss: 0.0118\n",
            "Epoch 28/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9986 - loss: 0.0196\n",
            "Epoch 29/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9980 - loss: 0.0102\n",
            "Epoch 30/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9925 - loss: 0.0344\n",
            "Epoch 31/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9977 - loss: 0.0165\n",
            "Epoch 32/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9977 - loss: 0.0089\n",
            "Epoch 33/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9915 - loss: 0.0297\n",
            "Epoch 34/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9860 - loss: 0.0303\n",
            "Epoch 35/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9847 - loss: 0.0896\n",
            "Epoch 36/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9941 - loss: 0.0332\n",
            "Epoch 37/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0079\n",
            "Epoch 38/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 0.0069\n",
            "Epoch 39/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 0.0040\n",
            "Epoch 40/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0044\n",
            "Epoch 41/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 0.0054\n",
            "Epoch 42/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0025\n",
            "Epoch 43/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9996 - loss: 0.0031\n",
            "Epoch 44/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9990 - loss: 0.0050\n",
            "Epoch 45/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9956 - loss: 0.0077\n",
            "Epoch 46/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9998 - loss: 0.0017\n",
            "Epoch 47/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9970 - loss: 0.0069\n",
            "Epoch 48/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9974 - loss: 0.0063\n",
            "Epoch 49/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0015\n",
            "Epoch 50/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0022\n",
            "Epoch 51/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0022\n",
            "Epoch 52/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0135\n",
            "Epoch 53/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9952 - loss: 0.0136\n",
            "Epoch 54/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 0.0044\n",
            "Epoch 55/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0019\n",
            "Epoch 56/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9988 - loss: 0.0038\n",
            "Epoch 57/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0010\n",
            "Epoch 58/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.2033e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 7.1752e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.9937e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 5.1929e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.9792e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.0729e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.3009e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.6579e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.0032e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.1018e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.3252e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.1454e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.1542e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.7528e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.9341e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.6989e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.2581e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.8459e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.0118e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.1805e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.7989e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.8627e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.6476e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.4885e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4088e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 1.6247e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.1536e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.3454e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.2483e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.1321e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.0919e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.0893e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.4892e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.6871e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.0332e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.4214e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.8776e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.3393e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 7.1983e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 9.1057e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 7.0949e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 7.1548e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.4010e-05\n",
            "[{'epoch': 1, 'loss': 1.0775244235992432, 'accuracy': 0.5166425704956055}, {'epoch': 2, 'loss': 0.8016680479049683, 'accuracy': 0.6780028939247131}, {'epoch': 3, 'loss': 0.6272016763687134, 'accuracy': 0.756150484085083}, {'epoch': 4, 'loss': 0.492581307888031, 'accuracy': 0.8140376210212708}, {'epoch': 5, 'loss': 0.44046205282211304, 'accuracy': 0.8364688754081726}, {'epoch': 6, 'loss': 0.3721173107624054, 'accuracy': 0.870477557182312}, {'epoch': 7, 'loss': 0.3085813522338867, 'accuracy': 0.8972503542900085}, {'epoch': 8, 'loss': 0.2585539221763611, 'accuracy': 0.9182344675064087}, {'epoch': 9, 'loss': 0.21198022365570068, 'accuracy': 0.9327062368392944}, {'epoch': 10, 'loss': 0.21477697789669037, 'accuracy': 0.9370477795600891}, {'epoch': 11, 'loss': 0.14739854633808136, 'accuracy': 0.959479033946991}, {'epoch': 12, 'loss': 0.17009542882442474, 'accuracy': 0.9645441174507141}, {'epoch': 13, 'loss': 0.1190955638885498, 'accuracy': 0.9703328609466553}, {'epoch': 14, 'loss': 0.1032286137342453, 'accuracy': 0.9732272028923035}, {'epoch': 15, 'loss': 0.13944634795188904, 'accuracy': 0.9573082327842712}, {'epoch': 16, 'loss': 0.1589026153087616, 'accuracy': 0.9688856601715088}, {'epoch': 17, 'loss': 0.08247721940279007, 'accuracy': 0.9804630875587463}, {'epoch': 18, 'loss': 0.0568736307322979, 'accuracy': 0.9862518310546875}, {'epoch': 19, 'loss': 0.05683840811252594, 'accuracy': 0.9905933141708374}, {'epoch': 20, 'loss': 0.04920695722103119, 'accuracy': 0.9884225726127625}, {'epoch': 21, 'loss': 0.05253283679485321, 'accuracy': 0.9876989722251892}, {'epoch': 22, 'loss': 0.05168723315000534, 'accuracy': 0.9862518310546875}, {'epoch': 23, 'loss': 0.03279091417789459, 'accuracy': 0.9920405149459839}, {'epoch': 24, 'loss': 0.027843354269862175, 'accuracy': 0.9963820576667786}, {'epoch': 25, 'loss': 0.03443572670221329, 'accuracy': 0.9920405149459839}, {'epoch': 26, 'loss': 0.022354060783982277, 'accuracy': 0.9963820576667786}, {'epoch': 27, 'loss': 0.015082393772900105, 'accuracy': 0.9971056580543518}, {'epoch': 28, 'loss': 0.015553265810012817, 'accuracy': 0.997829258441925}, {'epoch': 29, 'loss': 0.014660932123661041, 'accuracy': 0.9971056580543518}, {'epoch': 30, 'loss': 0.03449113667011261, 'accuracy': 0.9927641153335571}, {'epoch': 31, 'loss': 0.014882436953485012, 'accuracy': 0.997829258441925}, {'epoch': 32, 'loss': 0.01882060244679451, 'accuracy': 0.9956584572792053}, {'epoch': 33, 'loss': 0.03919650614261627, 'accuracy': 0.9898697733879089}, {'epoch': 34, 'loss': 0.03985263779759407, 'accuracy': 0.9840810298919678}, {'epoch': 35, 'loss': 0.08692922443151474, 'accuracy': 0.9826338887214661}, {'epoch': 36, 'loss': 0.026679575443267822, 'accuracy': 0.9956584572792053}, {'epoch': 37, 'loss': 0.0074592637829482555, 'accuracy': 0.9992763996124268}, {'epoch': 38, 'loss': 0.006466477643698454, 'accuracy': 0.9992763996124268}, {'epoch': 39, 'loss': 0.005158718675374985, 'accuracy': 0.9992763996124268}, {'epoch': 40, 'loss': 0.006530844606459141, 'accuracy': 0.9985527992248535}, {'epoch': 41, 'loss': 0.005598179530352354, 'accuracy': 0.9985527992248535}, {'epoch': 42, 'loss': 0.003538701683282852, 'accuracy': 0.9992763996124268}, {'epoch': 43, 'loss': 0.002915934892371297, 'accuracy': 0.9992763996124268}, {'epoch': 44, 'loss': 0.004288402386009693, 'accuracy': 0.9992763996124268}, {'epoch': 45, 'loss': 0.004466059617698193, 'accuracy': 0.9985527992248535}, {'epoch': 46, 'loss': 0.0030018072575330734, 'accuracy': 0.9992763996124268}, {'epoch': 47, 'loss': 0.008219322189688683, 'accuracy': 0.9971056580543518}, {'epoch': 48, 'loss': 0.006514715030789375, 'accuracy': 0.997829258441925}, {'epoch': 49, 'loss': 0.0020777133759111166, 'accuracy': 0.9992763996124268}, {'epoch': 50, 'loss': 0.0031174668110907078, 'accuracy': 0.9992763996124268}, {'epoch': 51, 'loss': 0.003271728754043579, 'accuracy': 0.9992763996124268}, {'epoch': 52, 'loss': 0.011900718323886395, 'accuracy': 0.9985527992248535}, {'epoch': 53, 'loss': 0.008302816189825535, 'accuracy': 0.997829258441925}, {'epoch': 54, 'loss': 0.008662356995046139, 'accuracy': 0.9985527992248535}, {'epoch': 55, 'loss': 0.0018226985121145844, 'accuracy': 1.0}, {'epoch': 56, 'loss': 0.0027894864324480295, 'accuracy': 0.9992763996124268}, {'epoch': 57, 'loss': 0.0010715721873566508, 'accuracy': 1.0}, {'epoch': 58, 'loss': 0.0008377257618121803, 'accuracy': 1.0}, {'epoch': 59, 'loss': 0.0007575505296699703, 'accuracy': 1.0}, {'epoch': 60, 'loss': 0.0006399898556992412, 'accuracy': 1.0}, {'epoch': 61, 'loss': 0.0005603765021078289, 'accuracy': 1.0}, {'epoch': 62, 'loss': 0.0005148709751665592, 'accuracy': 1.0}, {'epoch': 63, 'loss': 0.0004915485624223948, 'accuracy': 1.0}, {'epoch': 64, 'loss': 0.0004436693270690739, 'accuracy': 1.0}, {'epoch': 65, 'loss': 0.00040311712655238807, 'accuracy': 1.0}, {'epoch': 66, 'loss': 0.0003778906539082527, 'accuracy': 1.0}, {'epoch': 67, 'loss': 0.0003475987759884447, 'accuracy': 1.0}, {'epoch': 68, 'loss': 0.0003315272624604404, 'accuracy': 1.0}, {'epoch': 69, 'loss': 0.0003043760370928794, 'accuracy': 1.0}, {'epoch': 70, 'loss': 0.0002988132182508707, 'accuracy': 1.0}, {'epoch': 71, 'loss': 0.0002724410151131451, 'accuracy': 1.0}, {'epoch': 72, 'loss': 0.0003132145793642849, 'accuracy': 1.0}, {'epoch': 73, 'loss': 0.00041218215483240783, 'accuracy': 1.0}, {'epoch': 74, 'loss': 0.0002536768151912838, 'accuracy': 1.0}, {'epoch': 75, 'loss': 0.00023059411614667624, 'accuracy': 1.0}, {'epoch': 76, 'loss': 0.0002117434050887823, 'accuracy': 1.0}, {'epoch': 77, 'loss': 0.0001937403721967712, 'accuracy': 1.0}, {'epoch': 78, 'loss': 0.0001851809793151915, 'accuracy': 1.0}, {'epoch': 79, 'loss': 0.00017686080536805093, 'accuracy': 1.0}, {'epoch': 80, 'loss': 0.00016740952560212463, 'accuracy': 1.0}, {'epoch': 81, 'loss': 0.00016356840205844492, 'accuracy': 1.0}, {'epoch': 82, 'loss': 0.00014991643547546118, 'accuracy': 1.0}, {'epoch': 83, 'loss': 0.00014397532504517585, 'accuracy': 1.0}, {'epoch': 84, 'loss': 0.00013782661699224263, 'accuracy': 1.0}, {'epoch': 85, 'loss': 0.00012957799481227994, 'accuracy': 1.0}, {'epoch': 86, 'loss': 0.0001198331083287485, 'accuracy': 1.0}, {'epoch': 87, 'loss': 0.00011718689347617328, 'accuracy': 1.0}, {'epoch': 88, 'loss': 0.00011197457206435502, 'accuracy': 1.0}, {'epoch': 89, 'loss': 0.0001049121783580631, 'accuracy': 1.0}, {'epoch': 90, 'loss': 0.00010189263412030414, 'accuracy': 1.0}, {'epoch': 91, 'loss': 9.864156891126186e-05, 'accuracy': 1.0}, {'epoch': 92, 'loss': 9.240037616109475e-05, 'accuracy': 1.0}, {'epoch': 93, 'loss': 8.934202924137935e-05, 'accuracy': 1.0}, {'epoch': 94, 'loss': 8.408806752413511e-05, 'accuracy': 1.0}, {'epoch': 95, 'loss': 8.035514474613592e-05, 'accuracy': 1.0}, {'epoch': 96, 'loss': 7.67212113714777e-05, 'accuracy': 1.0}, {'epoch': 97, 'loss': 7.642222772119567e-05, 'accuracy': 1.0}, {'epoch': 98, 'loss': 6.950946408323944e-05, 'accuracy': 1.0}, {'epoch': 99, 'loss': 6.707897409796715e-05, 'accuracy': 1.0}, {'epoch': 100, 'loss': 6.419498822651803e-05, 'accuracy': 1.0}]\n"
          ]
        }
      ],
      "source": [
        "# Initialize a list to store loss and accuracy\n",
        "import keras\n",
        "from keras.callbacks import Callback\n",
        "import numpy as np\n",
        "\n",
        "metrics = []\n",
        "\n",
        "# Define a custom callback to store loss and accuracy after each epoch\n",
        "class MetricsCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        loss = logs.get('loss')\n",
        "        accuracy = logs.get('accuracy')\n",
        "        metrics.append({'epoch': epoch + 1, 'loss': loss, 'accuracy': accuracy})\n",
        "\n",
        "# Update the pipeline to include the custom callback\n",
        "pipeline_teacher = Pipeline([\n",
        "    ('flatten', FlattenTransformer()),\n",
        "    ('standardize', StandardScaler()),\n",
        "    ('tcn', KerasClassifier(model=create_tcn_model(), epochs=100, batch_size=20, verbose=1,\n",
        "                            callbacks=[MetricsCallback()]))\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline_teacher.fit(X_train, y_encoded)\n",
        "\n",
        "# Print the collected metrics after training\n",
        "print(metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc6Z2Qjhqe57",
        "outputId": "4a3b0c90-0fe1-43fb-b03a-585c1dea6460"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Training Accuracy: 99.06%\n",
            "Training F1 Score: 99.06\n",
            "Training Recall Score: 0.99\n",
            "Training Precision Score: 0.99\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Testing Accuracy: 76.01%\n",
            "Testing F1 Score: 76.02\n",
            "Testing Recall Score: 0.76\n",
            "Testing Precision Score: 0.76\n"
          ]
        }
      ],
      "source": [
        "# Evaluate training accuracy\n",
        "Y_train_pred_encoded = student_pipeline.predict(X_train[:,32:])\n",
        "Y_train_pred = np.argmax(Y_train_pred_encoded, axis=1)\n",
        "train_accuracy = accuracy_score(np.argmax(y_encoded, axis=1), Y_train_pred)\n",
        "train_f1 = f1_score(np.argmax(y_encoded, axis=1), Y_train_pred, average='weighted') * 100\n",
        "train_recall = recall_score(np.argmax(y_encoded, axis=1), Y_train_pred, average='weighted')\n",
        "train_precision = precision_score(np.argmax(y_encoded, axis=1), Y_train_pred, average='weighted')\n",
        "\n",
        "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "print(f\"Training F1 Score: {train_f1:.2f}\")\n",
        "print(f\"Training Recall Score: {train_recall:.2f}\")\n",
        "print(f\"Training Precision Score: {train_precision:.2f}\")\n",
        "\n",
        "# Evaluate testing accuracy\n",
        "Y_test_pred_encoded = student_pipeline.predict(X_test[:, 32:])\n",
        "Y_test_pred = np.argmax(Y_test_pred_encoded, axis=1)\n",
        "test_accuracy = accuracy_score(np.argmax(y_encoded_test, axis=1), Y_test_pred)\n",
        "test_f1 = f1_score(np.argmax(y_encoded_test, axis=1), Y_test_pred, average='weighted') * 100\n",
        "test_recall = recall_score(np.argmax(y_encoded_test, axis=1), Y_test_pred, average='weighted')\n",
        "test_precision = precision_score(np.argmax(y_encoded_test, axis=1), Y_test_pred, average='weighted')\n",
        "\n",
        "print(f\"Testing Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Testing F1 Score: {test_f1:.2f}\")\n",
        "print(f\"Testing Recall Score: {test_recall:.2f}\")\n",
        "print(f\"Testing Precision Score: {test_precision:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LVttzHQrL6A"
      },
      "outputs": [],
      "source": [
        "# this model for only 8 pps signals\n",
        "\n",
        "def create_tcn_student_model():\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer(input_shape=(8, 1)))\n",
        "    model.add(Conv1D(filters=64, kernel_size=2, dilation_rate=1, activation='relu'))\n",
        "    model.add(Conv1D(filters=64, kernel_size=2, dilation_rate=2, activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(4, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "SMhTd6n0retu",
        "outputId": "ba50fac0-37a8-43b3-eb6c-1a3bd9ecd3cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3952 - loss: 1.2386\n",
            "Epoch 2/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5023 - loss: 1.0809\n",
            "Epoch 3/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5289 - loss: 0.9994\n",
            "Epoch 4/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5631 - loss: 0.9325\n",
            "Epoch 5/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5845 - loss: 0.8975\n",
            "Epoch 6/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6232 - loss: 0.8466\n",
            "Epoch 7/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6502 - loss: 0.8127\n",
            "Epoch 8/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6776 - loss: 0.7293\n",
            "Epoch 9/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6961 - loss: 0.6897\n",
            "Epoch 10/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6990 - loss: 0.6898\n",
            "Epoch 11/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7498 - loss: 0.6212\n",
            "Epoch 12/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7576 - loss: 0.5833\n",
            "Epoch 13/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7719 - loss: 0.5558\n",
            "Epoch 14/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8006 - loss: 0.5243\n",
            "Epoch 15/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7906 - loss: 0.5101\n",
            "Epoch 16/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8081 - loss: 0.4739\n",
            "Epoch 17/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8179 - loss: 0.4282\n",
            "Epoch 18/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8396 - loss: 0.3993\n",
            "Epoch 19/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8292 - loss: 0.4117\n",
            "Epoch 20/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8565 - loss: 0.3688\n",
            "Epoch 21/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8483 - loss: 0.3446\n",
            "Epoch 22/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8507 - loss: 0.3616\n",
            "Epoch 23/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8802 - loss: 0.3199\n",
            "Epoch 24/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8794 - loss: 0.3012\n",
            "Epoch 25/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8776 - loss: 0.3182\n",
            "Epoch 26/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8946 - loss: 0.2829\n",
            "Epoch 27/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8937 - loss: 0.2646\n",
            "Epoch 28/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8970 - loss: 0.2761\n",
            "Epoch 29/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8955 - loss: 0.2752\n",
            "Epoch 30/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9136 - loss: 0.2262\n",
            "Epoch 31/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9158 - loss: 0.2202\n",
            "Epoch 32/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9052 - loss: 0.2307\n",
            "Epoch 33/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8867 - loss: 0.2965\n",
            "Epoch 34/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9255 - loss: 0.2286\n",
            "Epoch 35/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9334 - loss: 0.1850\n",
            "Epoch 36/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9215 - loss: 0.1987\n",
            "Epoch 37/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9387 - loss: 0.1906\n",
            "Epoch 38/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9226 - loss: 0.2150\n",
            "Epoch 39/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9278 - loss: 0.1804\n",
            "Epoch 40/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9411 - loss: 0.1913\n",
            "Epoch 41/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9360 - loss: 0.1796\n",
            "Epoch 42/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9425 - loss: 0.1450\n",
            "Epoch 43/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1434\n",
            "Epoch 44/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9286 - loss: 0.1723\n",
            "Epoch 45/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9464 - loss: 0.1469\n",
            "Epoch 46/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9456 - loss: 0.1489\n",
            "Epoch 47/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9473 - loss: 0.1373\n",
            "Epoch 48/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9406 - loss: 0.1634\n",
            "Epoch 49/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9491 - loss: 0.1259\n",
            "Epoch 50/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.1156\n",
            "Epoch 51/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1388\n",
            "Epoch 52/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9468 - loss: 0.1390\n",
            "Epoch 53/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9318 - loss: 0.1835\n",
            "Epoch 54/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9279 - loss: 0.2128\n",
            "Epoch 55/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.1049\n",
            "Epoch 56/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9528 - loss: 0.1346\n",
            "Epoch 57/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9568 - loss: 0.1459\n",
            "Epoch 58/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1518\n",
            "Epoch 59/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9693 - loss: 0.0957\n",
            "Epoch 60/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.1117\n",
            "Epoch 61/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9766 - loss: 0.0786\n",
            "Epoch 62/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9764 - loss: 0.0762\n",
            "Epoch 63/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9739 - loss: 0.0891\n",
            "Epoch 64/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9730 - loss: 0.0755\n",
            "Epoch 65/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9687 - loss: 0.0789\n",
            "Epoch 66/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9829 - loss: 0.0651\n",
            "Epoch 67/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9824 - loss: 0.0572\n",
            "Epoch 68/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9737 - loss: 0.0847\n",
            "Epoch 69/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9759 - loss: 0.0851\n",
            "Epoch 70/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9783 - loss: 0.0713\n",
            "Epoch 71/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9584 - loss: 0.1078\n",
            "Epoch 72/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9706 - loss: 0.0952\n",
            "Epoch 73/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9513 - loss: 0.1544\n",
            "Epoch 74/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9745 - loss: 0.0700\n",
            "Epoch 75/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9835 - loss: 0.0534\n",
            "Epoch 76/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9883 - loss: 0.0506\n",
            "Epoch 77/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9865 - loss: 0.0551\n",
            "Epoch 78/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0558\n",
            "Epoch 79/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.0504\n",
            "Epoch 80/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9905 - loss: 0.0416\n",
            "Epoch 81/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9867 - loss: 0.0419\n",
            "Epoch 82/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9838 - loss: 0.0460\n",
            "Epoch 83/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.0538\n",
            "Epoch 84/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9842 - loss: 0.0550\n",
            "Epoch 85/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9820 - loss: 0.0610\n",
            "Epoch 86/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9485 - loss: 0.1661\n",
            "Epoch 87/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8913 - loss: 0.5558\n",
            "Epoch 88/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9152 - loss: 0.2378\n",
            "Epoch 89/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9666 - loss: 0.1262\n",
            "Epoch 90/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.0618\n",
            "Epoch 91/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9798 - loss: 0.0583\n",
            "Epoch 92/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9863 - loss: 0.0495\n",
            "Epoch 93/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 0.0499\n",
            "Epoch 94/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.0450\n",
            "Epoch 95/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9886 - loss: 0.0467\n",
            "Epoch 96/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9890 - loss: 0.0571\n",
            "Epoch 97/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9814 - loss: 0.0745\n",
            "Epoch 98/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0373\n",
            "Epoch 99/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0307\n",
            "Epoch 100/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('flatten', FlattenTransformer()),\n",
              "                ('standardize', StandardScaler()),\n",
              "                ('tcn',\n",
              "                 KerasClassifier(batch_size=20, callbacks=[<__main__.MetricsCallback object at 0x7f589482fb50>], epochs=100, model=<Sequential name=sequential_14, built=True>))])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;flatten&#x27;, FlattenTransformer()),\n",
              "                (&#x27;standardize&#x27;, StandardScaler()),\n",
              "                (&#x27;tcn&#x27;,\n",
              "                 KerasClassifier(batch_size=20, callbacks=[&lt;__main__.MetricsCallback object at 0x7f589482fb50&gt;], epochs=100, model=&lt;Sequential name=sequential_14, built=True&gt;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;flatten&#x27;, FlattenTransformer()),\n",
              "                (&#x27;standardize&#x27;, StandardScaler()),\n",
              "                (&#x27;tcn&#x27;,\n",
              "                 KerasClassifier(batch_size=20, callbacks=[&lt;__main__.MetricsCallback object at 0x7f589482fb50&gt;], epochs=100, model=&lt;Sequential name=sequential_14, built=True&gt;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">FlattenTransformer</label><div class=\"sk-toggleable__content fitted\"><pre>FlattenTransformer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">KerasClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>KerasClassifier(\n",
              "\tmodel=&lt;Sequential name=sequential_14, built=True&gt;\n",
              "\tbuild_fn=None\n",
              "\twarm_start=False\n",
              "\trandom_state=None\n",
              "\toptimizer=rmsprop\n",
              "\tloss=None\n",
              "\tmetrics=None\n",
              "\tbatch_size=20\n",
              "\tvalidation_batch_size=None\n",
              "\tverbose=1\n",
              "\tcallbacks=[&lt;__main__.MetricsCallback object at 0x7f589482fb50&gt;]\n",
              "\tvalidation_split=0.0\n",
              "\tshuffle=True\n",
              "\trun_eagerly=False\n",
              "\tepochs=100\n",
              "\tclass_weight=None\n",
              ")</pre></div> </div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Without KD\n",
        "# Define the pipeline with flattening and scaling without Knowledge distillation\n",
        "metrics2 = []\n",
        "\n",
        "# Define a custom callback to store loss and accuracy after each epoch\n",
        "class MetricsCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        loss = logs.get('loss')\n",
        "        accuracy = logs.get('accuracy')\n",
        "        metrics2.append({'epoch': epoch + 1, 'loss': loss, 'accuracy': accuracy})\n",
        "\n",
        "student_pipeline = Pipeline([\n",
        "    ('flatten', FlattenTransformer()),\n",
        "    ('standardize', StandardScaler()),\n",
        "    ('tcn', KerasClassifier(model=create_tcn_student_model(), epochs=100, batch_size=20, verbose=1,callbacks=[MetricsCallback()]))\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "student_pipeline.fit(X_train[:,32:], y_encoded)\n",
        "\n",
        "# 70/70 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step\n",
        "# Training Accuracy: 96.67%\n",
        "# Training F1 Score: 96.66\n",
        "# Training Recall Score: 0.97\n",
        "# Training Precision Score: 0.97\n",
        "# 18/18 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step\n",
        "# Testing Accuracy: 79.19%\n",
        "# Testing F1 Score: 79.08\n",
        "# Testing Recall Score: 0.79\n",
        "# Testing Precision Score: 0.80\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "CgbiIgCrtW_o",
        "outputId": "669365fa-8025-45f4-f519-cc8d5deb79d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4156 - loss: 1.2498\n",
            "Epoch 2/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5085 - loss: 1.0703\n",
            "Epoch 3/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5457 - loss: 0.9771\n",
            "Epoch 4/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5618 - loss: 0.9442\n",
            "Epoch 5/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5867 - loss: 0.8779\n",
            "Epoch 6/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6568 - loss: 0.8038\n",
            "Epoch 7/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6456 - loss: 0.7968\n",
            "Epoch 8/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6683 - loss: 0.7523\n",
            "Epoch 9/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7120 - loss: 0.6786\n",
            "Epoch 10/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7106 - loss: 0.6700\n",
            "Epoch 11/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7384 - loss: 0.6225\n",
            "Epoch 12/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7062 - loss: 0.6535\n",
            "Epoch 13/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7498 - loss: 0.5792\n",
            "Epoch 14/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7604 - loss: 0.5249\n",
            "Epoch 15/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7712 - loss: 0.5327\n",
            "Epoch 16/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 0.5184\n",
            "Epoch 17/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8237 - loss: 0.4389\n",
            "Epoch 18/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7945 - loss: 0.4617\n",
            "Epoch 19/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8301 - loss: 0.4005\n",
            "Epoch 20/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8399 - loss: 0.3859\n",
            "Epoch 21/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8791 - loss: 0.3222\n",
            "Epoch 22/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8500 - loss: 0.3572\n",
            "Epoch 23/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8619 - loss: 0.3477\n",
            "Epoch 24/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8649 - loss: 0.3355\n",
            "Epoch 25/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8616 - loss: 0.3566\n",
            "Epoch 26/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8832 - loss: 0.3000\n",
            "Epoch 27/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8738 - loss: 0.3051\n",
            "Epoch 28/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9006 - loss: 0.2636\n",
            "Epoch 29/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8987 - loss: 0.2759\n",
            "Epoch 30/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9177 - loss: 0.2423\n",
            "Epoch 31/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9155 - loss: 0.2589\n",
            "Epoch 32/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9239 - loss: 0.2195\n",
            "Epoch 33/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2327\n",
            "Epoch 34/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8985 - loss: 0.2771\n",
            "Epoch 35/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9149 - loss: 0.2343\n",
            "Epoch 36/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9352 - loss: 0.2036\n",
            "Epoch 37/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9316 - loss: 0.1915\n",
            "Epoch 38/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9386 - loss: 0.1817\n",
            "Epoch 39/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9302 - loss: 0.1951\n",
            "Epoch 40/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9397 - loss: 0.1618\n",
            "Epoch 41/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8771 - loss: 0.3579\n",
            "Epoch 42/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9342 - loss: 0.1934\n",
            "Epoch 43/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9431 - loss: 0.1618\n",
            "Epoch 44/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9426 - loss: 0.1723\n",
            "Epoch 45/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9552 - loss: 0.1374\n",
            "Epoch 46/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9464 - loss: 0.1499\n",
            "Epoch 47/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9228 - loss: 0.1971\n",
            "Epoch 48/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9646 - loss: 0.1416\n",
            "Epoch 49/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9215 - loss: 0.2047\n",
            "Epoch 50/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9516 - loss: 0.1569\n",
            "Epoch 51/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9477 - loss: 0.1418\n",
            "Epoch 52/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9620 - loss: 0.1205\n",
            "Epoch 53/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9695 - loss: 0.1084\n",
            "Epoch 54/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9768 - loss: 0.1056\n",
            "Epoch 55/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9705 - loss: 0.0987\n",
            "Epoch 56/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1241\n",
            "Epoch 57/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.1074\n",
            "Epoch 58/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9436 - loss: 0.1364\n",
            "Epoch 59/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9323 - loss: 0.2287\n",
            "Epoch 60/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9377 - loss: 0.1687\n",
            "Epoch 61/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9507 - loss: 0.1252\n",
            "Epoch 62/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9689 - loss: 0.0885\n",
            "Epoch 63/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9673 - loss: 0.0935\n",
            "Epoch 64/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.0956\n",
            "Epoch 65/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9791 - loss: 0.0804\n",
            "Epoch 66/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9764 - loss: 0.0765\n",
            "Epoch 67/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.1326\n",
            "Epoch 68/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9666 - loss: 0.1037\n",
            "Epoch 69/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9708 - loss: 0.0883\n",
            "Epoch 70/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9755 - loss: 0.0810\n",
            "Epoch 71/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0645\n",
            "Epoch 72/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9714 - loss: 0.0811\n",
            "Epoch 73/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.0680\n",
            "Epoch 74/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9820 - loss: 0.0718\n",
            "Epoch 75/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9760 - loss: 0.0657\n",
            "Epoch 76/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9710 - loss: 0.1026\n",
            "Epoch 77/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9731 - loss: 0.1007\n",
            "Epoch 78/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9453 - loss: 0.2020\n",
            "Epoch 79/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1549\n",
            "Epoch 80/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9442 - loss: 0.1937\n",
            "Epoch 81/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.1100\n",
            "Epoch 82/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9715 - loss: 0.0986\n",
            "Epoch 83/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9756 - loss: 0.0965\n",
            "Epoch 84/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9781 - loss: 0.0649\n",
            "Epoch 85/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9854 - loss: 0.0578\n",
            "Epoch 86/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9768 - loss: 0.0624\n",
            "Epoch 87/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9825 - loss: 0.0657\n",
            "Epoch 88/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9815 - loss: 0.0574\n",
            "Epoch 89/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9699 - loss: 0.0677\n",
            "Epoch 90/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9878 - loss: 0.0488\n",
            "Epoch 91/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9835 - loss: 0.0517\n",
            "Epoch 92/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9842 - loss: 0.0578\n",
            "Epoch 93/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9835 - loss: 0.0544\n",
            "Epoch 94/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0536\n",
            "Epoch 95/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9851 - loss: 0.0543\n",
            "Epoch 96/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9808 - loss: 0.0534\n",
            "Epoch 97/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9557 - loss: 0.1223\n",
            "Epoch 98/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9794 - loss: 0.0718\n",
            "Epoch 99/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9764 - loss: 0.0600\n",
            "Epoch 100/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9776 - loss: 0.0599\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('flatten', FlattenTransformer()),\n",
              "                ('standardize', StandardScaler()),\n",
              "                ('tcn',\n",
              "                 KerasClassifier(batch_size=20, callbacks=[<__main__.MetricsCallback object at 0x7f5893d2fee0>], epochs=100, model=<Sequential name=sequential_15, built=True>))])"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-3 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-3 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-3 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-3 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-3 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;flatten&#x27;, FlattenTransformer()),\n",
              "                (&#x27;standardize&#x27;, StandardScaler()),\n",
              "                (&#x27;tcn&#x27;,\n",
              "                 KerasClassifier(batch_size=20, callbacks=[&lt;__main__.MetricsCallback object at 0x7f5893d2fee0&gt;], epochs=100, model=&lt;Sequential name=sequential_15, built=True&gt;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;flatten&#x27;, FlattenTransformer()),\n",
              "                (&#x27;standardize&#x27;, StandardScaler()),\n",
              "                (&#x27;tcn&#x27;,\n",
              "                 KerasClassifier(batch_size=20, callbacks=[&lt;__main__.MetricsCallback object at 0x7f5893d2fee0&gt;], epochs=100, model=&lt;Sequential name=sequential_15, built=True&gt;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">FlattenTransformer</label><div class=\"sk-toggleable__content fitted\"><pre>FlattenTransformer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">KerasClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>KerasClassifier(\n",
              "\tmodel=&lt;Sequential name=sequential_15, built=True&gt;\n",
              "\tbuild_fn=None\n",
              "\twarm_start=False\n",
              "\trandom_state=None\n",
              "\toptimizer=rmsprop\n",
              "\tloss=None\n",
              "\tmetrics=None\n",
              "\tbatch_size=20\n",
              "\tvalidation_batch_size=None\n",
              "\tverbose=1\n",
              "\tcallbacks=[&lt;__main__.MetricsCallback object at 0x7f5893d2fee0&gt;]\n",
              "\tvalidation_split=0.0\n",
              "\tshuffle=True\n",
              "\trun_eagerly=False\n",
              "\tepochs=100\n",
              "\tclass_weight=None\n",
              ")</pre></div> </div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# Applying the KD for the TCN student - 8 pps model with the TCN teacher model\n",
        "\n",
        "metrics3 = []\n",
        "\n",
        "# Define a custom callback to store loss and accuracy after each epoch\n",
        "class MetricsCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        loss = logs.get('loss')\n",
        "        accuracy = logs.get('accuracy')\n",
        "        metrics3.append({'epoch': epoch + 1, 'loss': loss, 'accuracy': accuracy})\n",
        "\n",
        "# Generate soft targets from Teacher Model for Student Training\n",
        "soft_targets = pipeline_teacher.predict(X_train)\n",
        "\n",
        "student_pipeline = Pipeline([\n",
        "    ('flatten', FlattenTransformer()),\n",
        "    ('standardize', StandardScaler()),\n",
        "    ('tcn', KerasClassifier(model=create_tcn_student_model(), epochs=100, batch_size=20, verbose=1, callbacks=[MetricsCallback()]))\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "student_pipeline.fit(X_train[:,32:], soft_targets)\n",
        "\n",
        "# 70/70 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step\n",
        "# Training Accuracy: 99.06%\n",
        "# Training F1 Score: 99.06\n",
        "# Training Recall Score: 0.99\n",
        "# Training Precision Score: 0.99\n",
        "# 18/18 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step\n",
        "# Testing Accuracy: 76.01%\n",
        "# Testing F1 Score: 76.02\n",
        "# Testing Recall Score: 0.76\n",
        "# Testing Precision Score: 0.76"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pipeline_teacher.named_steps['tcn'].model_.summary())\n",
        "print(student_pipeline.named_steps['tcn'].model_.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "_L-K0iSPJjxV",
        "outputId": "d398f70f-4050-4707-d336-d1864a9e002a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m12,352\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2176\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m278,656\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m516\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2176</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">278,656</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875,342\u001b[0m (3.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875,342</span> (3.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m291,780\u001b[0m (1.11 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">291,780</span> (1.11 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m583,562\u001b[0m (2.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">583,562</span> (2.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │             \u001b[38;5;34m192\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m41,088\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m516\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m150,158\u001b[0m (586.56 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">150,158</span> (586.56 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,052\u001b[0m (195.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,052</span> (195.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m100,106\u001b[0m (391.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,106</span> (391.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Using 40 channels for student model"
      ],
      "metadata": {
        "id": "100-0k6oX5hL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "6EYQnVodvuH4",
        "outputId": "526b9d72-f4e8-43b4-92ed-08b0fc19819d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.4037 - loss: 1.2357\n",
            "Epoch 2/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5701 - loss: 0.9009\n",
            "Epoch 3/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7444 - loss: 0.6919\n",
            "Epoch 4/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8111 - loss: 0.4880\n",
            "Epoch 5/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8663 - loss: 0.3813\n",
            "Epoch 6/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8739 - loss: 0.3670\n",
            "Epoch 7/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9096 - loss: 0.2774\n",
            "Epoch 8/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9253 - loss: 0.2223\n",
            "Epoch 9/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9477 - loss: 0.1829\n",
            "Epoch 10/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9687 - loss: 0.1280\n",
            "Epoch 11/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9552 - loss: 0.1354\n",
            "Epoch 12/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9588 - loss: 0.1226\n",
            "Epoch 13/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9759 - loss: 0.0902\n",
            "Epoch 14/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9770 - loss: 0.1206\n",
            "Epoch 15/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9723 - loss: 0.0880\n",
            "Epoch 16/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9896 - loss: 0.0466\n",
            "Epoch 17/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9900 - loss: 0.0366\n",
            "Epoch 18/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9945 - loss: 0.0307\n",
            "Epoch 19/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9954 - loss: 0.0255\n",
            "Epoch 20/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9968 - loss: 0.0182\n",
            "Epoch 21/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9956 - loss: 0.0238\n",
            "Epoch 22/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9945 - loss: 0.0172\n",
            "Epoch 23/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9987 - loss: 0.0079\n",
            "Epoch 24/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9919 - loss: 0.0377\n",
            "Epoch 25/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9892 - loss: 0.0388\n",
            "Epoch 26/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9466 - loss: 0.1914\n",
            "Epoch 27/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9644 - loss: 0.1238\n",
            "Epoch 28/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9964 - loss: 0.0161\n",
            "Epoch 29/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9959 - loss: 0.0256\n",
            "Epoch 30/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0041\n",
            "Epoch 31/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0026\n",
            "Epoch 32/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0023\n",
            "Epoch 33/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0018\n",
            "Epoch 34/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0018\n",
            "Epoch 35/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 36/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 9.5399e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.7687e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.1327e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.8118e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.4595e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.9551e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.2268e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.4549e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.1574e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 4.2239e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 4.3782e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5060e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 3.5289e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.9851e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.3569e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6684e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.2686e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.0354e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.3198e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 2.2572e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.1627e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.1708e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 1.7908e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 1.7083e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 2.0045e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2963e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.5957e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 1.4065e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.4650e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3836e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.3737e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1097e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 9.7358e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 1.0437e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 9.4474e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 1.0084e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 8.5263e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 7.7739e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 8.5748e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.6945e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.4157e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 7.6982e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 6.2991e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 2.0344e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9194 - loss: 0.3384\n",
            "Epoch 81/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9532 - loss: 0.1360\n",
            "Epoch 82/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9804 - loss: 0.0652\n",
            "Epoch 83/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9909 - loss: 0.0420\n",
            "Epoch 84/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9976 - loss: 0.0137\n",
            "Epoch 85/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9987 - loss: 0.0045\n",
            "Epoch 86/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9975 - loss: 0.0095\n",
            "Epoch 87/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0037\n",
            "Epoch 88/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 9.1023e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.6512e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.0949e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.2667e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.8383e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 3.2264e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.6809e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.4044e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.3787e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 2.7123e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 2.2615e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 2.1644e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.6993e-04\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-7 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-7 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-7 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-7 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-7 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-7 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-7 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-7 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-7 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-7 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-7 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-7 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-7 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;flatten&#x27;, FlattenTransformer()),\n",
              "                (&#x27;standardize&#x27;, StandardScaler()),\n",
              "                (&#x27;tcn&#x27;,\n",
              "                 KerasClassifier(batch_size=20, callbacks=[&lt;__main__.MetricsCallback object at 0x7e549a08ebf0&gt;], epochs=100, model=&lt;Sequential name=sequential_7, built=True&gt;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;flatten&#x27;, FlattenTransformer()),\n",
              "                (&#x27;standardize&#x27;, StandardScaler()),\n",
              "                (&#x27;tcn&#x27;,\n",
              "                 KerasClassifier(batch_size=20, callbacks=[&lt;__main__.MetricsCallback object at 0x7e549a08ebf0&gt;], epochs=100, model=&lt;Sequential name=sequential_7, built=True&gt;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">FlattenTransformer</label><div class=\"sk-toggleable__content fitted\"><pre>FlattenTransformer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">KerasClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>KerasClassifier(\n",
              "\tmodel=&lt;Sequential name=sequential_7, built=True&gt;\n",
              "\tbuild_fn=None\n",
              "\twarm_start=False\n",
              "\trandom_state=None\n",
              "\toptimizer=rmsprop\n",
              "\tloss=None\n",
              "\tmetrics=None\n",
              "\tbatch_size=20\n",
              "\tvalidation_batch_size=None\n",
              "\tverbose=1\n",
              "\tcallbacks=[&lt;__main__.MetricsCallback object at 0x7e549a08ebf0&gt;]\n",
              "\tvalidation_split=0.0\n",
              "\tshuffle=True\n",
              "\trun_eagerly=False\n",
              "\tepochs=100\n",
              "\tclass_weight=None\n",
              ")</pre></div> </div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('flatten', FlattenTransformer()),\n",
              "                ('standardize', StandardScaler()),\n",
              "                ('tcn',\n",
              "                 KerasClassifier(batch_size=20, callbacks=[<__main__.MetricsCallback object at 0x7e549a08ebf0>], epochs=100, model=<Sequential name=sequential_7, built=True>))])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Applying the KD for the TCN student model - 40 channels with the TCN teacher model\n",
        "\n",
        "# this model for only 40 pps signals with reduced parameters\n",
        "\n",
        "def create_tcn_student_model():\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer(input_shape=(40, 1)))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, dilation_rate=1, activation='relu'))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, dilation_rate=2, activation='relu'))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, dilation_rate=2, activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(4, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "y_encoded = to_categorical(y_train)\n",
        "y_encoded_test = to_categorical(y_test)\n",
        "\n",
        "# Generate soft targets from Teacher Model for Student Training\n",
        "soft_targets = pipeline_teacher.predict(X_train)\n",
        "metrics5 = []\n",
        "\n",
        "# Define a custom callback to store loss and accuracy after each epoch\n",
        "class MetricsCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        loss = logs.get('loss')\n",
        "        accuracy = logs.get('accuracy')\n",
        "        metrics5.append({'epoch': epoch + 1, 'loss': loss, 'accuracy': accuracy})\n",
        "\n",
        "student_pipeline = Pipeline([\n",
        "    ('flatten', FlattenTransformer()),\n",
        "    ('standardize', StandardScaler()),\n",
        "    ('tcn', KerasClassifier(model=create_tcn_student_model(), epochs=100, batch_size=20, verbose=1, callbacks=[MetricsCallback()]))\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "student_pipeline.fit(X_train, soft_targets)\n",
        "\n",
        "## With KD\n",
        "\n",
        "# 70/70 ━━━━━━━━━━━━━━━━━━━━ 1s 7ms/step\n",
        "# Training Accuracy: 100.00%\n",
        "# Training F1 Score: 100.00\n",
        "# Training Recall Score: 1.00\n",
        "# Training Precision Score: 1.00\n",
        "# 18/18 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step\n",
        "# Testing Accuracy: 93.35%\n",
        "# Testing F1 Score: 93.35\n",
        "# Testing Recall Score: 0.93\n",
        "# Testing Precision Score: 0.93\n",
        "\n",
        "## without KD\n",
        "# 70/70 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step\n",
        "# Training Accuracy: 100.00%\n",
        "# Training F1 Score: 100.00\n",
        "# Training Recall Score: 1.00\n",
        "# Training Precision Score: 1.00\n",
        "# 18/18 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step\n",
        "# Testing Accuracy: 92.77%\n",
        "# Testing F1 Score: 92.76\n",
        "# Testing Recall Score: 0.93\n",
        "# Testing Precision Score: 0.93"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhW3kRa4xCsF",
        "outputId": "1b1be248-ce12-4837-868e-3be5a602c654"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Training Accuracy: 100.00%\n",
            "Training F1 Score: 100.00\n",
            "Training Recall Score: 1.00\n",
            "Training Precision Score: 1.00\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Testing Accuracy: 92.77%\n",
            "Testing F1 Score: 92.76\n",
            "Testing Recall Score: 0.93\n",
            "Testing Precision Score: 0.93\n"
          ]
        }
      ],
      "source": [
        "# Evaluate training accuracy\n",
        "\n",
        "# Y_train_pred_encoded = pipeline.predict(X_train)\n",
        "Y_train_pred_encoded = student_pipeline.predict(X_train)\n",
        "Y_train_pred = np.argmax(Y_train_pred_encoded, axis=1)\n",
        "train_accuracy = accuracy_score(np.argmax(y_encoded, axis=1), Y_train_pred)\n",
        "train_f1 = f1_score(np.argmax(y_encoded, axis=1), Y_train_pred, average='weighted') * 100\n",
        "train_recall = recall_score(np.argmax(y_encoded, axis=1), Y_train_pred, average='weighted')\n",
        "train_precision = precision_score(np.argmax(y_encoded, axis=1), Y_train_pred, average='weighted')\n",
        "\n",
        "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "print(f\"Training F1 Score: {train_f1:.2f}\")\n",
        "print(f\"Training Recall Score: {train_recall:.2f}\")\n",
        "print(f\"Training Precision Score: {train_precision:.2f}\")\n",
        "\n",
        "# Evaluate testing accuracy\n",
        "# Y_test_pred_encoded = pipeline.predict(X_test)\n",
        "Y_test_pred_encoded = student_pipeline.predict(X_test)\n",
        "Y_test_pred = np.argmax(Y_test_pred_encoded, axis=1)\n",
        "test_accuracy = accuracy_score(np.argmax(y_encoded_test, axis=1), Y_test_pred)\n",
        "test_f1 = f1_score(np.argmax(y_encoded_test, axis=1), Y_test_pred, average='weighted') * 100\n",
        "test_recall = recall_score(np.argmax(y_encoded_test, axis=1), Y_test_pred, average='weighted')\n",
        "test_precision = precision_score(np.argmax(y_encoded_test, axis=1), Y_test_pred, average='weighted')\n",
        "\n",
        "print(f\"Testing Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Testing F1 Score: {test_f1:.2f}\")\n",
        "print(f\"Testing Recall Score: {test_recall:.2f}\")\n",
        "print(f\"Testing Precision Score: {test_precision:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "AvX0jxJ45inf",
        "outputId": "b25c47a2-b38d-4ba0-ddd3-8417e3ef2a8f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2176</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">278,656</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_47 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_48 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m12,352\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_14 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2176\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m278,656\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m516\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875,342</span> (3.34 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875,342\u001b[0m (3.34 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">291,780</span> (1.11 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m291,780\u001b[0m (1.11 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">583,562</span> (2.23 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m583,562\u001b[0m (2.23 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">245,888</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_49 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_50 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m12,352\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_51 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m12,352\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_15 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1920\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m245,888\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m516\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">814,094</span> (3.11 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m814,094\u001b[0m (3.11 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">271,364</span> (1.04 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m271,364\u001b[0m (1.04 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">542,730</span> (2.07 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m542,730\u001b[0m (2.07 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Access the Keras model from the KerasClassifier in the pipeline\n",
        "tcn_model = pipeline.named_steps['tcn'].model_\n",
        "\n",
        "# Print the summary of the TCN model\n",
        "tcn_model.summary()\n",
        "\n",
        "# Access the Keras model from the KerasClassifier in the pipeline\n",
        "tcn_model = student_pipeline.named_steps['tcn'].model_\n",
        "\n",
        "# Print the summary of the TCN model\n",
        "tcn_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiNHPug3LwIF"
      },
      "source": [
        "###TCN With 5-fold cross validation\n",
        "<p>Teacher model: Accuracy: 0.9306, F1 Score: 0.9306</p>\n",
        "<p>Student Model with 8 pps: Accuracy: 0.7687, F1 Score: 0.7681</p>\n",
        "<p>Student Model with 40 channels: Accuracy: 0.9219, F1 Score: 0.9220</p>\n",
        "<p>Student model with 8 pps no KD: Accuracy: 0.7832, F1 Score: 0.7832</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1K-vEw5-LBDs",
        "outputId": "65f2d05d-111e-4356-d30f-bbc2f606a91f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4326 - loss: 1.2384\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6109 - loss: 0.8974\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7422 - loss: 0.6635\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7820 - loss: 0.5778\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8624 - loss: 0.4410\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8529 - loss: 0.5100\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8819 - loss: 0.3713\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8897 - loss: 0.3316\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9176 - loss: 0.2748\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9337 - loss: 0.2056\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9472 - loss: 0.1843\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9452 - loss: 0.2389\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9340 - loss: 0.1971\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9770 - loss: 0.1231\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9738 - loss: 0.1208\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9678 - loss: 0.1240\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9688 - loss: 0.1164\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9712 - loss: 0.1729\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9739 - loss: 0.1056\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9774 - loss: 0.0785\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9898 - loss: 0.0385\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9837 - loss: 0.0838\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9970 - loss: 0.0329\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.0248\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9953 - loss: 0.0294\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9872 - loss: 0.0668\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9957 - loss: 0.0237\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9970 - loss: 0.0322\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9987 - loss: 0.0158\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9962 - loss: 0.0135\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9931 - loss: 0.0238\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9955 - loss: 0.0412\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9991 - loss: 0.0111\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9958 - loss: 0.0244\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9897 - loss: 0.0444\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0112\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9987 - loss: 0.0102\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0063\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0060\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 0.0059\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0046\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 0.0027\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 0.0026\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9978 - loss: 0.0052\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0021\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0043\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 0.0017\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0019\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0017\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.0023\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9987 - loss: 0.0027\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9999 - loss: 0.0012\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0016\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.4674e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0010\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 9.9092e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 7.6617e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.7291e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 7.2888e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.8620e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.0545e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.0028e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.1050e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.3041e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6266e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.3646e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.4434e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.7906e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.6008e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.5690e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.1772e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.1672e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.4140e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.1700e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2991e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.1859e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.3564e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5976e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.7704e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.7789e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.2191e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.8093e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.9745e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.7568e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.8778e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.5706e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.6372e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.5895e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.4347e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.4276e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.1324e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.4091e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.1552e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.7105e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2381e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.1691e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.0393e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.1590e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.6139e-05\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Fold 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.83      0.87        12\n",
            "           1       0.91      0.93      0.92       115\n",
            "           2       0.86      0.93      0.90        75\n",
            "           3       0.91      0.81      0.86        75\n",
            "\n",
            "    accuracy                           0.90       277\n",
            "   macro avg       0.90      0.88      0.89       277\n",
            "weighted avg       0.90      0.90      0.89       277\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9233 - loss: 0.3954\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9369 - loss: 0.2532\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9808 - loss: 0.0968\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9947 - loss: 0.0345\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9949 - loss: 0.0408\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9973 - loss: 0.0149\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0085\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0063\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0054\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0034\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0038\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0019\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0023\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0020\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0016\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.5505e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 7.9335e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.2708e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 7.2509e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.7018e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.8638e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.3618e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.8308e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.5412e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.5943e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.4468e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.1143e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.2429e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 2.9947e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.4681e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.0278e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.9715e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.7026e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.7489e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.5574e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.4719e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.5850e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.2251e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.8676e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5083e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8235e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.0096e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.5869e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.5645e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.6379e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.5203e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.4533e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4213e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.2953e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.1088e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.0426e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.0279e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.1926e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.0302e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.0855e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.0682e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.7780e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.3974e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 7.6778e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.2882e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 8.2699e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 7.9094e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.8022e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.7146e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.8214e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.9781e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.9774e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.4263e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.9971e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.5576e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.3985e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.0344e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.3070e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.0049e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.8449e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6453e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.5267e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.1695e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.9001e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.0511e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3246e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.5955e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.9703e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.3668e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.6474e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.5735e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.8538e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.6339e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.8786e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.0662e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.2740e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 2.6283e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.7485e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.2809e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.9467e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.0427e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.9459e-05\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Fold 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.88      0.94        17\n",
            "           1       0.96      0.97      0.97       113\n",
            "           2       0.95      0.96      0.96        78\n",
            "           3       0.94      0.94      0.94        69\n",
            "\n",
            "    accuracy                           0.96       277\n",
            "   macro avg       0.96      0.94      0.95       277\n",
            "weighted avg       0.96      0.96      0.96       277\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9364 - loss: 0.2641\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9506 - loss: 0.1406\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9780 - loss: 0.0547\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.0950\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9899 - loss: 0.0291\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0114\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0036\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0025\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0021\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0012\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 9.7068e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 8.7242e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 8.0231e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.0963e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.0996e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.7354e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6929e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.2299e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.8789e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.7221e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.9548e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.7398e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.2825e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.2471e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.8607e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7441e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.7844e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.8391e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.6161e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2854e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.4963e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 9.9977e-05\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.1515e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0943e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.8351e-05\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.7400e-05\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.6195e-05\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 7.0401e-05\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 7.1791e-05\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.9530e-05\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.3604e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.3087e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.1026e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.2081e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.2899e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.5581e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.0889e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.4416e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5948e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.3010e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2827e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.2277e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.8453e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 3.7463e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 3.7569e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.0979e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.2866e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.4913e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.2331e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.7033e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4793e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.4832e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.2093e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.2593e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.4157e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.3311e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.7180e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.7341e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.5892e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.9931e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.0777e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.6262e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.5848e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.4442e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.5453e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.6797e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.5496e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.2650e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.3965e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.2667e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.0988e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.4963e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.2372e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.0116e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.0921e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1906e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.0754e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.5232e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 8.6069e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.7209e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.1625e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.8567e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 8.1279e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 9.4686e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.4513e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.7779e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 7.5356e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.3619e-06\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Fold 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       0.98      0.98      0.98       115\n",
            "           2       0.99      1.00      0.99        75\n",
            "           3       0.99      0.97      0.98        79\n",
            "\n",
            "    accuracy                           0.99       276\n",
            "   macro avg       0.99      0.99      0.99       276\n",
            "weighted avg       0.99      0.99      0.99       276\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9732 - loss: 0.0884\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9620 - loss: 0.1399\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9812 - loss: 0.1007\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0053\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0017\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 8.3512e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 7.3228e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.2730e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.7188e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.8757e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.9289e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.1523e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2866e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.6972e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 2.4483e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 2.4802e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 2.1876e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.2174e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.0266e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.0228e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.6398e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.3246e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7994e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.4149e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.2863e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.2756e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.2359e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1698e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.1548e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 9.4933e-05\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 9.1759e-05\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.4116e-05\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.3619e-05\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.1298e-05\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 9.2711e-05\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 8.5283e-05\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.6193e-05\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.6940e-05\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.5318e-05\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 6.8413e-05\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.2919e-05\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.5504e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2811e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.9505e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.6250e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.7291e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.6359e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.1894e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.5021e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.8020e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.3052e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.0201e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.3377e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.4299e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.7097e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.5412e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.4427e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.2551e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.6151e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.1089e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.8849e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.3992e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5235e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.6843e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.5699e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.3991e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.4677e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.6393e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.4271e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.0118e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.7437e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8196e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.0379e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8824e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.7462e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.8132e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4384e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.5388e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 1.5702e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.3283e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.5619e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.6884e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3793e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4341e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1210e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.1443e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.2466e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1281e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.2485e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.0691e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.0538e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.1299e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.2079e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.0096e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 7.8446e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.0899e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 9.4043e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 7.4543e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.6951e-06\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Fold 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        15\n",
            "           1       0.98      1.00      0.99       128\n",
            "           2       1.00      0.96      0.98        74\n",
            "           3       0.98      1.00      0.99        59\n",
            "\n",
            "    accuracy                           0.99       276\n",
            "   macro avg       0.99      0.99      0.99       276\n",
            "weighted avg       0.99      0.99      0.99       276\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9803 - loss: 0.1154\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9604 - loss: 0.1903\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9911 - loss: 0.0357\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9982 - loss: 0.0084\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9973 - loss: 0.0083\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0017\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.0200e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.2543e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.3220e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.7983e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.8960e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.1921e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4729e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.3921e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.0963e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.1143e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.9032e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.6701e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.5585e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.4105e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2563e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.7381e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.3241e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.1139e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 9.4079e-05\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1617e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 9.8006e-05\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 8.4286e-05\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.7699e-05\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.8058e-05\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 7.0585e-05\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.7965e-05\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.3476e-05\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.1099e-05\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.6898e-05\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.7721e-05\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6154e-05\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.7254e-05\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.4412e-05\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.0240e-05\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.2704e-05\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.2022e-05\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.6594e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 3.8719e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.0613e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.8911e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.8540e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.9872e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.6555e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.4603e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.3382e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5299e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4335e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.7050e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5897e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.9885e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.1042e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8785e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.2110e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8695e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7922e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.5115e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.5245e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.5815e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.3778e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.5364e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2337e-05 \n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.4162e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1057e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.6643e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0351e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2545e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.0102e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.0591e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2649e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1295e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 9.9979e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 8.9661e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.6497e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 7.6661e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.8183e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 9.0202e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 7.3136e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 6.6286e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.5767e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.8375e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 8.9550e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.1166e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.9290e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.9501e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.3495e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.6842e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.3971e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2292e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.0935e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.4907e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.2832e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.5854e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.7357e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.1165e-06\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Fold 5 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        17\n",
            "           1       1.00      1.00      1.00        98\n",
            "           2       1.00      0.99      0.99        97\n",
            "           3       0.98      1.00      0.99        64\n",
            "\n",
            "    accuracy                           1.00       276\n",
            "   macro avg       1.00      1.00      1.00       276\n",
            "weighted avg       1.00      1.00      1.00       276\n",
            "\n",
            "Cross-validation Accuracy scores: [0.8953068592057761, 0.9566787003610109, 0.9855072463768116, 0.9891304347826086, 0.9963768115942029]\n",
            "Mean accuracy: 0.9646000104640822\n",
            "Cross-validation F1 scores: [0.8945899358529399, 0.9565892111762931, 0.9854846272396764, 0.9890613012170223, 0.9963814684616562]\n",
            "Mean F1 score: 0.9644213087895176\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "metrics = []\n",
        "\n",
        "# Define a custom callback to store loss and accuracy after each epoch\n",
        "class MetricsCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        loss = logs.get('loss')\n",
        "        accuracy = logs.get('accuracy')\n",
        "        metrics.append({'epoch': epoch + 1, 'loss': loss, 'accuracy': accuracy})\n",
        "\n",
        "# Define the pipeline with flattening and scaling\n",
        "pipeline_teacher = Pipeline([\n",
        "    ('flatten', FlattenTransformer()),\n",
        "    ('standardize', StandardScaler()),\n",
        "    ('tcn', KerasClassifier(model=create_tcn_model(), epochs=100, batch_size=20, verbose=1, callbacks=[MetricsCallback()]))\n",
        "])\n",
        "\n",
        "y_encoded = to_categorical(y_train)\n",
        "y_encoded_test = to_categorical(y_test)\n",
        "\n",
        "# Set up 5-fold cross-validation\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store metrics for each fold\n",
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "# Perform cross-validation manually to get detailed metrics\n",
        "for train_idx, val_idx in kfold.split(X_train):\n",
        "    # Split the data into training and validation sets\n",
        "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
        "    y_train_fold, y_val_fold = y_encoded[train_idx], y_encoded[val_idx]\n",
        "\n",
        "    # Fit the model on the current fold\n",
        "    pipeline_teacher.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Predict on the validation set\n",
        "    y_pred_fold = pipeline_teacher.predict(X_val_fold)\n",
        "\n",
        "    # Convert predictions back to class labels (from one-hot encoding)\n",
        "    y_val_fold_labels = y_val_fold.argmax(axis=1)\n",
        "    y_pred_fold_labels = y_pred_fold.argmax(axis=1)\n",
        "\n",
        "    # Calculate metrics\n",
        "    acc = accuracy_score(y_val_fold_labels, y_pred_fold_labels)\n",
        "    f1 = f1_score(y_val_fold_labels, y_pred_fold_labels, average='weighted')\n",
        "\n",
        "    # Store the results\n",
        "    accuracy_scores.append(acc)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    # Print the classification report for the current fold\n",
        "    print(f\"Fold {len(accuracy_scores)} Classification Report:\")\n",
        "    print(classification_report(y_val_fold_labels, y_pred_fold_labels))\n",
        "\n",
        "# Print the average accuracy and F1 scores across all folds\n",
        "print(\"Cross-validation Accuracy scores:\", accuracy_scores)\n",
        "print(\"Mean accuracy:\", sum(accuracy_scores) / len(accuracy_scores))\n",
        "print(\"Cross-validation F1 scores:\", f1_scores)\n",
        "print(\"Mean F1 score:\", sum(f1_scores) / len(f1_scores))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPcOCYviLSMy",
        "outputId": "ef8d84bd-588b-4287-8252-4c03d6fd855f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Accuracy: 0.9132947976878613\n",
            "F1 Score: 0.9131920746625416\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.81      0.90        16\n",
            "           1       0.92      0.94      0.93       151\n",
            "           2       0.92      0.89      0.90       105\n",
            "           3       0.87      0.92      0.89        74\n",
            "\n",
            "    accuracy                           0.91       346\n",
            "   macro avg       0.93      0.89      0.91       346\n",
            "weighted avg       0.91      0.91      0.91       346\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "# y_pred = pipeline_teacher.predict(X_test)\n",
        "# y_pred = student_pipeline.predict(X_test)\n",
        "y_pred = student_pipeline.predict(X_test)\n",
        "\n",
        "# Convert the one-hot encoded predictions back to single class labels\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Convert the one-hot encoded test labels back to single class labels\n",
        "y_test_classes = np.argmax(y_encoded_test, axis=1)\n",
        "\n",
        "# Calculate accuracy and F1 score\n",
        "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
        "f1 = f1_score(y_test_classes, y_pred_classes, average='weighted')\n",
        "\n",
        "# Print the results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_classes, y_pred_classes))\n",
        "\n",
        "#teacher model\n",
        "# Accuracy: 0.930635838150289\n",
        "# F1 Score: 0.9307854001277291\n",
        "\n",
        "#student with 40 with kd\n",
        "# Accuracy: 0.9248554913294798\n",
        "# F1 Score: 0.924233662908216\n",
        "\n",
        "#student with 40 without KD\n",
        "# Accuracy: 0.9132947976878613\n",
        "# F1 Score: 0.9131920746625416\n",
        "\n",
        "#student with 8 with KD\n",
        "# Accuracy: 0.7716763005780347\n",
        "# F1 Score: 0.7716928231952385\n",
        "\n",
        "#student with 8 without kd\n",
        "# Accuracy: 0.7630057803468208\n",
        "# F1 Score: 0.763305091548424"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "58NJMmxCiF-v",
        "outputId": "9facc8ec-4030-4e32-ffa2-eebb6e7b2d72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4451 - loss: 1.2152\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5881 - loss: 0.9103\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7361 - loss: 0.7064\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7875 - loss: 0.5610\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8427 - loss: 0.4405\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8354 - loss: 0.5830\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8669 - loss: 0.3287\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9199 - loss: 0.2566\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9237 - loss: 0.2374\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9398 - loss: 0.1901\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9601 - loss: 0.1536\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9632 - loss: 0.1232\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9555 - loss: 0.1582\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9646 - loss: 0.0991\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9757 - loss: 0.0860\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9805 - loss: 0.0651\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9900 - loss: 0.0574\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0347\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9917 - loss: 0.0500\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9913 - loss: 0.0440\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9966 - loss: 0.0218\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9980 - loss: 0.0131\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9953 - loss: 0.0169\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9917 - loss: 0.0174\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9986 - loss: 0.0113\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9983 - loss: 0.0229\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0104\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9973 - loss: 0.0119\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9987 - loss: 0.0106\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9985 - loss: 0.0077\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9992 - loss: 0.0057\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9946 - loss: 0.0119\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9983 - loss: 0.0141\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9980 - loss: 0.0075\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 0.0021\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 0.0024\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0028\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0055\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.7119e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 7.5075e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.0644e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.6773e-04 \n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.4208e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.8381e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.0750e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.0858e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.0512e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.0797e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.9674e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.7548e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.3286e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 2.7531e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 2.6680e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.8272e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.1631e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4087e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.2983e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.1396e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.3632e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.9701e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.2201e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.7677e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7187e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.8049e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.4611e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.6922e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.5004e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2579e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2527e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.1721e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.2473e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.0720e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 8.6615e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 9.6974e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.7292e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.0912e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.0186e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 9.1343e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.0692e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 8.6321e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.5611e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 7.3894e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.0825e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.2299e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.0738e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1212e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.5982e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5250e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.8280e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.9639e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.5559e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.9829e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.4098e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.3300e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.0598e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6213e-05 \n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.1535e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3714e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.4265e-05\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Fold 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        12\n",
            "           1       1.00      1.00      1.00       115\n",
            "           2       1.00      1.00      1.00        75\n",
            "           3       1.00      1.00      1.00        75\n",
            "\n",
            "    accuracy                           1.00       277\n",
            "   macro avg       1.00      1.00      1.00       277\n",
            "weighted avg       1.00      1.00      1.00       277\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8126 - loss: 0.6704\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9158 - loss: 0.2550\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9564 - loss: 0.1536\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9782 - loss: 0.0689 \n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9832 - loss: 0.0613\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9709 - loss: 0.1054\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9945 - loss: 0.0246\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9973 - loss: 0.0167\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0061\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0026\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0019\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0019\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0012\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 9.7125e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 8.9988e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 7.9892e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 6.0858e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 8.0259e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.0218e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.4286e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.2267e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.0796e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.9364e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.4654e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.4563e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.7676e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.8952e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.8333e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.4782e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.9558e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.8028e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.0698e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.7519e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.1681e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.9780e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.5376e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.9533e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.5710e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.3047e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2348e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2709e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1289e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0840e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 9.0246e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.9431e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.0219e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 9.3772e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 1.0138e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 8.1690e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 9.1496e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 8.5045e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 9.2586e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.0537e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.3976e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.4835e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.3334e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.3827e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.4945e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.5929e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.0492e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5636e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.9774e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.3723e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6051e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.5888e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.8475e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.2959e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.6856e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 3.6216e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6338e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.7416e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.1742e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6742e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.7572e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.8131e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.7291e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5211e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2108e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.6543e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.5428e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.2010e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.2819e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.2340e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.1924e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.0623e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.8038e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 2.1267e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.5805e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.8688e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.8517e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.9951e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.5770e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2863e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.4181e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.4838e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3849e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2978e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1487e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0743e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1470e-05\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Fold 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        17\n",
            "           1       1.00      1.00      1.00       113\n",
            "           2       1.00      1.00      1.00        78\n",
            "           3       1.00      1.00      1.00        69\n",
            "\n",
            "    accuracy                           1.00       277\n",
            "   macro avg       1.00      1.00      1.00       277\n",
            "weighted avg       1.00      1.00      1.00       277\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9220 - loss: 0.3149\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9306 - loss: 0.2333\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9664 - loss: 0.4641\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9906 - loss: 0.0434\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0125\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9911 - loss: 0.0321\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9994 - loss: 0.0070\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9977 - loss: 0.0249\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9998 - loss: 0.0019\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9979 - loss: 0.0031\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9996 - loss: 0.0013\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.0645e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4231e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.8581e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3240e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.6767e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.0125e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.7908e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.4090e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.3104e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.0013e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.9915e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7344e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.7961e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.5608e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.4812e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 1.3803e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.2156e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1904e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1952e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.0936e-04 \n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0226e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 9.0538e-05\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.2187e-05\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.0791e-05\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2195e-05\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.9267e-05\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 8.3566e-05\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.8705e-05\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.0413e-05\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.2341e-05\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.9145e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 6.2781e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.3721e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.1533e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.4973e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.6253e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.5021e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.8170e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.0340e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.9902e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.0571e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.0600e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 3.2583e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.5600e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 3.3598e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.0551e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2481e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.9329e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 2.9463e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.0346e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.7614e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.6232e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.3275e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.2975e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.2638e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.2768e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.4533e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.1589e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.9295e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.0098e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.7048e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.3668e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.9426e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.4949e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.3625e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.6528e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.4621e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2929e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.2366e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.1303e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.0875e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.1761e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 1.2261e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.2963e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.1362e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2350e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.7047e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.1086e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 8.7718e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.5908e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.9900e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.3684e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.3583e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 8.4010e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1656e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.1642e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.0578e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.8865e-06\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Fold 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       1.00      1.00      1.00       115\n",
            "           2       1.00      1.00      1.00        75\n",
            "           3       1.00      1.00      1.00        79\n",
            "\n",
            "    accuracy                           1.00       276\n",
            "   macro avg       1.00      1.00      1.00       276\n",
            "weighted avg       1.00      1.00      1.00       276\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9481 - loss: 0.1701\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9476 - loss: 0.2858\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9957 - loss: 0.0222\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9979 - loss: 0.0107\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0024\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 8.2281e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.8862e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.7397e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.3556e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.6363e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.3250e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.7886e-05\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.0602e-05\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.3896e-05\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.9507e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.6736e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.0165e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.9075e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.4909e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.4396e-05\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.3588e-05\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.0188e-05\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 2.7973e-05\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 2.5022e-05\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.3809e-05\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4655e-05\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.3222e-05\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5688e-05\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.9370e-05\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.6499e-05\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.8091e-05\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.8984e-05\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.8729e-05\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.6491e-05\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.4560e-05\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2760e-05\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.5849e-05\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.3748e-05\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2117e-05\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.2239e-05\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.1234e-05\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.1379e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 9.9770e-06\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 1.0749e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.0114e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.9847e-06\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 8.7688e-06\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.0244e-06\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0255e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.9348e-06\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.4525e-06\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.8550e-06\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.8690e-06\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.7297e-06\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.4442e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.5737e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.3226e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.7819e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.1297e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.6464e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.7441e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.3252e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 4.9967e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.5985e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.8701e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7594e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.1411e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.9858e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5780e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7131e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.7716e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.2060e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5100e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.3320e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.9826e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.1722e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 3.4588e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 2.8779e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.2818e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.8900e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.5681e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.0356e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.9259e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.8476e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.6373e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.6147e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.6303e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.1992e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.0901e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.1790e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.9388e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.0919e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.9531e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.9036e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.8240e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 2.0038e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 2.0949e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.7091e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.5605e-06\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Fold 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        15\n",
            "           1       1.00      1.00      1.00       128\n",
            "           2       1.00      1.00      1.00        74\n",
            "           3       1.00      1.00      1.00        59\n",
            "\n",
            "    accuracy                           1.00       276\n",
            "   macro avg       1.00      1.00      1.00       276\n",
            "weighted avg       1.00      1.00      1.00       276\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9593 - loss: 0.1859\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9656 - loss: 0.1135\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9921 - loss: 0.0196\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9933 - loss: 0.0278\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0024\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9990 - loss: 0.0037\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.6966e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.6170e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.6762e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.0714e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.7217e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.1600e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 1.9666e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.6588e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.6287e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.5847e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2698e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1583e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 8.8007e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0295e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.5363e-05\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.0555e-05\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 8.1567e-05\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.1223e-05\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.5720e-05\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.8387e-05\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.3107e-05\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 6.0614e-05\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.1970e-05\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.7609e-05\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 4.3130e-05\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.6452e-05\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.2626e-05\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.0329e-05\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.9238e-05\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.9961e-05\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.7241e-05\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.6958e-05\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.9253e-05\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.3117e-05\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.1434e-05\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.0186e-05\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.1853e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.2504e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.7264e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.8132e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.9856e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 2.0248e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.7089e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.4121e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.4601e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.4020e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2816e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.4752e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2240e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.1044e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1117e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2270e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.4788e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.0778e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0079e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.1474e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.7795e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 8.6490e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 7.6128e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 9.5780e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 8.4665e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.0027e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.0478e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.6995e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.3062e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.0195e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.4532e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.7710e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.7147e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.9357e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.2982e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.0446e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.7984e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 4.9603e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 4.3718e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.8835e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6653e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.7640e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.5121e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.2102e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.9695e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.2833e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.3572e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.7738e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.4271e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.1197e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6439e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.7604e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.4090e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.4702e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.1090e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.0453e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.1007e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 2.0916e-06\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Fold 5 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        17\n",
            "           1       1.00      1.00      1.00        98\n",
            "           2       1.00      0.99      0.99        97\n",
            "           3       0.98      1.00      0.99        64\n",
            "\n",
            "    accuracy                           1.00       276\n",
            "   macro avg       1.00      1.00      1.00       276\n",
            "weighted avg       1.00      1.00      1.00       276\n",
            "\n",
            "Cross-validation Accuracy scores: [1.0, 1.0, 1.0, 1.0, 0.9963768115942029]\n",
            "Mean accuracy: 0.9992753623188406\n",
            "Cross-validation F1 scores: [1.0, 1.0, 1.0, 1.0, 0.9963814684616562]\n",
            "Mean F1 score: 0.9992762936923313\n"
          ]
        }
      ],
      "source": [
        "# Applying the KD for the TCN student model - 40 channels with the TCN teacher model\n",
        "\n",
        "# this model for only 40 pps signals with reduced layer and 5 fold cross validation\n",
        "\n",
        "def create_tcn_student_model():\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer(input_shape=(40, 1)))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, dilation_rate=1, activation='relu'))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, dilation_rate=2, activation='relu'))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, dilation_rate=2, activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(4, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "metrics3 = []\n",
        "\n",
        "# Define a custom callback to store loss and accuracy after each epoch\n",
        "class MetricsCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        loss = logs.get('loss')\n",
        "        accuracy = logs.get('accuracy')\n",
        "        metrics3.append({'epoch': epoch + 1, 'loss': loss, 'accuracy': accuracy})\n",
        "\n",
        "student_pipeline = Pipeline([\n",
        "    ('flatten', FlattenTransformer()),\n",
        "    ('standardize', StandardScaler()),\n",
        "    ('tcn', KerasClassifier(model=create_tcn_student_model(), epochs=100, batch_size=20, verbose=1, callbacks=[MetricsCallback()]))\n",
        "])\n",
        "\n",
        "# Set up 5-fold cross-validation\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store metrics for each fold\n",
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "# Perform cross-validation manually to get detailed metrics\n",
        "for train_idx, val_idx in kfold.split(X_train):\n",
        "    # Split the data into training and validation sets\n",
        "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
        "    y_train_fold, y_val_fold = y_encoded[train_idx], y_encoded[val_idx]\n",
        "\n",
        "    # Generate soft targets from Teacher Model for Student Training\n",
        "    # soft_targets = pipeline_teacher.predict(X_train_fold)\n",
        "    # Fit the model on the current fold\n",
        "    student_pipeline.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Predict on the validation set\n",
        "    y_pred_fold = pipeline_teacher.predict(X_val_fold)\n",
        "\n",
        "    # Convert predictions back to class labels (from one-hot encoding)\n",
        "    y_val_fold_labels = y_val_fold.argmax(axis=1)\n",
        "    y_pred_fold_labels = y_pred_fold.argmax(axis=1)\n",
        "\n",
        "    # Calculate metrics\n",
        "    acc = accuracy_score(y_val_fold_labels, y_pred_fold_labels)\n",
        "    f1 = f1_score(y_val_fold_labels, y_pred_fold_labels, average='weighted')\n",
        "\n",
        "    # Store the results\n",
        "    accuracy_scores.append(acc)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    # Print the classification report for the current fold\n",
        "    print(f\"Fold {len(accuracy_scores)} Classification Report:\")\n",
        "    print(classification_report(y_val_fold_labels, y_pred_fold_labels))\n",
        "\n",
        "# Print the average accuracy and F1 scores across all folds\n",
        "print(\"Cross-validation Accuracy scores:\", accuracy_scores)\n",
        "print(\"Mean accuracy:\", sum(accuracy_scores) / len(accuracy_scores))\n",
        "print(\"Cross-validation F1 scores:\", f1_scores)\n",
        "print(\"Mean F1 score:\", sum(f1_scores) / len(f1_scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3m6r23ssoWZP",
        "outputId": "d0233dcd-1a0b-45e0-b1b0-097e612f3708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m 1/56\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 30ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3621 - loss: 1.3004\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4666 - loss: 1.0893\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5189 - loss: 1.0147\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5344 - loss: 0.9687\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5822 - loss: 0.9239\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6248 - loss: 0.8670\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6704 - loss: 0.7930\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6721 - loss: 0.7529\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6498 - loss: 0.7488\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6779 - loss: 0.7267\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6909 - loss: 0.6908\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7111 - loss: 0.6615\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7224 - loss: 0.6197\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.5912\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7158 - loss: 0.6218\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7490 - loss: 0.5815\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7669 - loss: 0.5199\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8016 - loss: 0.4824\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7921 - loss: 0.4937\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8277 - loss: 0.4332\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8088 - loss: 0.4621\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8156 - loss: 0.4467\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8145 - loss: 0.4294\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8254 - loss: 0.4253\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8678 - loss: 0.3713\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8577 - loss: 0.3761\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8541 - loss: 0.3711\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8816 - loss: 0.3361\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8755 - loss: 0.3181\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8662 - loss: 0.3532\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8804 - loss: 0.3156\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8865 - loss: 0.2977\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8767 - loss: 0.3025\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8700 - loss: 0.3974\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8669 - loss: 0.3319\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9078 - loss: 0.2797\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9085 - loss: 0.2765\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8995 - loss: 0.2781\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8999 - loss: 0.2564\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9129 - loss: 0.3062\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8871 - loss: 0.2800\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9061 - loss: 0.2325\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9335 - loss: 0.2114\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9336 - loss: 0.2042\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9262 - loss: 0.2096\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9278 - loss: 0.1920\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9317 - loss: 0.1855\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9383 - loss: 0.1769\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2374\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9490 - loss: 0.1687\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9313 - loss: 0.1955\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9198 - loss: 0.2134\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9257 - loss: 0.2031\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9418 - loss: 0.1624\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9537 - loss: 0.1447\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9336 - loss: 0.1550\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1530\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.1393\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.1548\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.1340\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9467 - loss: 0.1616\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.1172\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9503 - loss: 0.1526\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9444 - loss: 0.1395\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.1150\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9686 - loss: 0.1020\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9399 - loss: 0.1563\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9377 - loss: 0.1752\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9674 - loss: 0.1407\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9396 - loss: 0.1365\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.1100\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9721 - loss: 0.0976\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9735 - loss: 0.0886\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9689 - loss: 0.0978\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9626 - loss: 0.1066\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9707 - loss: 0.1131\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9419 - loss: 0.1383\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9608 - loss: 0.1187\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9497 - loss: 0.1399\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9612 - loss: 0.1068\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9716 - loss: 0.0978\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9695 - loss: 0.0823\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9746 - loss: 0.0767\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9683 - loss: 0.0917\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9754 - loss: 0.0691\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0961\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9673 - loss: 0.0975\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9761 - loss: 0.0834\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0647\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9764 - loss: 0.0781\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9630 - loss: 0.1258\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9492 - loss: 0.1412\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9282 - loss: 0.2157\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9726 - loss: 0.0864\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9803 - loss: 0.0812\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.0738\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9756 - loss: 0.0811\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 0.0804\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9789 - loss: 0.0631\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9737 - loss: 0.0773\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Fold 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        12\n",
            "           1       1.00      1.00      1.00       115\n",
            "           2       1.00      1.00      1.00        75\n",
            "           3       1.00      1.00      1.00        75\n",
            "\n",
            "    accuracy                           1.00       277\n",
            "   macro avg       1.00      1.00      1.00       277\n",
            "weighted avg       1.00      1.00      1.00       277\n",
            "\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: 0.5261\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8887 - loss: 0.3424\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.2244\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9356 - loss: 0.1896\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9496 - loss: 0.1296\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9668 - loss: 0.1203\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9680 - loss: 0.1017\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9547 - loss: 0.1995\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9471 - loss: 0.1568\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1183\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.1178\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.1028\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9729 - loss: 0.0989\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9788 - loss: 0.0740\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.0858\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9737 - loss: 0.0864\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9693 - loss: 0.0822\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9734 - loss: 0.0738\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9784 - loss: 0.0738\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9638 - loss: 0.1056\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9801 - loss: 0.0720\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9813 - loss: 0.0661\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9742 - loss: 0.0813\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9831 - loss: 0.0654\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0541\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9809 - loss: 0.0622\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9645 - loss: 0.0930\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9623 - loss: 0.1330\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9157 - loss: 0.2604\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9445 - loss: 0.1976\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9592 - loss: 0.1050\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9716 - loss: 0.0804\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9669 - loss: 0.0962\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9762 - loss: 0.0711\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9823 - loss: 0.0616\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9806 - loss: 0.0646\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9904 - loss: 0.0438\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9856 - loss: 0.0542\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.0471\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0474\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9847 - loss: 0.0518\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9892 - loss: 0.0420\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0403\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0363\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0441\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9870 - loss: 0.0510\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9811 - loss: 0.0557\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9912 - loss: 0.0332\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.0465\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9957 - loss: 0.0313\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9805 - loss: 0.0537\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9857 - loss: 0.0449\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9885 - loss: 0.0403\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9902 - loss: 0.0392\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9847 - loss: 0.0482\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9933 - loss: 0.0363\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.0442\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9825 - loss: 0.0453\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.0428\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9774 - loss: 0.0436\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0366\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0431\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0278\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0461\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0349\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9869 - loss: 0.0469\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0808\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9332 - loss: 0.2226\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9214 - loss: 0.2092\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1124\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0540\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 0.0455\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9834 - loss: 0.0481\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0380\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.0299\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9956 - loss: 0.0301\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0332\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9909 - loss: 0.0283\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0198\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9898 - loss: 0.0327\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.0350\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9947 - loss: 0.0330\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9928 - loss: 0.0266\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9950 - loss: 0.0228\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0240\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0238\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0219\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0341\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0220\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0208\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0164\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.0213\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0227\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0242\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0199\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9915 - loss: 0.0278\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0179\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0309\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9903 - loss: 0.0334\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.0433\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Fold 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        17\n",
            "           1       1.00      1.00      1.00       113\n",
            "           2       1.00      1.00      1.00        78\n",
            "           3       1.00      1.00      1.00        69\n",
            "\n",
            "    accuracy                           1.00       277\n",
            "   macro avg       1.00      1.00      1.00       277\n",
            "weighted avg       1.00      1.00      1.00       277\n",
            "\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9471 - loss: 0.2023\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8888 - loss: 0.5371\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9061 - loss: 0.3659\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9383 - loss: 0.1556\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9740 - loss: 0.0784\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9721 - loss: 0.0929\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9802 - loss: 0.0601\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.0490\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9741 - loss: 0.0724\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.0402\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9851 - loss: 0.0434\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9915 - loss: 0.0476\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.0439\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0309\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9905 - loss: 0.0372\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0304\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9801 - loss: 0.0533\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9894 - loss: 0.0404\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0373\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0317\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9916 - loss: 0.0317\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9888 - loss: 0.0367\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9886 - loss: 0.0328\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9921 - loss: 0.0354\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9945 - loss: 0.0275\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9945 - loss: 0.0247\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9935 - loss: 0.0299\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9967 - loss: 0.0264\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9950 - loss: 0.0323\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9929 - loss: 0.0297\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9867 - loss: 0.0354\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.0251\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0197\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0208\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0246\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9902 - loss: 0.0295\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0229\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0169\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0197\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0192\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0215\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0299\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0184\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0280\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9862 - loss: 0.0423\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9977 - loss: 0.0143\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9912 - loss: 0.0289\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9966 - loss: 0.0178\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0147\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.0262\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9858 - loss: 0.0501\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.3951\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9404 - loss: 0.2508\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9454 - loss: 0.1997\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9860 - loss: 0.0616\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0252\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9910 - loss: 0.0315\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0244\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0336\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0187\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0182\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0192\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0137\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0173\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0230\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0148\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0222\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0192\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0146\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0120\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0215\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0135\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9953 - loss: 0.0166\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0149\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9986 - loss: 0.0116\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9992 - loss: 0.0126\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9817 - loss: 0.0340\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9956 - loss: 0.0138\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9936 - loss: 0.0241\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0152\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0141\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0147\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0163\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0107\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0093\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0122\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0181\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9950 - loss: 0.0202\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9835 - loss: 0.0985\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9359 - loss: 0.4492\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9409 - loss: 0.1821\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9552 - loss: 0.1698\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9757 - loss: 0.0488\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0236\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0207\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0123\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0136\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0135\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0160\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0090\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Fold 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       1.00      1.00      1.00       115\n",
            "           2       1.00      1.00      1.00        75\n",
            "           3       1.00      1.00      1.00        79\n",
            "\n",
            "    accuracy                           1.00       276\n",
            "   macro avg       1.00      1.00      1.00       276\n",
            "weighted avg       1.00      1.00      1.00       276\n",
            "\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.1009\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9707 - loss: 0.0888\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9682 - loss: 0.1107\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9892 - loss: 0.0400\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0240\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0191\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0152\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0148\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0151\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0163\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0125\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0180\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0133\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0208\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0117\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9953 - loss: 0.0162\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9958 - loss: 0.0144\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0094\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0102\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.0101\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9971 - loss: 0.0114\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0109\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9957 - loss: 0.0142\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 0.0161\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0103\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.0195\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0138\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0087\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0132\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0116\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0091\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0148\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0099\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0136\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0054\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0068\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0177\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0095\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0071\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0169\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0090\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9856 - loss: 0.0492\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0172\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9861 - loss: 0.0376\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9772 - loss: 0.0837\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9356 - loss: 0.2978\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9456 - loss: 0.1973\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.0741\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9856 - loss: 0.0408\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0327\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0131\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0159\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0117\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0106\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0052\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0075\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0057\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0099\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0065\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0055\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0061\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0056\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0037\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0043\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0090\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 0.0040\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 0.0079\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0042\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9970 - loss: 0.0069\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0061\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0072\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0105\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0054\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0135\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0069\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0050\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0034\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0040\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0059\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0031\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0087\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0039\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0049\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0039\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0042\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0048\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0093\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0047\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0069\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0100\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0042\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0095\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0131\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0066\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0059\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0040\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0023\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0085\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0038\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Fold 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        15\n",
            "           1       1.00      1.00      1.00       128\n",
            "           2       1.00      1.00      1.00        74\n",
            "           3       1.00      1.00      1.00        59\n",
            "\n",
            "    accuracy                           1.00       276\n",
            "   macro avg       1.00      1.00      1.00       276\n",
            "weighted avg       1.00      1.00      1.00       276\n",
            "\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9542 - loss: 0.2297\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9276 - loss: 0.3431\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.1346\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9894 - loss: 0.0382\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.1248\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0248\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9952 - loss: 0.0166\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0138\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 0.0106\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9977 - loss: 0.0110\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0110\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9941 - loss: 0.0119\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0074\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0073\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0079\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0119\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0085\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0072\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0067\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0080\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0071\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0055\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0117\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0057\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0040\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0031\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0069\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0051\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0060\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0040\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0044\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0038\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0042\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0045\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0028\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0047\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0028\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0035\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0049\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0085\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0137\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0084\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9807 - loss: 0.0910\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9909 - loss: 0.0330\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9728 - loss: 0.0823\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9354 - loss: 0.3267\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9855 - loss: 0.0605\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9939 - loss: 0.0167\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0077\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0051\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0040\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0041\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0039\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0035\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0030\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0023\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0024\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0026\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0023\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0029\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0024\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0034\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0028\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0019\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0022\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0021\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0028\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0017\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0016\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0015\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0018\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0014\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0016\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0019\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0023\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0035\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0023\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0016\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0018\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0014\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0014\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0014\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0020\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0019\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0017\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0016\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0041\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0027\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0020\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0069\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0053\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0152\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0055\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0167\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0130\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9903 - loss: 0.0464\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.2056\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9487 - loss: 0.2121\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9781 - loss: 0.0828\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9970 - loss: 0.0115\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Fold 5 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        17\n",
            "           1       1.00      1.00      1.00        98\n",
            "           2       1.00      0.99      0.99        97\n",
            "           3       0.98      1.00      0.99        64\n",
            "\n",
            "    accuracy                           1.00       276\n",
            "   macro avg       1.00      1.00      1.00       276\n",
            "weighted avg       1.00      1.00      1.00       276\n",
            "\n",
            "Cross-validation Accuracy scores: [1.0, 1.0, 1.0, 1.0, 0.9963768115942029]\n",
            "Mean accuracy: 0.9992753623188406\n",
            "Cross-validation F1 scores: [1.0, 1.0, 1.0, 1.0, 0.9963814684616562]\n",
            "Mean F1 score: 0.9992762936923313\n"
          ]
        }
      ],
      "source": [
        "# 40 channels with the TCN teacher model\n",
        "\n",
        "# this model for only 8 pps signals with reduced layer and 5 fold cross validation with and without KD\n",
        "\n",
        "def create_tcn_student_model():\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer(input_shape=(8, 1)))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, dilation_rate=1, activation='relu'))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, dilation_rate=2, activation='relu'))\n",
        "    # model.add(Conv1D(filters=64, kernel_size=3, dilation_rate=2, activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(4, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "metrics2 = []\n",
        "\n",
        "# Define a custom callback to store loss and accuracy after each epoch\n",
        "class MetricsCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        loss = logs.get('loss')\n",
        "        accuracy = logs.get('accuracy')\n",
        "        metrics2.append({'epoch': epoch + 1, 'loss': loss, 'accuracy': accuracy})\n",
        "\n",
        "student_pipeline2 = Pipeline([\n",
        "    ('flatten', FlattenTransformer()),\n",
        "    ('standardize', StandardScaler()),\n",
        "    ('tcn', KerasClassifier(model=create_tcn_student_model(), epochs=100, batch_size=20, verbose=1, callbacks=[MetricsCallback()]))\n",
        "])\n",
        "\n",
        "# Set up 5-fold cross-validation\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store metrics for each fold\n",
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "# Perform cross-validation manually to get detailed metrics\n",
        "for train_idx, val_idx in kfold.split(X_train):\n",
        "    # Split the data into training and validation sets\n",
        "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
        "    y_train_fold, y_val_fold = y_encoded[train_idx], y_encoded[val_idx]\n",
        "\n",
        "    # Generate soft targets from Teacher Model for Student Training\n",
        "    soft_targets = pipeline_teacher.predict(X_train_fold)\n",
        "    # Fit the model on the current fold\n",
        "    student_pipeline2.fit(X_train_fold[:,32:], soft_targets)\n",
        "\n",
        "    #training with hard labels\n",
        "\n",
        "    # student_pipeline2.fit(X_train_fold[:,32:], y_train_fold)\n",
        "\n",
        "    # Predict on the validation set\n",
        "    y_pred_fold = pipeline_teacher.predict(X_val_fold)\n",
        "\n",
        "    # Convert predictions back to class labels (from one-hot encoding)\n",
        "    y_val_fold_labels = y_val_fold.argmax(axis=1)\n",
        "    y_pred_fold_labels = y_pred_fold.argmax(axis=1)\n",
        "\n",
        "    # Calculate metrics\n",
        "    acc = accuracy_score(y_val_fold_labels, y_pred_fold_labels)\n",
        "    f1 = f1_score(y_val_fold_labels, y_pred_fold_labels, average='weighted')\n",
        "\n",
        "    # Store the results\n",
        "    accuracy_scores.append(acc)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    # Print the classification report for the current fold\n",
        "    print(f\"Fold {len(accuracy_scores)} Classification Report:\")\n",
        "    print(classification_report(y_val_fold_labels, y_pred_fold_labels))\n",
        "\n",
        "# Print the average accuracy and F1 scores across all folds\n",
        "print(\"Cross-validation Accuracy scores:\", accuracy_scores)\n",
        "print(\"Mean accuracy:\", sum(accuracy_scores) / len(accuracy_scores))\n",
        "print(\"Cross-validation F1 scores:\", f1_scores)\n",
        "print(\"Mean F1 score:\", sum(f1_scores) / len(f1_scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfPONoJa_XT6",
        "outputId": "e1ef5548-f566-4c8c-b6de-eff6e04ab4a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.1085710525512695, 0.7926556468009949, 0.6523367166519165, 0.5528551340103149, 0.48211047053337097, 0.44902074337005615, 0.34961968660354614, 0.34466788172721863, 0.3039117753505707, 0.2632679343223572, 0.19971542060375214, 0.19833801686763763, 0.16719837486743927, 0.163405641913414, 0.1586054116487503, 0.17343787848949432, 0.09492556750774384, 0.0799844041466713, 0.07739340513944626, 0.07218971103429794, 0.08463670313358307, 0.05054612457752228, 0.06099424138665199, 0.06689102202653885, 0.07069018483161926, 0.054340384900569916, 0.02396918460726738, 0.04149528965353966, 0.02959778718650341, 0.02758081443607807, 0.021096594631671906, 0.04451526328921318, 0.019938595592975616, 0.00995281245559454, 0.018440380692481995, 0.012651280499994755, 0.008875676430761814, 0.019730987027287483, 0.008406163193285465, 0.008798866532742977, 0.015423454344272614, 0.005528366658836603, 0.007734339218586683, 0.01580040343105793, 0.02710467204451561, 0.00729625066742301, 0.003423494752496481, 0.0026304256170988083, 0.0019298502011224627, 0.0015814501093700528, 0.0014977197861298919, 0.0014446449931710958, 0.0012395335361361504, 0.0011477085063233972, 0.0010697080288082361, 0.0010915746679529548, 0.0009243282256647944, 0.000876206555403769, 0.0008042408735491335, 0.000766618293710053, 0.0007402458577416837, 0.000658284465316683, 0.000633169140201062, 0.000602257321588695, 0.0005603911122307181, 0.0007452674326486886, 0.0013638186501339078, 0.03329427167773247, 0.113515205681324, 0.21995909512043, 0.07978729158639908, 0.06323458254337311, 0.016279881820082664, 0.006613282952457666, 0.0036733229644596577, 0.0028280112892389297, 0.002445625839754939, 0.002247824100777507, 0.001816297066397965, 0.0015000724233686924, 0.0012837575050070882, 0.0011830783914774656, 0.001025315374135971, 0.0009492665994912386, 0.0011803588131442666, 0.0008282674243673682, 0.0007313432870432734, 0.0006687350105494261, 0.0006247528363019228, 0.0005768646369688213, 0.0005448745214380324, 0.0005140508292242885, 0.00048209578380919993, 0.0004537409695331007, 0.0004281873407308012, 0.00040546926902607083, 0.00038230555946938694, 0.0003651710576377809, 0.0003455835103522986, 0.000322859879815951, 0.26535579562187195, 0.17372259497642517, 0.058276284486055374, 0.019392192363739014, 0.032387394458055496, 0.024311702698469162, 0.008797705173492432, 0.005822429433465004, 0.0033681809436529875, 0.0020382015500217676, 0.0018927688943222165, 0.001381237176246941, 0.0012170957634225488, 0.0010823734337463975, 0.0009697136119939387, 0.0008766615064814687, 0.0008077897364273667, 0.0007387626101262867, 0.0006776427617296576, 0.0006282377289608121, 0.0005812667077407241, 0.0005477190134115517, 0.0005100618582218885, 0.00048158556455746293, 0.0004441146447788924, 0.000417110015405342, 0.0003929000231437385, 0.000370227440726012, 0.0003431451041251421, 0.00032665900653228164, 0.00030894894734956324, 0.00029087011353112757, 0.00027891327044926584, 0.00026607338804751635, 0.0002546354371588677, 0.00023771502310410142, 0.00022691555204801261, 0.0002176411508116871, 0.00020573481742758304, 0.00019850482931360602, 0.0001890658459160477, 0.0001798812736524269, 0.00017227402713615447, 0.00016374919505324215, 0.00015673568123020232, 0.00015038117999210954, 0.0001450233394280076, 0.00013876156299374998, 0.00013215697254054248, 0.00012659413914661855, 0.0001222786377184093, 0.00011655050184344873, 0.00011163858289364725, 0.00010708242916734889, 0.00010420667967991903, 9.939902520272881e-05, 9.60226243478246e-05, 9.185484668705612e-05, 8.781323413131759e-05, 8.421402890235186e-05, 8.216856804210693e-05, 7.879288023104891e-05, 7.623928831890225e-05, 7.332432141993195e-05, 7.056852336972952e-05, 6.795220542699099e-05, 6.523647607536986e-05, 6.208118429640308e-05, 6.044332985766232e-05, 5.8204972447128966e-05, 5.5697069910820574e-05, 5.3386502258945256e-05, 5.176004924578592e-05, 4.980871744919568e-05, 4.7785531933186576e-05, 4.627177622751333e-05, 4.4536744098877534e-05, 4.286867624614388e-05, 4.109422297915444e-05, 4.000991248176433e-05, 3.8629626942565665e-05, 3.724959242390469e-05, 3.5971876059193164e-05, 3.484225817373954e-05, 3.415831088204868e-05, 3.2380925404140726e-05, 3.102925984421745e-05, 3.0148190489853732e-05, 2.90886437142035e-05, 2.8010685127810575e-05, 2.6850946596823633e-05, 2.6123820134671405e-05, 2.509975092834793e-05, 2.425010643491987e-05, 2.3447339117410593e-05, 2.237877379229758e-05, 2.1983927581459284e-05, 2.1143674530321732e-05, 2.0406048861332238e-05, 1.9689658074639738e-05, 0.3065115213394165, 0.12193907797336578, 0.06500989198684692, 0.03615199401974678, 0.011882084421813488, 0.010252490639686584, 0.011347921565175056, 0.0017947357846423984, 0.0015272650634869933, 0.001391405938193202, 0.0009701483650133014, 0.0008336234022863209, 0.0007340788142755628, 0.0006606291281059384, 0.0006010228535160422, 0.0005507923779077828, 0.0005019304808229208, 0.0004603673005476594, 0.0004256858956068754, 0.0003971674886997789, 0.0003669250290840864, 0.0003468721406534314, 0.0003209779679309577, 0.0002966241736430675, 0.000280761974863708, 0.00026400163187645376, 0.0002468698949087411, 0.0002328613627469167, 0.00022272720525506884, 0.0002104474260704592, 0.00019864144269376993, 0.00018879718845710158, 0.00018041787552647293, 0.0001701236906228587, 0.00016142913955263793, 0.00015627975517418236, 0.0001474451128160581, 0.00014180886500980705, 0.0001353528641629964, 0.0001301018928643316, 0.0001226127496920526, 0.00011899874516529962, 0.00011534037912497297, 0.00011366131366230547, 0.0001027086764224805, 9.849314665189013e-05, 9.468672215007246e-05, 9.056834824150428e-05, 8.746339153731242e-05, 8.313262515002862e-05, 8.083294960670173e-05, 7.617248775204644e-05, 7.362107862718403e-05, 7.150499732233584e-05, 6.787128222640604e-05, 6.592332647414878e-05, 6.252337334444746e-05, 6.07763540756423e-05, 5.8749930758494884e-05, 5.553870141739026e-05, 5.449584568850696e-05, 5.239443635218777e-05, 5.021339165978134e-05, 4.841774716624059e-05, 4.660613922169432e-05, 4.487249316298403e-05, 4.351145253167488e-05, 4.2125408072024584e-05, 4.284070382709615e-05, 3.8786463846918195e-05, 3.74577721231617e-05, 3.651190854725428e-05, 3.484366970951669e-05, 3.357205423526466e-05, 3.265100531280041e-05, 3.1370709621114656e-05, 2.9954069759696722e-05, 2.9510621970985085e-05, 2.778724956442602e-05, 2.7004276489606127e-05, 2.6019950382760726e-05, 2.5289235054515302e-05, 2.4173887140932493e-05, 2.340733408345841e-05, 2.2755531972507015e-05, 2.196602690673899e-05, 2.10633243113989e-05, 2.035059515037574e-05, 1.9899198377970606e-05, 1.919680471473839e-05, 1.851911292760633e-05, 1.8072048987960443e-05, 1.7194770407513715e-05, 1.6735286408220418e-05, 1.6039130059652962e-05, 1.5638541299267672e-05, 1.5127600818232168e-05, 1.4623085007769987e-05, 1.4064923561818432e-05, 1.3640517863677815e-05, 0.24288195371627808, 0.10112264752388, 0.018922582268714905, 0.006442966405302286, 0.001414549769833684, 0.0007046867976896465, 0.0005494999932125211, 0.00044782154145650566, 0.00039165053749457, 0.00033613177947700024, 0.0002991656365338713, 0.00026428201817907393, 0.00023818180488888174, 0.00021662279323209077, 0.00019848562078550458, 0.00018113890837412328, 0.00016593381587881595, 0.00015255610924214125, 0.00014111459313426167, 0.0001298751449212432, 0.00011866887507494539, 0.00011097289097961038, 0.0001014668305288069, 9.188664989778772e-05, 8.507131860824302e-05, 7.746402843622491e-05, 6.940086313989013e-05, 6.383946310961619e-05, 5.6804190535331145e-05, 5.327261897036806e-05, 4.854584040003829e-05, 4.493816595640965e-05, 4.029223055113107e-05, 3.7501562474062666e-05, 3.523494888213463e-05, 3.1855324778007343e-05, 3.025561454705894e-05, 2.795213003992103e-05, 2.6321753466618247e-05, 2.4748822397668846e-05, 2.3667516870773397e-05, 2.1583748093689792e-05, 2.1011852368246764e-05, 1.9966902982559986e-05, 1.8884154997067526e-05, 1.7894015400088392e-05, 1.683441223576665e-05, 1.5927123968140222e-05, 1.5186233213171363e-05, 1.4719088540005032e-05, 1.3782602763967589e-05, 1.3277624930196907e-05, 1.2996573786949739e-05, 1.2073405741830356e-05, 1.156986127170967e-05, 1.1079562682425603e-05, 1.076045555237215e-05, 1.015942598314723e-05, 9.937068170984276e-06, 9.423286428500433e-06, 9.077157301362604e-06, 8.652844371681567e-06, 8.57392205944052e-06, 7.860047844587825e-06, 7.721777365077287e-06, 7.468180683645187e-06, 7.274250947375549e-06, 6.81581286698929e-06, 6.578820375580108e-06, 6.272712653299095e-06, 6.2062226788839325e-06, 5.948858415649738e-06, 5.854537903360324e-06, 5.463106845127186e-06, 5.437773779704003e-06, 5.0408234528731555e-06, 5.136739218869479e-06, 5.023794983571861e-06, 4.6615518840553705e-06, 4.584051566780545e-06, 4.332389835326467e-06, 4.207049187243683e-06, 4.066498149768449e-06, 3.968642886320595e-06, 3.912810370820807e-06, 3.7225768210191745e-06, 3.683130216813879e-06, 3.4928973491332727e-06, 3.589143716453691e-06, 3.2727079997130204e-06, 3.2001682939153397e-06, 3.109198814854608e-06, 2.925544322351925e-06, 2.849020575013128e-06, 2.8009458219457883e-06, 2.7108424092148198e-06, 2.658460061866208e-06, 2.5579015527910087e-06, 2.524488536437275e-06, 2.4148737338691717e-06, 0.22363893687725067, 0.1502281129360199, 0.023621823638677597, 0.006332347635179758, 0.001872497727163136, 0.000966694438830018, 0.0007125987904146314, 0.0006010127835907042, 0.0005215650307945907, 0.0004587081784848124, 0.00040753220673650503, 0.00036428531166166067, 0.00032979491516016424, 0.00030130354571156204, 0.00027644570218399167, 0.0002539740817155689, 0.00023502302065026015, 0.00021831323101650923, 0.0002028248563874513, 0.0001885253586806357, 0.00017592089716345072, 0.0001669676130404696, 0.00015619168698322028, 0.00014717601879965514, 0.00013881399354431778, 0.0001312276435783133, 0.00012422254076227546, 0.00011755467858165503, 0.00011163011367898434, 0.00010595310595817864, 0.00010124602704308927, 9.625086386222392e-05, 9.16228091227822e-05, 8.801868534646928e-05, 8.378655911656097e-05, 8.029406308196485e-05, 7.626345905009657e-05, 7.29049788787961e-05, 6.999429751886055e-05, 6.695453339489177e-05, 6.432709051296115e-05, 6.15862591075711e-05, 5.9205682191532105e-05, 5.667793448083103e-05, 5.461345426738262e-05, 5.226958091952838e-05, 5.026809230912477e-05, 4.8392070311820135e-05, 4.646689194487408e-05, 4.4678658014163375e-05, 4.3196567276027054e-05, 4.155074566369876e-05, 3.9989641663851216e-05, 3.856279363390058e-05, 3.736574581125751e-05, 3.605729580158368e-05, 3.4554464946268126e-05, 3.326703154016286e-05, 3.2179468689719215e-05, 3.1067582312971354e-05, 2.996253351739142e-05, 2.8979682610952295e-05, 2.792990744637791e-05, 2.7049565687775612e-05, 2.6014460672740825e-05, 2.5322431611130014e-05, 2.44123293668963e-05, 2.3692677132203244e-05, 2.2776199330110103e-05, 2.2070767954573967e-05, 2.1354084310587496e-05, 2.0684537958004512e-05, 1.9921342754969373e-05, 1.9288991097710095e-05, 1.8711580196395516e-05, 1.8031381841865368e-05, 1.7423257304471917e-05, 1.689767486823257e-05, 1.6413141565863043e-05, 1.5834106307011098e-05, 1.532588248664979e-05, 1.485904158471385e-05, 1.4416322301258333e-05, 1.4008292964717839e-05, 1.353195693809539e-05, 1.3111437510815449e-05, 1.2741240425384603e-05, 1.2336778127064463e-05, 1.191938736155862e-05, 1.1636578165052924e-05, 1.125248491007369e-05, 1.0939727872028016e-05, 1.0601322173897643e-05, 1.025515030050883e-05, 9.962871445168275e-06, 9.6503190434305e-06, 9.354482244816609e-06, 9.048082574736327e-06, 8.808395250525791e-06, 8.526777492079418e-06]\n",
            "[0.47873303294181824, 0.6841629147529602, 0.762895941734314, 0.7990950345993042, 0.8190045356750488, 0.85158371925354, 0.8751131296157837, 0.8859728574752808, 0.9031674265861511, 0.9140271544456482, 0.9339366555213928, 0.9375565648078918, 0.955656111240387, 0.9538461565971375, 0.9529411792755127, 0.9583710432052612, 0.9773755669593811, 0.9819004535675049, 0.9819004535675049, 0.9891402721405029, 0.9855203628540039, 0.9882352948188782, 0.9864253401756287, 0.9846153855323792, 0.9819004535675049, 0.9891402721405029, 0.9954751133918762, 0.9900452494621277, 0.9954751133918762, 0.996380090713501, 0.996380090713501, 0.9918552041053772, 0.9972850680351257, 0.9981900453567505, 0.9981900453567505, 0.9990950226783752, 0.9990950226783752, 0.9981900453567505, 0.9981900453567505, 0.9990950226783752, 0.9972850680351257, 0.9990950226783752, 0.9972850680351257, 0.9972850680351257, 0.9972850680351257, 0.9981900453567505, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9990950226783752, 0.9954751133918762, 0.9737556576728821, 0.9330316781997681, 0.9800904989242554, 0.9900452494621277, 0.996380090713501, 0.9990950226783752, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9303167462348938, 0.9438914060592651, 0.9819004535675049, 0.9954751133918762, 0.9882352948188782, 0.992760181427002, 0.9981900453567505, 0.9990950226783752, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9222423434257507, 0.965641975402832, 0.9837251305580139, 0.9936708807945251, 0.9972875118255615, 0.9981916546821594, 0.9981916546821594, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9547920227050781, 0.9746835231781006, 0.9918625950813293, 0.9981916546821594, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9502712488174438, 0.9755877256393433, 0.9927667379379272, 0.9990958571434021, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
          ]
        }
      ],
      "source": [
        "teacherloss = []\n",
        "teacheracc = []\n",
        "nstudloss = []\n",
        "nstudacc = []\n",
        "studloss = []\n",
        "studacc = []\n",
        "\n",
        "# metrics = metrics[:100]\n",
        "for item in metrics:\n",
        "    teacherloss.append(item['loss'])\n",
        "    teacheracc.append(item['accuracy'])\n",
        "for item in metrics2:\n",
        "    nstudloss.append(item['loss'])\n",
        "    nstudacc.append(item['accuracy'])\n",
        "for item in metrics3:\n",
        "    studloss.append(item['loss'])\n",
        "    studacc.append(item['accuracy'])\n",
        "print(teacherloss)\n",
        "print(teacheracc)\n",
        "# print(studloss)\n",
        "# print(studacc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# epochs = list(range(1, 501))\n",
        "# plt.plot(epochs, teacheracc, label='Teacher Model accuracy', color = \"blue\")\n",
        "# plt.plot(epochs, studacc, label='Student Model(Distillation) accuracy', color = \"green\")\n",
        "# plt.plot(epochs, nstudacc, label='Student Model(No Distillation) accuracy', color = \"red\")\n",
        "# plt.title('Epochs vs Accuracy')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.legend()\n",
        "# plt.grid()\n",
        "epochs = list(range(1, 501))\n",
        "plt.plot(epochs, teacherloss, label='Teacher Model Loss', color = \"blue\")\n",
        "plt.plot(epochs, studloss, label='Student Model(Distillation) Loss', color = \"green\")\n",
        "plt.plot(epochs, nstudloss, label='Student Model(No Distillation) Loss', color = \"red\")\n",
        "plt.title('Epochs vs Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "# plt.grid()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "gF-6h8VbHxA_",
        "outputId": "798aa49d-86a4-414d-c31c-5b0ad7c3b5cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7e548fc9dc90>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89Q6FZKYlkYz",
        "outputId": "d0f4c6c3-1fb1-4a3e-98eb-343f54ce0047"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Accuracy: 0.7832369942196532\n",
            "F1 Score: 0.7832315378488834\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.62      0.65        16\n",
            "           1       0.82      0.79      0.81       151\n",
            "           2       0.76      0.77      0.77       105\n",
            "           3       0.76      0.81      0.78        74\n",
            "\n",
            "    accuracy                           0.78       346\n",
            "   macro avg       0.75      0.75      0.75       346\n",
            "weighted avg       0.78      0.78      0.78       346\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = student_pipeline.predict(X_test[:, 32:])\n",
        "\n",
        "# Convert the one-hot encoded predictions back to single class labels\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Convert the one-hot encoded test labels back to single class labels\n",
        "y_test_classes = np.argmax(y_encoded_test, axis=1)\n",
        "\n",
        "# Calculate accuracy and F1 score\n",
        "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
        "f1 = f1_score(y_test_classes, y_pred_classes, average='weighted')\n",
        "\n",
        "# Print the results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_classes, y_pred_classes))\n",
        "\n",
        "# 18/18 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step with kd\n",
        "# Accuracy: 0.9219653179190751\n",
        "# F1 Score: 0.9220532842731181\n",
        "\n",
        "# 18/18 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step\n",
        "# Accuracy: 0.7832369942196532\n",
        "# F1 Score: 0.7832315378488834\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pipeline_teacher.named_steps['tcn'].model_.summary())\n",
        "print(student_pipeline.named_steps['tcn'].model_.summary())\n",
        "print(student_pipeline2.named_steps['tcn'].model_.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "id": "XleW9WrfbAyv",
        "outputId": "e5418543-dc86-42fb-e67c-b37393cde892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_15 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m12,352\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2176\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_56 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m278,656\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_57 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m516\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2176</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">278,656</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875,342\u001b[0m (3.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875,342</span> (3.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m291,780\u001b[0m (1.11 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">291,780</span> (1.11 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m583,562\u001b[0m (2.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">583,562</span> (2.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_21\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_21\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_23 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_24 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m12,352\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_25 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m12,352\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_11 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1920\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_64 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m245,888\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_65 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m516\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">245,888</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m814,094\u001b[0m (3.11 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">814,094</span> (3.11 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m271,364\u001b[0m (1.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">271,364</span> (1.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m542,730\u001b[0m (2.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">542,730</span> (2.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_20\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_20\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_21 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_22 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │          \u001b[38;5;34m12,352\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_10 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_62 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_63 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m516\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m88,910\u001b[0m (347.31 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">88,910</span> (347.31 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,636\u001b[0m (115.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,636</span> (115.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m59,274\u001b[0m (231.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">59,274</span> (231.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6syUbh_cTxgW"
      },
      "source": [
        "## Using CNN and LSTM hybrid for both teacher and student model\n",
        "<p>Teacher model with 40 channels: accuracy - 77.75, f1 score - 78.27</p>\n",
        "<p>student model with 8 channels and KD: accuracy - , f1 score - </p>\n",
        "<p>student model with 40 channels and without KD: accuracy - , f1 score - </p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYXEQQNYT4jb"
      },
      "outputs": [],
      "source": [
        "eeg_signals_train = X_train[:, :32]\n",
        "phys_signals_train = X_train[:, 32:]\n",
        "eeg_signals_test = X_test[:, :32]\n",
        "phys_signals_test = X_test[:, 32:]\n",
        "X_train_EEG = eeg_signals_train\n",
        "X_train_Phys = phys_signals_train\n",
        "X_test_EEG = eeg_signals_test\n",
        "X_test_Phys = phys_signals_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cXMJLB4Y5pt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, losses, optimizers\n",
        "\n",
        "def create_teacher_model():\n",
        "    input_eeg = layers.Input(shape=(32,))\n",
        "    input_phys = layers.Input(shape=(8,))\n",
        "\n",
        "    # CNN branch for EEG signals\n",
        "    x_eeg = layers.Reshape((32, 1))(input_eeg)\n",
        "    x_eeg = layers.Conv1D(64, kernel_size=3, activation='relu')(x_eeg)\n",
        "    x_eeg = layers.MaxPooling1D(pool_size=2)(x_eeg)\n",
        "    x_eeg = layers.Conv1D(128, kernel_size=3, activation='relu')(x_eeg)\n",
        "    x_eeg = layers.MaxPooling1D(pool_size=2)(x_eeg)\n",
        "    x_eeg = layers.Flatten()(x_eeg)\n",
        "\n",
        "    # LSTM branch for physiological signals\n",
        "    x_phys = layers.Reshape((8, 1))(input_phys)\n",
        "    x_phys = layers.LSTM(64, return_sequences=False)(x_phys)\n",
        "\n",
        "    # Combine both branches\n",
        "    combined = layers.Concatenate()([x_eeg, x_phys])\n",
        "    combined = layers.Dense(128, activation='relu')(combined)\n",
        "    output = layers.Dense(4, activation='softmax')(combined)\n",
        "\n",
        "    model = models.Model(inputs=[input_eeg, input_phys], outputs=output)\n",
        "    return model\n",
        "\n",
        "teacher_model = create_teacher_model()\n",
        "teacher_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-mMeRh6pZDYn",
        "outputId": "a00b06b1-e66e-4b2e-866b-c5039e74bd58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4803 - loss: 1.1972 - val_accuracy: 0.5578 - val_loss: 1.0412\n",
            "Epoch 2/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5514 - loss: 1.0651 - val_accuracy: 0.5838 - val_loss: 0.9475\n",
            "Epoch 3/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5761 - loss: 0.9331 - val_accuracy: 0.6185 - val_loss: 0.8970\n",
            "Epoch 4/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6119 - loss: 0.8800 - val_accuracy: 0.6676 - val_loss: 0.8231\n",
            "Epoch 5/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6741 - loss: 0.8117 - val_accuracy: 0.6936 - val_loss: 0.7812\n",
            "Epoch 6/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6760 - loss: 0.7404 - val_accuracy: 0.6908 - val_loss: 0.7355\n",
            "Epoch 7/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7213 - loss: 0.7262 - val_accuracy: 0.7457 - val_loss: 0.6629\n",
            "Epoch 8/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7641 - loss: 0.6225 - val_accuracy: 0.7225 - val_loss: 0.7018\n",
            "Epoch 9/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7856 - loss: 0.5796 - val_accuracy: 0.7717 - val_loss: 0.6210\n",
            "Epoch 10/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7883 - loss: 0.5633 - val_accuracy: 0.7717 - val_loss: 0.6606\n",
            "Epoch 11/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8031 - loss: 0.5253 - val_accuracy: 0.7717 - val_loss: 0.6235\n",
            "Epoch 12/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8162 - loss: 0.4722 - val_accuracy: 0.7543 - val_loss: 0.6394\n",
            "Epoch 13/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8106 - loss: 0.4973 - val_accuracy: 0.7861 - val_loss: 0.6356\n",
            "Epoch 14/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8376 - loss: 0.4266 - val_accuracy: 0.8382 - val_loss: 0.5445\n",
            "Epoch 15/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8481 - loss: 0.3909 - val_accuracy: 0.8324 - val_loss: 0.5073\n",
            "Epoch 16/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8598 - loss: 0.3523 - val_accuracy: 0.8121 - val_loss: 0.5210\n",
            "Epoch 17/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8637 - loss: 0.3428 - val_accuracy: 0.8006 - val_loss: 0.5539\n",
            "Epoch 18/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8753 - loss: 0.3677 - val_accuracy: 0.8208 - val_loss: 0.5080\n",
            "Epoch 19/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8805 - loss: 0.3247 - val_accuracy: 0.8324 - val_loss: 0.4920\n",
            "Epoch 20/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8896 - loss: 0.2848 - val_accuracy: 0.8439 - val_loss: 0.4834\n",
            "Epoch 21/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8936 - loss: 0.2679 - val_accuracy: 0.8584 - val_loss: 0.4394\n",
            "Epoch 22/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9237 - loss: 0.2605 - val_accuracy: 0.8526 - val_loss: 0.5001\n",
            "Epoch 23/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8980 - loss: 0.2524 - val_accuracy: 0.8324 - val_loss: 0.5400\n",
            "Epoch 24/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9033 - loss: 0.2541 - val_accuracy: 0.8324 - val_loss: 0.5911\n",
            "Epoch 25/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9057 - loss: 0.2492 - val_accuracy: 0.8699 - val_loss: 0.4753\n",
            "Epoch 26/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9317 - loss: 0.2047 - val_accuracy: 0.8613 - val_loss: 0.4613\n",
            "Epoch 27/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9372 - loss: 0.1987 - val_accuracy: 0.8699 - val_loss: 0.4466\n",
            "Epoch 28/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9385 - loss: 0.1925 - val_accuracy: 0.8584 - val_loss: 0.5012\n",
            "Epoch 29/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9437 - loss: 0.1709 - val_accuracy: 0.8410 - val_loss: 0.5160\n",
            "Epoch 30/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9137 - loss: 0.2567 - val_accuracy: 0.8728 - val_loss: 0.4622\n",
            "Epoch 31/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9485 - loss: 0.1606 - val_accuracy: 0.8786 - val_loss: 0.4641\n",
            "Epoch 32/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9466 - loss: 0.1529 - val_accuracy: 0.8642 - val_loss: 0.4874\n",
            "Epoch 33/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9582 - loss: 0.1337 - val_accuracy: 0.8555 - val_loss: 0.5389\n",
            "Epoch 34/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9584 - loss: 0.1446 - val_accuracy: 0.8786 - val_loss: 0.4462\n",
            "Epoch 35/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9595 - loss: 0.1312 - val_accuracy: 0.8439 - val_loss: 0.5528\n",
            "Epoch 36/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9553 - loss: 0.1489 - val_accuracy: 0.8555 - val_loss: 0.5369\n",
            "Epoch 37/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9757 - loss: 0.1029 - val_accuracy: 0.8757 - val_loss: 0.4769\n",
            "Epoch 38/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9789 - loss: 0.1006 - val_accuracy: 0.8757 - val_loss: 0.4922\n",
            "Epoch 39/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9586 - loss: 0.1313 - val_accuracy: 0.8988 - val_loss: 0.4650\n",
            "Epoch 40/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9663 - loss: 0.1185 - val_accuracy: 0.8960 - val_loss: 0.4470\n",
            "Epoch 41/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9707 - loss: 0.1128 - val_accuracy: 0.8844 - val_loss: 0.4682\n",
            "Epoch 42/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9818 - loss: 0.0899 - val_accuracy: 0.8873 - val_loss: 0.4629\n",
            "Epoch 43/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9843 - loss: 0.0760 - val_accuracy: 0.8960 - val_loss: 0.4445\n",
            "Epoch 44/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9793 - loss: 0.0867 - val_accuracy: 0.8902 - val_loss: 0.4684\n",
            "Epoch 45/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9661 - loss: 0.0914 - val_accuracy: 0.8613 - val_loss: 0.5243\n",
            "Epoch 46/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9774 - loss: 0.0929 - val_accuracy: 0.8988 - val_loss: 0.4552\n",
            "Epoch 47/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9740 - loss: 0.0819 - val_accuracy: 0.8786 - val_loss: 0.5379\n",
            "Epoch 48/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9814 - loss: 0.0678 - val_accuracy: 0.8873 - val_loss: 0.4814\n",
            "Epoch 49/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9854 - loss: 0.0676 - val_accuracy: 0.8873 - val_loss: 0.4969\n",
            "Epoch 50/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9839 - loss: 0.0531 - val_accuracy: 0.8931 - val_loss: 0.5430\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cb61a0e2770>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "teacher_model.fit([eeg_signals_train, phys_signals_train], y_train, epochs=50, validation_data=([eeg_signals_test, phys_signals_test], y_test))\n",
        "# Accuracy: 0.8931\n",
        "# F1 Score: 0.8944"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9wQxEO5ZpR6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, losses, optimizers\n",
        "\n",
        "def create_student_model():\n",
        "    input_phys = layers.Input(shape=(8,))\n",
        "\n",
        "    # LSTM branch for physiological signals\n",
        "    x_phys = layers.Reshape((8, 1))(input_phys)\n",
        "    x_phys = layers.Conv1D(64, kernel_size=2, activation='relu')(x_phys)\n",
        "    x_phys = layers.MaxPooling1D(pool_size=2)(x_phys)\n",
        "    x_phys = layers.LSTM(64, return_sequences=False)(x_phys)\n",
        "\n",
        "    x_phys = layers.Dense(64, activation='relu')(x_phys)\n",
        "    output = layers.Dense(4, activation='softmax')(x_phys)\n",
        "\n",
        "    model = models.Model(inputs=[input_phys], outputs=output)\n",
        "    return model\n",
        "\n",
        "student_model = create_student_model()\n",
        "student_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AeDSlza6aJkG",
        "outputId": "33d1a29b-d428-462f-a922-e57a1b387058"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.3354 - loss: 1.3576 - val_accuracy: 0.5116 - val_loss: 1.1228\n",
            "Epoch 2/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4474 - loss: 1.1822 - val_accuracy: 0.5116 - val_loss: 1.1305\n",
            "Epoch 3/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4502 - loss: 1.1670 - val_accuracy: 0.5058 - val_loss: 1.0921\n",
            "Epoch 4/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5010 - loss: 1.1380 - val_accuracy: 0.5578 - val_loss: 1.0769\n",
            "Epoch 5/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4946 - loss: 1.1109 - val_accuracy: 0.4827 - val_loss: 1.1038\n",
            "Epoch 6/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5011 - loss: 1.1026 - val_accuracy: 0.4913 - val_loss: 1.0946\n",
            "Epoch 7/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4571 - loss: 1.1219 - val_accuracy: 0.5000 - val_loss: 1.1066\n",
            "Epoch 8/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.4877 - loss: 1.0995 - val_accuracy: 0.4971 - val_loss: 1.0795\n",
            "Epoch 9/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5180 - loss: 1.0669 - val_accuracy: 0.4740 - val_loss: 1.1206\n",
            "Epoch 10/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4847 - loss: 1.1106 - val_accuracy: 0.5087 - val_loss: 1.1195\n",
            "Epoch 11/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4958 - loss: 1.0990 - val_accuracy: 0.5318 - val_loss: 1.0849\n",
            "Epoch 12/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4985 - loss: 1.0765 - val_accuracy: 0.5462 - val_loss: 1.0568\n",
            "Epoch 13/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5430 - loss: 1.0544 - val_accuracy: 0.5462 - val_loss: 1.0769\n",
            "Epoch 14/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5513 - loss: 1.0536 - val_accuracy: 0.5173 - val_loss: 1.0755\n",
            "Epoch 15/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5410 - loss: 1.0437 - val_accuracy: 0.4913 - val_loss: 1.0933\n",
            "Epoch 16/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5508 - loss: 1.0508 - val_accuracy: 0.5029 - val_loss: 1.0828\n",
            "Epoch 17/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5247 - loss: 1.0485 - val_accuracy: 0.5405 - val_loss: 1.0774\n",
            "Epoch 18/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5092 - loss: 1.0615 - val_accuracy: 0.5231 - val_loss: 1.0813\n",
            "Epoch 19/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5249 - loss: 1.0375 - val_accuracy: 0.5173 - val_loss: 1.0753\n",
            "Epoch 20/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5261 - loss: 1.0469 - val_accuracy: 0.5145 - val_loss: 1.1043\n",
            "Epoch 21/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5484 - loss: 0.9901 - val_accuracy: 0.5520 - val_loss: 1.0745\n",
            "Epoch 22/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5357 - loss: 1.0346 - val_accuracy: 0.5260 - val_loss: 1.0814\n",
            "Epoch 23/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5665 - loss: 0.9875 - val_accuracy: 0.4711 - val_loss: 1.1206\n",
            "Epoch 24/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5233 - loss: 1.0327 - val_accuracy: 0.5289 - val_loss: 1.0676\n",
            "Epoch 25/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5474 - loss: 1.0098 - val_accuracy: 0.5434 - val_loss: 1.0740\n",
            "Epoch 26/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5525 - loss: 1.0431 - val_accuracy: 0.5520 - val_loss: 1.0759\n",
            "Epoch 27/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5415 - loss: 1.0545 - val_accuracy: 0.5520 - val_loss: 1.0900\n",
            "Epoch 28/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5186 - loss: 1.0596 - val_accuracy: 0.5260 - val_loss: 1.0685\n",
            "Epoch 29/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5565 - loss: 1.0116 - val_accuracy: 0.5665 - val_loss: 1.0729\n",
            "Epoch 30/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5515 - loss: 1.0045 - val_accuracy: 0.5549 - val_loss: 1.0753\n",
            "Epoch 31/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5645 - loss: 0.9951 - val_accuracy: 0.5202 - val_loss: 1.0779\n",
            "Epoch 32/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5614 - loss: 1.0020 - val_accuracy: 0.5780 - val_loss: 1.0438\n",
            "Epoch 33/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5765 - loss: 0.9760 - val_accuracy: 0.5347 - val_loss: 1.0738\n",
            "Epoch 34/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5955 - loss: 0.9526 - val_accuracy: 0.5376 - val_loss: 1.0543\n",
            "Epoch 35/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5737 - loss: 0.9813 - val_accuracy: 0.5520 - val_loss: 1.0703\n",
            "Epoch 36/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5759 - loss: 0.9778 - val_accuracy: 0.4855 - val_loss: 1.1229\n",
            "Epoch 37/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5574 - loss: 0.9569 - val_accuracy: 0.5202 - val_loss: 1.0953\n",
            "Epoch 38/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5700 - loss: 0.9866 - val_accuracy: 0.5116 - val_loss: 1.1009\n",
            "Epoch 39/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5564 - loss: 0.9797 - val_accuracy: 0.4971 - val_loss: 1.1356\n",
            "Epoch 40/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5526 - loss: 0.9956 - val_accuracy: 0.4798 - val_loss: 1.1119\n",
            "Epoch 41/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5741 - loss: 0.9555 - val_accuracy: 0.5491 - val_loss: 1.0912\n",
            "Epoch 42/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5693 - loss: 0.9437 - val_accuracy: 0.5578 - val_loss: 1.0884\n",
            "Epoch 43/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6019 - loss: 0.9265 - val_accuracy: 0.5173 - val_loss: 1.0711\n",
            "Epoch 44/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5841 - loss: 0.9215 - val_accuracy: 0.5116 - val_loss: 1.0863\n",
            "Epoch 45/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5837 - loss: 0.9156 - val_accuracy: 0.4682 - val_loss: 1.1461\n",
            "Epoch 46/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5588 - loss: 0.9804 - val_accuracy: 0.5260 - val_loss: 1.0547\n",
            "Epoch 47/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5683 - loss: 0.9706 - val_accuracy: 0.5491 - val_loss: 1.0756\n",
            "Epoch 48/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5630 - loss: 0.9764 - val_accuracy: 0.5520 - val_loss: 1.0790\n",
            "Epoch 49/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5431 - loss: 0.9576 - val_accuracy: 0.5491 - val_loss: 1.0457\n",
            "Epoch 50/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5569 - loss: 0.9747 - val_accuracy: 0.5491 - val_loss: 1.0696\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cb619359f60>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "student_model.fit([phys_signals_train], y_train, epochs=50, validation_data=([phys_signals_test], y_test))\n",
        "\n",
        "# Accuracy: 0.5491\n",
        "# F1 Score: 0.5251"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import Callback\n",
        "\n",
        "# Define a custom callback to store loss and accuracy for training and validation\n",
        "class LossAccuracyHistory(Callback):\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.train_losses = []\n",
        "        self.train_accuracies = []\n",
        "        self.val_losses = []\n",
        "        self.val_accuracies = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Store training loss and accuracy\n",
        "        self.train_losses.append(logs.get('loss'))\n",
        "        self.train_accuracies.append(logs.get('accuracy'))\n",
        "        # Store validation loss and accuracy\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        self.val_accuracies.append(logs.get('val_accuracy'))\n",
        "\n",
        "# Instantiate the callback\n",
        "history_callback = LossAccuracyHistory()\n",
        "\n",
        "# Fit the student model\n",
        "student_model.fit(\n",
        "    [phys_signals_train], y_train,\n",
        "    epochs=100,\n",
        "    validation_data=([phys_signals_test], y_test),\n",
        "    callbacks=[history_callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlAuXwSgL3RG",
        "outputId": "7ecb0e72-8dd7-4736-c585-c14c3bed628f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.3582 - loss: 1.2966 - val_accuracy: 0.4884 - val_loss: 1.1278\n",
            "Epoch 2/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4658 - loss: 1.1790 - val_accuracy: 0.5087 - val_loss: 1.1267\n",
            "Epoch 3/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4683 - loss: 1.1647 - val_accuracy: 0.4740 - val_loss: 1.1175\n",
            "Epoch 4/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4672 - loss: 1.1158 - val_accuracy: 0.4769 - val_loss: 1.1217\n",
            "Epoch 5/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4637 - loss: 1.1314 - val_accuracy: 0.5231 - val_loss: 1.0851\n",
            "Epoch 6/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4802 - loss: 1.1028 - val_accuracy: 0.4884 - val_loss: 1.1346\n",
            "Epoch 7/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4636 - loss: 1.1138 - val_accuracy: 0.5058 - val_loss: 1.0846\n",
            "Epoch 8/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4970 - loss: 1.0848 - val_accuracy: 0.5058 - val_loss: 1.0862\n",
            "Epoch 9/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4967 - loss: 1.1209 - val_accuracy: 0.5289 - val_loss: 1.0955\n",
            "Epoch 10/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5023 - loss: 1.0952 - val_accuracy: 0.5289 - val_loss: 1.0959\n",
            "Epoch 11/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4916 - loss: 1.0843 - val_accuracy: 0.5145 - val_loss: 1.0748\n",
            "Epoch 12/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4885 - loss: 1.0945 - val_accuracy: 0.4682 - val_loss: 1.1032\n",
            "Epoch 13/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5096 - loss: 1.0859 - val_accuracy: 0.5000 - val_loss: 1.1013\n",
            "Epoch 14/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5003 - loss: 1.1112 - val_accuracy: 0.4538 - val_loss: 1.1283\n",
            "Epoch 15/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4746 - loss: 1.0904 - val_accuracy: 0.5029 - val_loss: 1.0827\n",
            "Epoch 16/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5199 - loss: 1.0592 - val_accuracy: 0.4798 - val_loss: 1.1267\n",
            "Epoch 17/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4947 - loss: 1.0779 - val_accuracy: 0.5173 - val_loss: 1.0795\n",
            "Epoch 18/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5142 - loss: 1.0848 - val_accuracy: 0.4942 - val_loss: 1.0890\n",
            "Epoch 19/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.5199 - loss: 1.0722 - val_accuracy: 0.4913 - val_loss: 1.0885\n",
            "Epoch 20/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.4968 - loss: 1.0831 - val_accuracy: 0.5000 - val_loss: 1.0710\n",
            "Epoch 21/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4964 - loss: 1.0605 - val_accuracy: 0.5260 - val_loss: 1.0638\n",
            "Epoch 22/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5401 - loss: 1.0436 - val_accuracy: 0.5116 - val_loss: 1.0773\n",
            "Epoch 23/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5007 - loss: 1.0373 - val_accuracy: 0.5145 - val_loss: 1.0884\n",
            "Epoch 24/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5169 - loss: 1.0473 - val_accuracy: 0.5029 - val_loss: 1.1032\n",
            "Epoch 25/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5174 - loss: 1.0887 - val_accuracy: 0.5000 - val_loss: 1.0800\n",
            "Epoch 26/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4853 - loss: 1.0829 - val_accuracy: 0.5173 - val_loss: 1.0560\n",
            "Epoch 27/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5165 - loss: 1.0500 - val_accuracy: 0.5087 - val_loss: 1.0708\n",
            "Epoch 28/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5075 - loss: 1.0733 - val_accuracy: 0.4884 - val_loss: 1.0852\n",
            "Epoch 29/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5474 - loss: 1.0555 - val_accuracy: 0.4769 - val_loss: 1.0848\n",
            "Epoch 30/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5224 - loss: 1.0589 - val_accuracy: 0.5145 - val_loss: 1.0883\n",
            "Epoch 31/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5149 - loss: 1.0848 - val_accuracy: 0.5202 - val_loss: 1.1023\n",
            "Epoch 32/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5324 - loss: 1.0467 - val_accuracy: 0.5520 - val_loss: 1.0417\n",
            "Epoch 33/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5221 - loss: 1.0693 - val_accuracy: 0.5376 - val_loss: 1.0579\n",
            "Epoch 34/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.5448 - loss: 1.0275 - val_accuracy: 0.5434 - val_loss: 1.0796\n",
            "Epoch 35/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5123 - loss: 1.0827 - val_accuracy: 0.5347 - val_loss: 1.0531\n",
            "Epoch 36/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5114 - loss: 1.0691 - val_accuracy: 0.5087 - val_loss: 1.1094\n",
            "Epoch 37/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5172 - loss: 1.0656 - val_accuracy: 0.5145 - val_loss: 1.0979\n",
            "Epoch 38/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5255 - loss: 1.0503 - val_accuracy: 0.5347 - val_loss: 1.0922\n",
            "Epoch 39/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5363 - loss: 1.0258 - val_accuracy: 0.5491 - val_loss: 1.0894\n",
            "Epoch 40/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5213 - loss: 1.0607 - val_accuracy: 0.5405 - val_loss: 1.0849\n",
            "Epoch 41/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5697 - loss: 1.0301 - val_accuracy: 0.5347 - val_loss: 1.0715\n",
            "Epoch 42/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5260 - loss: 1.0222 - val_accuracy: 0.5376 - val_loss: 1.0400\n",
            "Epoch 43/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5145 - loss: 1.0244 - val_accuracy: 0.4913 - val_loss: 1.0741\n",
            "Epoch 44/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5273 - loss: 1.0314 - val_accuracy: 0.4942 - val_loss: 1.0739\n",
            "Epoch 45/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5152 - loss: 1.0035 - val_accuracy: 0.5202 - val_loss: 1.0793\n",
            "Epoch 46/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5443 - loss: 1.0024 - val_accuracy: 0.5462 - val_loss: 1.0533\n",
            "Epoch 47/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5349 - loss: 1.0280 - val_accuracy: 0.5578 - val_loss: 1.0629\n",
            "Epoch 48/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5387 - loss: 1.0168 - val_accuracy: 0.5694 - val_loss: 1.0548\n",
            "Epoch 49/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5654 - loss: 1.0076 - val_accuracy: 0.5318 - val_loss: 1.0640\n",
            "Epoch 50/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5337 - loss: 0.9988 - val_accuracy: 0.4971 - val_loss: 1.0785\n",
            "Epoch 51/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5482 - loss: 0.9998 - val_accuracy: 0.4855 - val_loss: 1.1099\n",
            "Epoch 52/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 1.0037 - val_accuracy: 0.5202 - val_loss: 1.0571\n",
            "Epoch 53/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5457 - loss: 0.9957 - val_accuracy: 0.5318 - val_loss: 1.0837\n",
            "Epoch 54/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5205 - loss: 1.0075 - val_accuracy: 0.5405 - val_loss: 1.0702\n",
            "Epoch 55/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5367 - loss: 1.0183 - val_accuracy: 0.5578 - val_loss: 1.0380\n",
            "Epoch 56/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5554 - loss: 1.0339 - val_accuracy: 0.5260 - val_loss: 1.0735\n",
            "Epoch 57/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5387 - loss: 1.0306 - val_accuracy: 0.5116 - val_loss: 1.1014\n",
            "Epoch 58/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5601 - loss: 0.9935 - val_accuracy: 0.5520 - val_loss: 1.0540\n",
            "Epoch 59/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5448 - loss: 1.0207 - val_accuracy: 0.5405 - val_loss: 1.0389\n",
            "Epoch 60/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5809 - loss: 0.9806 - val_accuracy: 0.5058 - val_loss: 1.0619\n",
            "Epoch 61/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5171 - loss: 0.9980 - val_accuracy: 0.5231 - val_loss: 1.0662\n",
            "Epoch 62/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5353 - loss: 0.9814 - val_accuracy: 0.5145 - val_loss: 1.0454\n",
            "Epoch 63/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5550 - loss: 0.9813 - val_accuracy: 0.5231 - val_loss: 1.0497\n",
            "Epoch 64/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5709 - loss: 0.9703 - val_accuracy: 0.5260 - val_loss: 1.0706\n",
            "Epoch 65/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5784 - loss: 0.9501 - val_accuracy: 0.5029 - val_loss: 1.0768\n",
            "Epoch 66/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5332 - loss: 0.9768 - val_accuracy: 0.5116 - val_loss: 1.0882\n",
            "Epoch 67/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5614 - loss: 0.9922 - val_accuracy: 0.4971 - val_loss: 1.0982\n",
            "Epoch 68/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5506 - loss: 0.9909 - val_accuracy: 0.5723 - val_loss: 1.0537\n",
            "Epoch 69/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5662 - loss: 0.9690 - val_accuracy: 0.5636 - val_loss: 1.0371\n",
            "Epoch 70/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5709 - loss: 0.9781 - val_accuracy: 0.5520 - val_loss: 1.0342\n",
            "Epoch 71/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5778 - loss: 0.9497 - val_accuracy: 0.5723 - val_loss: 1.0265\n",
            "Epoch 72/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5622 - loss: 0.9956 - val_accuracy: 0.5780 - val_loss: 1.0439\n",
            "Epoch 73/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5322 - loss: 0.9913 - val_accuracy: 0.5231 - val_loss: 1.0575\n",
            "Epoch 74/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5558 - loss: 0.9580 - val_accuracy: 0.5145 - val_loss: 1.0440\n",
            "Epoch 75/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5922 - loss: 0.9480 - val_accuracy: 0.5434 - val_loss: 1.0497\n",
            "Epoch 76/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5891 - loss: 0.9248 - val_accuracy: 0.5578 - val_loss: 1.0385\n",
            "Epoch 77/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5619 - loss: 0.9520 - val_accuracy: 0.5607 - val_loss: 1.0269\n",
            "Epoch 78/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5767 - loss: 0.9418 - val_accuracy: 0.5000 - val_loss: 1.1235\n",
            "Epoch 79/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5351 - loss: 0.9805 - val_accuracy: 0.5318 - val_loss: 1.0839\n",
            "Epoch 80/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5661 - loss: 0.9572 - val_accuracy: 0.5491 - val_loss: 1.0790\n",
            "Epoch 81/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5541 - loss: 0.9884 - val_accuracy: 0.4711 - val_loss: 1.0976\n",
            "Epoch 82/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5557 - loss: 0.9517 - val_accuracy: 0.5087 - val_loss: 1.0924\n",
            "Epoch 83/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5688 - loss: 0.9759 - val_accuracy: 0.5231 - val_loss: 1.1158\n",
            "Epoch 84/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5545 - loss: 0.9469 - val_accuracy: 0.5289 - val_loss: 1.0863\n",
            "Epoch 85/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5467 - loss: 0.9913 - val_accuracy: 0.5173 - val_loss: 1.0765\n",
            "Epoch 86/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5572 - loss: 0.9706 - val_accuracy: 0.5318 - val_loss: 1.0820\n",
            "Epoch 87/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5533 - loss: 0.9678 - val_accuracy: 0.5434 - val_loss: 1.0462\n",
            "Epoch 88/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6004 - loss: 0.9208 - val_accuracy: 0.5202 - val_loss: 1.0719\n",
            "Epoch 89/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5578 - loss: 0.9552 - val_accuracy: 0.5462 - val_loss: 1.0731\n",
            "Epoch 90/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5842 - loss: 0.9530 - val_accuracy: 0.5347 - val_loss: 1.1033\n",
            "Epoch 91/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5596 - loss: 0.9684 - val_accuracy: 0.5520 - val_loss: 1.0792\n",
            "Epoch 92/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5571 - loss: 0.9523 - val_accuracy: 0.5087 - val_loss: 1.1224\n",
            "Epoch 93/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5424 - loss: 1.0050 - val_accuracy: 0.5202 - val_loss: 1.1206\n",
            "Epoch 94/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5776 - loss: 0.9717 - val_accuracy: 0.5000 - val_loss: 1.1518\n",
            "Epoch 95/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6070 - loss: 0.9288 - val_accuracy: 0.5116 - val_loss: 1.1005\n",
            "Epoch 96/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5707 - loss: 0.9370 - val_accuracy: 0.5289 - val_loss: 1.1066\n",
            "Epoch 97/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5555 - loss: 0.9599 - val_accuracy: 0.5607 - val_loss: 1.0525\n",
            "Epoch 98/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5811 - loss: 0.9208 - val_accuracy: 0.5491 - val_loss: 1.0805\n",
            "Epoch 99/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5886 - loss: 0.9322 - val_accuracy: 0.5376 - val_loss: 1.0602\n",
            "Epoch 100/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5702 - loss: 0.9347 - val_accuracy: 0.5780 - val_loss: 1.0638\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e548f606950>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the losses and accuracies\n",
        "studtrain_losses = history_callback.train_losses\n",
        "studtrain_accuracies = history_callback.train_accuracies"
      ],
      "metadata": {
        "id": "F7DrpH8IL-l3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# epochs = list(range(1, 501))\n",
        "plt.plot(epochs, teachtrain_accuracies, label='Teacher Model accuracy', color = \"blue\")\n",
        "plt.plot(epochs, studtrain_accuracies, label='Student Model(Distillation) accuracy', color = \"green\")\n",
        "# plt.plot(epochs, nstudacc, label='Student Model(No Distillation) accuracy', color = \"red\")\n",
        "plt.title('Epochs vs Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "# plt.grid()\n",
        "# epochs = list(range(1, 101))\n",
        "# plt.plot(epochs, teachtrain_losses, label='Teacher Model Loss', color = \"blue\")\n",
        "# plt.plot(epochs, studtrain_losses, label='Student Model(Distillation) Loss', color = \"green\")\n",
        "# # plt.plot(epochs, nstudloss, label='Student Model(No Distillation) Loss', color = \"red\")\n",
        "# plt.title('Epochs vs Loss')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.legend()\n",
        "# plt.grid()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "jQUNbhMVMZJs",
        "outputId": "538e2d40-e53d-4441-94f0-2d008298d95b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7e54781603a0>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7Vxq6O5ahj6"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred = student_model.predict([phys_signals_test])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Get the class with the highest probability\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "class_report = classification_report(y_test, y_pred_classes)\n",
        "\n",
        "# Print metrics\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print('Confusion Matrix:\\n', conf_matrix)\n",
        "print('Classification Report:\\n', class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4i6_WzlbOy2"
      },
      "outputs": [],
      "source": [
        "# applying the KD for the CNN and LSTM student model\n",
        "student_model = create_student_model()\n",
        "student_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# Accuracy: 0.5751\n",
        "# F1 Score: 0.5647"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VVFzt0Qev7D"
      },
      "outputs": [],
      "source": [
        "student_model = create_teacher_model()\n",
        "student_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# Accuracy: 0.7775\n",
        "# F1 Score: 0.7827"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX7gxVo4bsk3",
        "outputId": "413df4dc-9a4d-4863-cd32-a26a0a5016e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "Loss: 0.9455141425132751\n",
            "Epoch 2/50\n",
            "Loss: 0.8577882051467896\n",
            "Epoch 3/50\n",
            "Loss: 0.8218518495559692\n",
            "Epoch 4/50\n",
            "Loss: 0.7915941476821899\n",
            "Epoch 5/50\n",
            "Loss: 0.778545618057251\n",
            "Epoch 6/50\n",
            "Loss: 0.7676621079444885\n",
            "Epoch 7/50\n",
            "Loss: 0.748263418674469\n",
            "Epoch 8/50\n",
            "Loss: 0.7389328479766846\n",
            "Epoch 9/50\n",
            "Loss: 0.7233762145042419\n",
            "Epoch 10/50\n",
            "Loss: 0.7231774926185608\n",
            "Epoch 11/50\n",
            "Loss: 0.7413961887359619\n",
            "Epoch 12/50\n",
            "Loss: 0.771192193031311\n",
            "Epoch 13/50\n",
            "Loss: 0.7405998706817627\n",
            "Epoch 14/50\n",
            "Loss: 0.7755367755889893\n",
            "Epoch 15/50\n",
            "Loss: 0.8646643161773682\n",
            "Epoch 16/50\n",
            "Loss: 0.950154185295105\n",
            "Epoch 17/50\n",
            "Loss: 1.1085891723632812\n",
            "Epoch 18/50\n",
            "Loss: 1.0295817852020264\n",
            "Epoch 19/50\n",
            "Loss: 0.9263003468513489\n",
            "Epoch 20/50\n",
            "Loss: 1.1643168926239014\n",
            "Epoch 21/50\n",
            "Loss: 1.1465178728103638\n",
            "Epoch 22/50\n",
            "Loss: 1.083524465560913\n",
            "Epoch 23/50\n",
            "Loss: 0.9536473751068115\n",
            "Epoch 24/50\n",
            "Loss: 1.0298707485198975\n",
            "Epoch 25/50\n",
            "Loss: 0.8407856225967407\n",
            "Epoch 26/50\n",
            "Loss: 0.7801840901374817\n",
            "Epoch 27/50\n",
            "Loss: 0.9535982608795166\n",
            "Epoch 28/50\n",
            "Loss: 1.0893354415893555\n",
            "Epoch 29/50\n",
            "Loss: 1.209362268447876\n",
            "Epoch 30/50\n",
            "Loss: 0.7827417254447937\n",
            "Epoch 31/50\n",
            "Loss: 0.6900017261505127\n",
            "Epoch 32/50\n",
            "Loss: 0.689812183380127\n",
            "Epoch 33/50\n",
            "Loss: 1.201718807220459\n",
            "Epoch 34/50\n",
            "Loss: 1.2163293361663818\n",
            "Epoch 35/50\n",
            "Loss: 0.7288421988487244\n",
            "Epoch 36/50\n",
            "Loss: 0.6888566613197327\n",
            "Epoch 37/50\n",
            "Loss: 0.9374557137489319\n",
            "Epoch 38/50\n",
            "Loss: 0.8184986114501953\n",
            "Epoch 39/50\n",
            "Loss: 1.3398840427398682\n",
            "Epoch 40/50\n",
            "Loss: 0.7816314101219177\n",
            "Epoch 41/50\n",
            "Loss: 0.8726512789726257\n",
            "Epoch 42/50\n",
            "Loss: 1.0146989822387695\n",
            "Epoch 43/50\n",
            "Loss: 0.689405083656311\n",
            "Epoch 44/50\n",
            "Loss: 1.0439637899398804\n",
            "Epoch 45/50\n",
            "Loss: 0.8220502734184265\n",
            "Epoch 46/50\n",
            "Loss: 0.8961538076400757\n",
            "Epoch 47/50\n",
            "Loss: 1.1169122457504272\n",
            "Epoch 48/50\n",
            "Loss: 0.6897971034049988\n",
            "Epoch 49/50\n",
            "Loss: 0.688100278377533\n",
            "Epoch 50/50\n",
            "Loss: 0.8220580220222473\n"
          ]
        }
      ],
      "source": [
        "# for CNN-LSTM teacher and CNN-LSTM student\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import losses, optimizers\n",
        "\n",
        "def distill_teacher_to_student(teacher_model, student_model, X_train_phys, y_train, temperature=3, alpha=0.5, epochs=10, batch_size=32):\n",
        "    # Convert labels to categorical (soft labels not needed for distillation)\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=4)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        for i in range(0, len(X_train_phys), batch_size):\n",
        "            # Get batch data\n",
        "            X_batch = X_train_phys[i:i+batch_size]\n",
        "            y_batch = y_train[i:i+batch_size]\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Get teacher model predictions (soft labels)\n",
        "                teacher_logits = teacher_model([eeg_signals_train[i:i+batch_size], X_batch], training=False)\n",
        "                teacher_probs = tf.nn.softmax(teacher_logits / temperature)\n",
        "\n",
        "                # Get student model predictions\n",
        "                student_logits = student_model([eeg_signals_train[i:i+batch_size], X_batch], training=True)\n",
        "                student_probs = tf.nn.softmax(student_logits / temperature)\n",
        "\n",
        "                # Distillation loss (between soft targets from teacher and student)\n",
        "                distillation_loss = tf.reduce_mean(\n",
        "                    losses.categorical_crossentropy(teacher_probs, student_probs)\n",
        "                )\n",
        "\n",
        "                # Hard target loss (between true labels and student outputs)\n",
        "                hard_loss = tf.reduce_mean(\n",
        "                    losses.categorical_crossentropy(y_batch, student_logits)\n",
        "                )\n",
        "\n",
        "                # Combined loss\n",
        "                loss = alpha * distillation_loss + (1 - alpha) * hard_loss\n",
        "\n",
        "            # Compute gradients\n",
        "            grads = tape.gradient(loss, student_model.trainable_weights)\n",
        "            optimizers.Adam().apply_gradients(zip(grads, student_model.trainable_weights))\n",
        "\n",
        "        print(f\"Loss: {loss.numpy()}\")\n",
        "\n",
        "# Distill knowledge from teacher to student\n",
        "distill_teacher_to_student(teacher_model, student_model, phys_signals_train, y_train, epochs=50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TW4OXhx5HHn"
      },
      "source": [
        "## Using CNN and LSTM hybrid for teacher model\n",
        "<p> Tried different student models:</p>\n",
        "<p>Teacher model: Accuracy: 91.33,\n",
        "F1 Score: 91.47\n",
        "<ol>\n",
        "<li>LSTM - Accuracy: 51.73, F1 Score: 44.26</li>\n",
        "<li>DNN-300: Accuracy: 64.45, F1 Score: 64.34</li>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3KSfsRn2eqt"
      },
      "outputs": [],
      "source": [
        "eeg_signals_train = X_train[:, :32]\n",
        "phys_signals_train = X_train[:, 32:]\n",
        "eeg_signals_test = X_test[:, :32]\n",
        "phys_signals_test = X_test[:, 32:]\n",
        "X_train_EEG = eeg_signals_train\n",
        "X_train_Phys = phys_signals_train\n",
        "X_test_EEG = eeg_signals_test\n",
        "X_test_Phys = phys_signals_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPxqISiO5GCA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, losses, optimizers\n",
        "\n",
        "def create_teacher_model():\n",
        "    input_eeg = layers.Input(shape=(32,))\n",
        "    input_phys = layers.Input(shape=(8,))\n",
        "\n",
        "    # CNN branch for EEG signals\n",
        "    x_eeg = layers.Reshape((32, 1))(input_eeg)\n",
        "    x_eeg = layers.Conv1D(64, kernel_size=3, activation='relu')(x_eeg)\n",
        "    x_eeg = layers.MaxPooling1D(pool_size=2)(x_eeg)\n",
        "    x_eeg = layers.Conv1D(128, kernel_size=3, activation='relu')(x_eeg)\n",
        "    x_eeg = layers.MaxPooling1D(pool_size=2)(x_eeg)\n",
        "    x_eeg = layers.Flatten()(x_eeg)\n",
        "\n",
        "    # LSTM branch for physiological signals\n",
        "    x_phys = layers.Reshape((8, 1))(input_phys)\n",
        "    x_phys = layers.LSTM(64, return_sequences=False)(x_phys)\n",
        "\n",
        "    # Combine both branches\n",
        "    combined = layers.Concatenate()([x_eeg, x_phys])\n",
        "    combined = layers.Dense(128, activation='relu')(combined)\n",
        "    output = layers.Dense(4, activation='softmax')(combined)\n",
        "\n",
        "    model = models.Model(inputs=[input_eeg, input_phys], outputs=output)\n",
        "    return model\n",
        "\n",
        "teacher_model = create_teacher_model()\n",
        "teacher_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptIyQVCoBUK1",
        "outputId": "0d6a37c5-fa41-4eab-c7f8-af9f5992789a",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.4482 - loss: 1.2194 - val_accuracy: 0.5289 - val_loss: 1.0317\n",
            "Epoch 2/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5629 - loss: 1.0451 - val_accuracy: 0.5665 - val_loss: 0.9479\n",
            "Epoch 3/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5925 - loss: 0.9385 - val_accuracy: 0.6734 - val_loss: 0.8741\n",
            "Epoch 4/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6406 - loss: 0.8596 - val_accuracy: 0.6329 - val_loss: 0.8090\n",
            "Epoch 5/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6433 - loss: 0.8371 - val_accuracy: 0.6908 - val_loss: 0.7272\n",
            "Epoch 6/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7043 - loss: 0.7117 - val_accuracy: 0.7110 - val_loss: 0.7409\n",
            "Epoch 7/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7279 - loss: 0.6987 - val_accuracy: 0.7457 - val_loss: 0.6536\n",
            "Epoch 8/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7747 - loss: 0.5889 - val_accuracy: 0.7081 - val_loss: 0.7832\n",
            "Epoch 9/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7787 - loss: 0.6022 - val_accuracy: 0.7254 - val_loss: 0.6781\n",
            "Epoch 10/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8094 - loss: 0.5295 - val_accuracy: 0.7457 - val_loss: 0.6436\n",
            "Epoch 11/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8143 - loss: 0.5059 - val_accuracy: 0.7919 - val_loss: 0.5962\n",
            "Epoch 12/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8280 - loss: 0.4678 - val_accuracy: 0.7919 - val_loss: 0.6102\n",
            "Epoch 13/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8295 - loss: 0.4671 - val_accuracy: 0.8006 - val_loss: 0.5375\n",
            "Epoch 14/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8341 - loss: 0.4254 - val_accuracy: 0.8179 - val_loss: 0.5233\n",
            "Epoch 15/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8671 - loss: 0.3743 - val_accuracy: 0.8208 - val_loss: 0.5150\n",
            "Epoch 16/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8620 - loss: 0.3757 - val_accuracy: 0.8208 - val_loss: 0.5263\n",
            "Epoch 17/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8630 - loss: 0.3694 - val_accuracy: 0.8121 - val_loss: 0.5507\n",
            "Epoch 18/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8762 - loss: 0.3463 - val_accuracy: 0.8266 - val_loss: 0.5300\n",
            "Epoch 19/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8796 - loss: 0.3504 - val_accuracy: 0.8555 - val_loss: 0.4754\n",
            "Epoch 20/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8846 - loss: 0.3236 - val_accuracy: 0.8468 - val_loss: 0.4803\n",
            "Epoch 21/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8995 - loss: 0.2758 - val_accuracy: 0.8324 - val_loss: 0.5250\n",
            "Epoch 22/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9070 - loss: 0.2826 - val_accuracy: 0.8237 - val_loss: 0.5464\n",
            "Epoch 23/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9166 - loss: 0.2538 - val_accuracy: 0.8208 - val_loss: 0.5710\n",
            "Epoch 24/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9321 - loss: 0.2234 - val_accuracy: 0.8468 - val_loss: 0.4828\n",
            "Epoch 25/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9366 - loss: 0.2092 - val_accuracy: 0.8439 - val_loss: 0.4987\n",
            "Epoch 26/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9282 - loss: 0.2412 - val_accuracy: 0.8468 - val_loss: 0.5262\n",
            "Epoch 27/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9281 - loss: 0.2395 - val_accuracy: 0.8642 - val_loss: 0.4670\n",
            "Epoch 28/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9379 - loss: 0.1857 - val_accuracy: 0.8382 - val_loss: 0.5083\n",
            "Epoch 29/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9341 - loss: 0.1886 - val_accuracy: 0.8786 - val_loss: 0.4867\n",
            "Epoch 30/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9382 - loss: 0.2999 - val_accuracy: 0.8642 - val_loss: 0.4377\n",
            "Epoch 31/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9460 - loss: 0.1791 - val_accuracy: 0.8439 - val_loss: 0.5355\n",
            "Epoch 32/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9148 - loss: 0.2406 - val_accuracy: 0.8786 - val_loss: 0.4490\n",
            "Epoch 33/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9399 - loss: 0.1964 - val_accuracy: 0.8902 - val_loss: 0.4334\n",
            "Epoch 34/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9490 - loss: 0.1574 - val_accuracy: 0.8642 - val_loss: 0.4763\n",
            "Epoch 35/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9416 - loss: 0.1706 - val_accuracy: 0.8902 - val_loss: 0.4332\n",
            "Epoch 36/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9712 - loss: 0.1165 - val_accuracy: 0.8988 - val_loss: 0.4354\n",
            "Epoch 37/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9560 - loss: 0.1279 - val_accuracy: 0.8757 - val_loss: 0.4797\n",
            "Epoch 38/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9671 - loss: 0.1157 - val_accuracy: 0.8873 - val_loss: 0.4586\n",
            "Epoch 39/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9559 - loss: 0.1370 - val_accuracy: 0.8584 - val_loss: 0.6097\n",
            "Epoch 40/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9575 - loss: 0.1419 - val_accuracy: 0.8728 - val_loss: 0.5006\n",
            "Epoch 41/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9489 - loss: 0.1747 - val_accuracy: 0.8988 - val_loss: 0.4294\n",
            "Epoch 42/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9719 - loss: 0.1021 - val_accuracy: 0.9017 - val_loss: 0.4016\n",
            "Epoch 43/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9820 - loss: 0.0877 - val_accuracy: 0.9133 - val_loss: 0.4156\n",
            "Epoch 44/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9741 - loss: 0.0815 - val_accuracy: 0.9017 - val_loss: 0.4341\n",
            "Epoch 45/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9625 - loss: 0.1202 - val_accuracy: 0.9075 - val_loss: 0.4209\n",
            "Epoch 46/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9698 - loss: 0.0953 - val_accuracy: 0.8815 - val_loss: 0.5339\n",
            "Epoch 47/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9684 - loss: 0.1010 - val_accuracy: 0.9075 - val_loss: 0.4493\n",
            "Epoch 48/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9710 - loss: 0.1041 - val_accuracy: 0.8873 - val_loss: 0.5248\n",
            "Epoch 49/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9746 - loss: 0.1072 - val_accuracy: 0.9046 - val_loss: 0.4760\n",
            "Epoch 50/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9743 - loss: 0.0805 - val_accuracy: 0.8786 - val_loss: 0.5675\n",
            "Epoch 51/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9839 - loss: 0.0721 - val_accuracy: 0.9075 - val_loss: 0.4438\n",
            "Epoch 52/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9893 - loss: 0.0566 - val_accuracy: 0.8902 - val_loss: 0.4679\n",
            "Epoch 53/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9814 - loss: 0.0754 - val_accuracy: 0.8960 - val_loss: 0.4598\n",
            "Epoch 54/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9760 - loss: 0.1110 - val_accuracy: 0.8931 - val_loss: 0.4917\n",
            "Epoch 55/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9719 - loss: 0.0885 - val_accuracy: 0.8786 - val_loss: 0.4547\n",
            "Epoch 56/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9786 - loss: 0.0907 - val_accuracy: 0.8902 - val_loss: 0.5010\n",
            "Epoch 57/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9648 - loss: 0.1090 - val_accuracy: 0.8844 - val_loss: 0.5078\n",
            "Epoch 58/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9833 - loss: 0.0597 - val_accuracy: 0.8960 - val_loss: 0.4778\n",
            "Epoch 59/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9904 - loss: 0.0441 - val_accuracy: 0.9046 - val_loss: 0.4729\n",
            "Epoch 60/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9949 - loss: 0.0364 - val_accuracy: 0.8931 - val_loss: 0.4746\n",
            "Epoch 61/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9908 - loss: 0.0392 - val_accuracy: 0.9046 - val_loss: 0.5086\n",
            "Epoch 62/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9951 - loss: 0.0374 - val_accuracy: 0.9017 - val_loss: 0.4896\n",
            "Epoch 63/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9872 - loss: 0.0474 - val_accuracy: 0.9133 - val_loss: 0.4695\n",
            "Epoch 64/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9888 - loss: 0.0489 - val_accuracy: 0.9017 - val_loss: 0.5265\n",
            "Epoch 65/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9933 - loss: 0.0305 - val_accuracy: 0.9017 - val_loss: 0.4982\n",
            "Epoch 66/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9960 - loss: 0.0284 - val_accuracy: 0.8931 - val_loss: 0.4977\n",
            "Epoch 67/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9879 - loss: 0.0382 - val_accuracy: 0.8931 - val_loss: 0.5253\n",
            "Epoch 68/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9740 - loss: 0.0850 - val_accuracy: 0.8988 - val_loss: 0.4995\n",
            "Epoch 69/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9919 - loss: 0.0468 - val_accuracy: 0.9133 - val_loss: 0.4622\n",
            "Epoch 70/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9848 - loss: 0.0502 - val_accuracy: 0.8931 - val_loss: 0.4880\n",
            "Epoch 71/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9856 - loss: 0.0544 - val_accuracy: 0.8931 - val_loss: 0.5524\n",
            "Epoch 72/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9880 - loss: 0.0375 - val_accuracy: 0.9104 - val_loss: 0.4908\n",
            "Epoch 73/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9949 - loss: 0.0248 - val_accuracy: 0.9104 - val_loss: 0.4706\n",
            "Epoch 74/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9926 - loss: 0.0325 - val_accuracy: 0.9046 - val_loss: 0.4681\n",
            "Epoch 75/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9928 - loss: 0.0219 - val_accuracy: 0.9017 - val_loss: 0.5073\n",
            "Epoch 76/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9919 - loss: 0.0292 - val_accuracy: 0.9133 - val_loss: 0.4716\n",
            "Epoch 77/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9953 - loss: 0.0212 - val_accuracy: 0.9017 - val_loss: 0.5143\n",
            "Epoch 78/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9918 - loss: 0.0296 - val_accuracy: 0.8960 - val_loss: 0.5301\n",
            "Epoch 79/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9977 - loss: 0.0145 - val_accuracy: 0.9046 - val_loss: 0.5207\n",
            "Epoch 80/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9957 - loss: 0.0212 - val_accuracy: 0.8931 - val_loss: 0.5361\n",
            "Epoch 81/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9941 - loss: 0.0173 - val_accuracy: 0.9075 - val_loss: 0.5002\n",
            "Epoch 82/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9874 - loss: 0.0517 - val_accuracy: 0.8988 - val_loss: 0.5046\n",
            "Epoch 83/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9921 - loss: 0.0281 - val_accuracy: 0.8988 - val_loss: 0.5249\n",
            "Epoch 84/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9886 - loss: 0.0349 - val_accuracy: 0.8960 - val_loss: 0.5124\n",
            "Epoch 85/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9960 - loss: 0.0197 - val_accuracy: 0.9075 - val_loss: 0.4865\n",
            "Epoch 86/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9979 - loss: 0.0111 - val_accuracy: 0.9104 - val_loss: 0.5248\n",
            "Epoch 87/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9968 - loss: 0.0143 - val_accuracy: 0.9017 - val_loss: 0.5086\n",
            "Epoch 88/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9863 - loss: 0.0359 - val_accuracy: 0.8931 - val_loss: 0.5178\n",
            "Epoch 89/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9950 - loss: 0.0202 - val_accuracy: 0.8844 - val_loss: 0.5965\n",
            "Epoch 90/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9950 - loss: 0.0217 - val_accuracy: 0.9075 - val_loss: 0.5398\n",
            "Epoch 91/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9969 - loss: 0.0133 - val_accuracy: 0.8988 - val_loss: 0.5571\n",
            "Epoch 92/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9974 - loss: 0.0124 - val_accuracy: 0.9017 - val_loss: 0.5005\n",
            "Epoch 93/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9939 - loss: 0.0151 - val_accuracy: 0.9017 - val_loss: 0.5380\n",
            "Epoch 94/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9972 - loss: 0.0157 - val_accuracy: 0.9046 - val_loss: 0.5417\n",
            "Epoch 95/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9973 - loss: 0.0105 - val_accuracy: 0.9104 - val_loss: 0.5346\n",
            "Epoch 96/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9933 - loss: 0.0204 - val_accuracy: 0.9075 - val_loss: 0.5682\n",
            "Epoch 97/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9995 - loss: 0.0058 - val_accuracy: 0.9046 - val_loss: 0.5397\n",
            "Epoch 98/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9971 - loss: 0.0141 - val_accuracy: 0.8960 - val_loss: 0.5906\n",
            "Epoch 99/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9953 - loss: 0.0138 - val_accuracy: 0.9046 - val_loss: 0.5602\n",
            "Epoch 100/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9973 - loss: 0.0085 - val_accuracy: 0.9133 - val_loss: 0.5391\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7af42d2c7880>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "teacher_model.fit([eeg_signals_train, phys_signals_train], y_train, epochs=100, validation_data=([eeg_signals_test, phys_signals_test], y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKHzE1B2uqIm",
        "outputId": "d680b514-5c25-4436-ef46-59f7c22c31d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Accuracy: 0.9133\n",
            "F1 Score: 0.9147\n",
            "Confusion Matrix:\n",
            " [[ 15   0   0   1]\n",
            " [  2 135   5   9]\n",
            " [  1   2  97   5]\n",
            " [  2   1   2  69]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.94      0.83        16\n",
            "         1.0       0.98      0.89      0.93       151\n",
            "         2.0       0.93      0.92      0.93       105\n",
            "         3.0       0.82      0.93      0.87        74\n",
            "\n",
            "    accuracy                           0.91       346\n",
            "   macro avg       0.87      0.92      0.89       346\n",
            "weighted avg       0.92      0.91      0.91       346\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Make predictions\n",
        "y_pred = teacher_model.predict([eeg_signals_test, phys_signals_test])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Get the class with the highest probability\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "class_report = classification_report(y_test, y_pred_classes)\n",
        "\n",
        "# Print metrics\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print('Confusion Matrix:\\n', conf_matrix)\n",
        "print('Classification Report:\\n', class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRhVpALr_qaT"
      },
      "outputs": [],
      "source": [
        "def create_student_model():\n",
        "    input_phys = layers.Input(shape=(8,))\n",
        "\n",
        "    # LSTM for physiological signals\n",
        "    x = layers.Reshape((8, 1))(input_phys)\n",
        "    x = layers.LSTM(64, return_sequences=False)(x)\n",
        "\n",
        "    # Added Dense Layers\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)  # Dropout layer for regularization\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)  # Dropout layer for regularization\n",
        "    x = layers.Dense(32, activation='relu')(x)\n",
        "\n",
        "    # Final Output Layer\n",
        "    output = layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=input_phys, outputs=output)\n",
        "    return model\n",
        "\n",
        "student_model_lstm = create_student_model()\n",
        "student_model_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tto5Hd3wbiIJ",
        "outputId": "84272d6f-874c-4f84-d718-35e2ace9791f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "def create_student_model():\n",
        "    model = Sequential()\n",
        "    # Only using 8 physiological signals as input\n",
        "    model.add(Dense(300, input_dim=8, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    # Output layer remains same since we have 4 classes\n",
        "    model.add(Dense(4, kernel_initializer='normal', activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "student_model_dnn = create_student_model()\n",
        "student_model_dnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(teacher_model.summary())\n",
        "print(student_model_lstm.summary())\n",
        "print(student_model_dnn.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jbE1b4ZfOaIy",
        "outputId": "7d7aa0ee-7d58-4766-f3dc-d84e2922f4d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_64\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_64\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_16            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ input_layer_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m256\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m24,704\u001b[0m │ max_pooling1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_17            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ input_layer_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ max_pooling1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m16,896\u001b[0m │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m832\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ flatten_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m106,624\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m516\u001b[0m │ dense_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_16            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_17            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">106,624</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ dense_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m148,996\u001b[0m (582.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">148,996</span> (582.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m148,996\u001b[0m (582.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">148,996</span> (582.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_65\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_65\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_18 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m16,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m132\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m35,684\u001b[0m (139.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,684</span> (139.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35,684\u001b[0m (139.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,684</span> (139.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │           \u001b[38;5;34m2,700\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_55 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │           \u001b[38;5;34m1,204\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,700</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,204</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m184,504\u001b[0m (720.72 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">184,504</span> (720.72 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m184,504\u001b[0m (720.72 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">184,504</span> (720.72 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZyA-WA7wK7m"
      },
      "outputs": [],
      "source": [
        "student_model = create_student_model_dnn300()\n",
        "student_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTqIP8eEsziu"
      },
      "outputs": [],
      "source": [
        "eeg_signals_train = X_train[:, :32]\n",
        "phys_signals_train = X_train[:, 32:]\n",
        "eeg_signals_test = X_test[:, :32]\n",
        "phys_signals_test = X_test[:, 32:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WakgaeeutPxa",
        "outputId": "1c39a318-f744-47bd-8af6-304a9ca62402"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_23\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_23\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ reshape_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ max_pooling1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_8             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │ reshape_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">106,624</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ dense_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_3 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m256\u001b[0m │ reshape_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m24,704\u001b[0m │ max_pooling1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_8             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_4 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ max_pooling1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m16,896\u001b[0m │ reshape_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m832\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m106,624\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m516\u001b[0m │ dense_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">148,996</span> (582.02 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m148,996\u001b[0m (582.02 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">148,996</span> (582.02 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m148,996\u001b[0m (582.02 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_22\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_22\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m16,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m132\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,684</span> (139.39 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m35,684\u001b[0m (139.39 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,684</span> (139.39 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35,684\u001b[0m (139.39 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(teacher_model.summary())\n",
        "print(student_model_lstm.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmgH9rEZsFTn"
      },
      "outputs": [],
      "source": [
        "#method - 3\n",
        "def distillation_loss(y_true, y_pred, teacher_logits):\n",
        "    alpha = 0.5  # Weight for true labels\n",
        "    temperature = 3.0\n",
        "\n",
        "    # Cross-entropy loss with true labels\n",
        "    hard_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
        "\n",
        "    # Soft targets from teacher model (using softmax with temperature scaling)\n",
        "    soft_targets_teacher = tf.nn.softmax(teacher_logits / temperature)\n",
        "\n",
        "    # Cross-entropy loss with soft targets\n",
        "    soft_loss = tf.keras.losses.categorical_crossentropy(\n",
        "    soft_targets_teacher,\n",
        "    tf.nn.softmax(y_pred / temperature))\n",
        "\n",
        "    # Combine losses\n",
        "    return alpha * hard_loss + (1 - alpha) * soft_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPL_HdC32_Lj"
      },
      "outputs": [],
      "source": [
        "def create_student_model():\n",
        "    input_eeg = layers.Input(shape=(32,))\n",
        "    input_phys = layers.Input(shape=(8,))\n",
        "\n",
        "    x_eeg = layers.Reshape((32, 1))(input_eeg)\n",
        "    x_eeg = layers.Conv1D(32, kernel_size=3, activation='relu')(x_eeg)  # Fewer filters\n",
        "    x_eeg = layers.MaxPooling1D(pool_size=2)(x_eeg)\n",
        "\n",
        "    x_phys = layers.Reshape((8, 1))(input_phys)\n",
        "    x_phys = layers.LSTM(32, return_sequences=False)(x_phys)  # Fewer units\n",
        "\n",
        "    combined = layers.Concatenate()([layers.Flatten()(x_eeg), x_phys])\n",
        "\n",
        "    output = layers.Dense(4, activation='softmax')(combined)\n",
        "\n",
        "    model = models.Model(inputs=[input_eeg, input_phys], outputs=output)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBI_qUr-3x38"
      },
      "outputs": [],
      "source": [
        "student_model = create_student_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-du7wn0bDQxV"
      },
      "outputs": [],
      "source": [
        "#For DNN 300\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import losses, optimizers\n",
        "\n",
        "def distill_teacher_to_student(teacher_model, student_model, X_train_phys, y_train, temperature=3, alpha=0.5, epochs=10, batch_size=32):\n",
        "    # Convert labels to categorical (soft labels not needed for distillation)\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=4)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        for i in range(0, len(X_train_phys), batch_size):\n",
        "            # Get batch data\n",
        "            X_batch = X_train_phys[i:i+batch_size]\n",
        "            y_batch = y_train[i:i+batch_size]\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Get teacher model predictions (soft labels)\n",
        "                teacher_logits = teacher_model([eeg_signals_train[i:i+batch_size], X_batch], training=False)\n",
        "                teacher_probs = tf.nn.softmax(teacher_logits / temperature)\n",
        "\n",
        "                # Get student model predictions\n",
        "                student_logits = student_model(X_batch, training=True)\n",
        "                student_probs = tf.nn.softmax(student_logits / temperature)\n",
        "\n",
        "                # Distillation loss (between soft targets from teacher and student)\n",
        "                distillation_loss = tf.reduce_mean(\n",
        "                    losses.categorical_crossentropy(teacher_probs, student_probs)\n",
        "                )\n",
        "\n",
        "                # Hard target loss (between true labels and student outputs)\n",
        "                hard_loss = tf.reduce_mean(\n",
        "                    losses.categorical_crossentropy(y_batch, student_logits)\n",
        "                )\n",
        "\n",
        "                # Combined loss\n",
        "                loss = alpha * distillation_loss + (1 - alpha) * hard_loss\n",
        "\n",
        "            # Compute gradients\n",
        "            grads = tape.gradient(loss, student_model.trainable_weights)\n",
        "            optimizers.Adam().apply_gradients(zip(grads, student_model.trainable_weights))\n",
        "\n",
        "        print(f\"Loss: {loss.numpy()}\")\n",
        "\n",
        "# Distill knowledge from teacher to student\n",
        "distill_teacher_to_student(teacher_model, student_model, phys_signals_train, y_train, epochs=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOdVQXmGy0xN",
        "outputId": "a98c88ca-89bc-41ee-9227-532814860afc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Accuracy: 0.6445\n",
            "F1 Score: 0.6434\n",
            "Confusion Matrix:\n",
            " [[  7   2   3   4]\n",
            " [  1 112  29   9]\n",
            " [  0  28  64  13]\n",
            " [  0  14  20  40]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.44      0.58        16\n",
            "         1.0       0.72      0.74      0.73       151\n",
            "         2.0       0.55      0.61      0.58       105\n",
            "         3.0       0.61      0.54      0.57        74\n",
            "\n",
            "    accuracy                           0.64       346\n",
            "   macro avg       0.69      0.58      0.62       346\n",
            "weighted avg       0.65      0.64      0.64       346\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Make predictions\n",
        "y_pred = student_model.predict(X_test[:,-8:])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Get the class with the highest probability\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "class_report = classification_report(y_test, y_pred_classes)\n",
        "\n",
        "# Print metrics\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print('Confusion Matrix:\\n', conf_matrix)\n",
        "print('Classification Report:\\n', class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "w6zql7QovuIQ",
        "outputId": "6891c6be-d549-4caf-a9ee-852137a55f27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Loss: 1.2128775119781494\n",
            "Epoch 2/100\n",
            "Loss: 1.203574776649475\n",
            "Epoch 3/100\n",
            "Loss: 1.1036243438720703\n",
            "Epoch 4/100\n",
            "Loss: 1.1622740030288696\n",
            "Epoch 5/100\n",
            "Loss: 1.1625922918319702\n",
            "Epoch 6/100\n",
            "Loss: 1.133740782737732\n",
            "Epoch 7/100\n",
            "Loss: 1.1630935668945312\n",
            "Epoch 8/100\n",
            "Loss: 1.1084630489349365\n",
            "Epoch 9/100\n",
            "Loss: 1.169747233390808\n",
            "Epoch 10/100\n",
            "Loss: 1.1103484630584717\n",
            "Epoch 11/100\n",
            "Loss: 1.1502937078475952\n",
            "Epoch 12/100\n",
            "Loss: 1.1710381507873535\n",
            "Epoch 13/100\n",
            "Loss: 1.1731455326080322\n",
            "Epoch 14/100\n",
            "Loss: 1.2289907932281494\n",
            "Epoch 15/100\n",
            "Loss: 1.1661672592163086\n",
            "Epoch 16/100\n",
            "Loss: 1.0937291383743286\n",
            "Epoch 17/100\n",
            "Loss: 1.0897048711776733\n",
            "Epoch 18/100\n",
            "Loss: 1.1415284872055054\n",
            "Epoch 19/100\n",
            "Loss: 1.0958646535873413\n",
            "Epoch 20/100\n",
            "Loss: 1.1336743831634521\n",
            "Epoch 21/100\n",
            "Loss: 1.1003069877624512\n",
            "Epoch 22/100\n",
            "Loss: 1.0963717699050903\n",
            "Epoch 23/100\n",
            "Loss: 1.0660960674285889\n",
            "Epoch 24/100\n",
            "Loss: 1.1388441324234009\n",
            "Epoch 25/100\n",
            "Loss: 1.0647414922714233\n",
            "Epoch 26/100\n",
            "Loss: 1.0776206254959106\n",
            "Epoch 27/100\n",
            "Loss: 1.0634534358978271\n",
            "Epoch 28/100\n",
            "Loss: 1.0609514713287354\n",
            "Epoch 29/100\n",
            "Loss: 1.056989073753357\n",
            "Epoch 30/100\n",
            "Loss: 0.9949483871459961\n",
            "Epoch 31/100\n",
            "Loss: 1.0263116359710693\n",
            "Epoch 32/100\n",
            "Loss: 1.024399995803833\n",
            "Epoch 33/100\n",
            "Loss: 1.0248146057128906\n",
            "Epoch 34/100\n",
            "Loss: 1.0652111768722534\n",
            "Epoch 35/100\n",
            "Loss: 1.0486770868301392\n",
            "Epoch 36/100\n",
            "Loss: 1.0300626754760742\n",
            "Epoch 37/100\n",
            "Loss: 1.0076814889907837\n",
            "Epoch 38/100\n",
            "Loss: 0.9932843446731567\n",
            "Epoch 39/100\n",
            "Loss: 1.0991277694702148\n",
            "Epoch 40/100\n",
            "Loss: 1.0333542823791504\n",
            "Epoch 41/100\n",
            "Loss: 0.9541353583335876\n",
            "Epoch 42/100\n",
            "Loss: 1.0470740795135498\n",
            "Epoch 43/100\n",
            "Loss: 0.9767657518386841\n",
            "Epoch 44/100\n",
            "Loss: 0.9885396957397461\n",
            "Epoch 45/100\n",
            "Loss: 0.9544367790222168\n",
            "Epoch 46/100\n",
            "Loss: 1.0708355903625488\n",
            "Epoch 47/100\n",
            "Loss: 2.0463461875915527\n",
            "Epoch 48/100\n",
            "Loss: 1.0477497577667236\n",
            "Epoch 49/100\n",
            "Loss: 1.0200958251953125\n",
            "Epoch 50/100\n",
            "Loss: 0.9445430040359497\n",
            "Epoch 51/100\n",
            "Loss: 1.0375256538391113\n",
            "Epoch 52/100\n",
            "Loss: 1.0762181282043457\n",
            "Epoch 53/100\n",
            "Loss: 1.2047239542007446\n",
            "Epoch 54/100\n",
            "Loss: 1.3124406337738037\n",
            "Epoch 55/100\n",
            "Loss: 1.0733940601348877\n",
            "Epoch 56/100\n",
            "Loss: 1.057535171508789\n",
            "Epoch 57/100\n",
            "Loss: 1.1329971551895142\n",
            "Epoch 58/100\n",
            "Loss: 1.0390067100524902\n",
            "Epoch 59/100\n",
            "Loss: 0.9609811305999756\n",
            "Epoch 60/100\n",
            "Loss: 1.0056174993515015\n",
            "Epoch 61/100\n",
            "Loss: 1.0362763404846191\n",
            "Epoch 62/100\n",
            "Loss: 1.0802749395370483\n",
            "Epoch 63/100\n",
            "Loss: 0.9205519556999207\n",
            "Epoch 64/100\n",
            "Loss: 1.0364151000976562\n",
            "Epoch 65/100\n",
            "Loss: 1.0479212999343872\n",
            "Epoch 66/100\n",
            "Loss: 1.074026107788086\n",
            "Epoch 67/100\n",
            "Loss: 1.310340166091919\n",
            "Epoch 68/100\n",
            "Loss: 1.049533724784851\n",
            "Epoch 69/100\n",
            "Loss: 0.9687479734420776\n",
            "Epoch 70/100\n",
            "Loss: 1.3984211683273315\n",
            "Epoch 71/100\n",
            "Loss: 1.2318264245986938\n",
            "Epoch 72/100\n",
            "Loss: 1.202186107635498\n",
            "Epoch 73/100\n",
            "Loss: 1.121227741241455\n",
            "Epoch 74/100\n",
            "Loss: 1.0449585914611816\n",
            "Epoch 75/100\n",
            "Loss: 1.0554418563842773\n",
            "Epoch 76/100\n",
            "Loss: 0.9913322925567627\n",
            "Epoch 77/100\n",
            "Loss: 1.0042208433151245\n",
            "Epoch 78/100\n",
            "Loss: 1.094138264656067\n",
            "Epoch 79/100\n",
            "Loss: 1.082557201385498\n",
            "Epoch 80/100\n",
            "Loss: 1.162942886352539\n",
            "Epoch 81/100\n",
            "Loss: 1.083858609199524\n",
            "Epoch 82/100\n",
            "Loss: 1.2539103031158447\n",
            "Epoch 83/100\n",
            "Loss: 1.4233806133270264\n",
            "Epoch 84/100\n",
            "Loss: 0.9511146545410156\n",
            "Epoch 85/100\n",
            "Loss: 1.0504508018493652\n",
            "Epoch 86/100\n",
            "Loss: 1.034303903579712\n",
            "Epoch 87/100\n",
            "Loss: 1.1599677801132202\n",
            "Epoch 88/100\n",
            "Loss: 1.1267956495285034\n",
            "Epoch 89/100\n",
            "Loss: 1.025528907775879\n",
            "Epoch 90/100\n",
            "Loss: 1.0704212188720703\n",
            "Epoch 91/100\n",
            "Loss: 1.4153951406478882\n",
            "Epoch 92/100\n",
            "Loss: 1.0979989767074585\n",
            "Epoch 93/100\n",
            "Loss: 1.1211439371109009\n",
            "Epoch 94/100\n",
            "Loss: 1.057263731956482\n",
            "Epoch 95/100\n",
            "Loss: 1.0257683992385864\n",
            "Epoch 96/100\n",
            "Loss: 1.0145920515060425\n",
            "Epoch 97/100\n",
            "Loss: 0.9892784357070923\n",
            "Epoch 98/100\n",
            "Loss: 0.9274526834487915\n",
            "Epoch 99/100\n",
            "Loss: 1.0221188068389893\n",
            "Epoch 100/100\n",
            "Loss: 1.2432128190994263\n"
          ]
        }
      ],
      "source": [
        "#Fro LSTM\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import losses, optimizers\n",
        "\n",
        "def distill_teacher_to_student(teacher_model, student_model, X_train_phys, y_train, temperature=3, alpha=0.5, epochs=10, batch_size=32):\n",
        "    # Convert labels to categorical (soft labels not needed for distillation)\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=4)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        for i in range(0, len(X_train_phys), batch_size):\n",
        "            # Get batch data\n",
        "            X_batch = X_train_phys[i:i+batch_size]\n",
        "            y_batch = y_train[i:i+batch_size]\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Get teacher model predictions (soft labels)\n",
        "                teacher_logits = teacher_model([eeg_signals_train[i:i+batch_size], X_batch], training=False)\n",
        "                teacher_probs = tf.nn.softmax(teacher_logits / temperature)\n",
        "\n",
        "                # Get student model predictions\n",
        "                student_logits = student_model(X_batch, training=True)\n",
        "                student_probs = tf.nn.softmax(student_logits / temperature)\n",
        "\n",
        "                # Distillation loss (between soft targets from teacher and student)\n",
        "                distillation_loss = tf.reduce_mean(\n",
        "                    losses.categorical_crossentropy(teacher_probs, student_probs)\n",
        "                )\n",
        "\n",
        "                # Hard target loss (between true labels and student outputs)\n",
        "                hard_loss = tf.reduce_mean(\n",
        "                    losses.categorical_crossentropy(y_batch, student_logits)\n",
        "                )\n",
        "\n",
        "                # Combined loss\n",
        "                loss = alpha * distillation_loss + (1 - alpha) * hard_loss\n",
        "\n",
        "            # Compute gradients\n",
        "            grads = tape.gradient(loss, student_model.trainable_weights)\n",
        "            optimizers.Adam().apply_gradients(zip(grads, student_model.trainable_weights))\n",
        "\n",
        "        print(f\"Loss: {loss.numpy()}\")\n",
        "\n",
        "# Distill knowledge from teacher to student\n",
        "distill_teacher_to_student(teacher_model, student_model_lstm, phys_signals_train, y_train, epochs=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoCIe_ePzmET",
        "outputId": "fc913edd-ebb3-459b-abbe-2cefb531f171"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
            "Accuracy: 0.5173\n",
            "F1 Score: 0.4426\n",
            "Confusion Matrix:\n",
            " [[  0  16   0   0]\n",
            " [  0 143   4   4]\n",
            " [  1  79  21   4]\n",
            " [  0  57   2  15]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        16\n",
            "         1.0       0.48      0.95      0.64       151\n",
            "         2.0       0.78      0.20      0.32       105\n",
            "         3.0       0.65      0.20      0.31        74\n",
            "\n",
            "    accuracy                           0.52       346\n",
            "   macro avg       0.48      0.34      0.32       346\n",
            "weighted avg       0.59      0.52      0.44       346\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Make predictions\n",
        "y_pred = student_model_lstm.predict(X_test[:,-8:])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Get the class with the highest probability\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "class_report = classification_report(y_test, y_pred_classes)\n",
        "\n",
        "# Print metrics\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print('Confusion Matrix:\\n', conf_matrix)\n",
        "print('Classification Report:\\n', class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "meXDFKECE7nC",
        "outputId": "28ad872d-03ea-4ac1-cde4-828880d6fe5a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_20\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_20\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">106,624</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ dense_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m256\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m24,704\u001b[0m │ max_pooling1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ max_pooling1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m16,896\u001b[0m │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m832\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m106,624\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m516\u001b[0m │ dense_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">446,990</span> (1.71 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m446,990\u001b[0m (1.71 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">148,996</span> (582.02 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m148,996\u001b[0m (582.02 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">297,994</span> (1.14 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m297,994\u001b[0m (1.14 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,700</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,204</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │           \u001b[38;5;34m2,700\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │           \u001b[38;5;34m1,204\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">274,804</span> (1.05 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m274,804\u001b[0m (1.05 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">274,804</span> (1.05 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m274,804\u001b[0m (1.05 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(teacher_model.summary())\n",
        "print(student_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EztmUvwHBunM",
        "outputId": "cb03c3b1-e5cb-4211-e8c3-bc865c27f621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
        "\n",
        "# Get predictions for the test set\n",
        "teacher_preds = np.argmax(teacher_model.predict([eeg_signals_test, phys_signals_test]), axis=1)\n",
        "student_preds = np.argmax(student_model.predict(phys_signals_test), axis=1)\n",
        "\n",
        "# True labels\n",
        "y_true = y_test  # Assuming y_test is already in the correct format\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EajCoBQf_8kJ",
        "outputId": "d5e3a386-c4bc-4a43-e4e2-3da0dc4b80eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher Model Performance:\n",
            "Confusion Matrix:\n",
            " [[ 15   0   0   1]\n",
            " [  1 133   5  12]\n",
            " [  2   1  93   9]\n",
            " [  1   2   1  70]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       relax       0.79      0.94      0.86        16\n",
            "    low_fear       0.98      0.88      0.93       151\n",
            " medium_fear       0.94      0.89      0.91       105\n",
            "   high_fear       0.76      0.95      0.84        74\n",
            "\n",
            "    accuracy                           0.90       346\n",
            "   macro avg       0.87      0.91      0.88       346\n",
            "weighted avg       0.91      0.90      0.90       346\n",
            "\n",
            "Accuracy: 89.88%\n",
            "F1 Score: 0.90\n",
            "\n",
            "Student Model Performance:\n",
            "Confusion Matrix:\n",
            " [[ 0 10  6  0]\n",
            " [ 0 98 50  3]\n",
            " [ 0 26 77  2]\n",
            " [ 1 15 49  9]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       relax       0.00      0.00      0.00        16\n",
            "    low_fear       0.66      0.65      0.65       151\n",
            " medium_fear       0.42      0.73      0.54       105\n",
            "   high_fear       0.64      0.12      0.20        74\n",
            "\n",
            "    accuracy                           0.53       346\n",
            "   macro avg       0.43      0.38      0.35       346\n",
            "weighted avg       0.55      0.53      0.49       346\n",
            "\n",
            "Accuracy: 53.18%\n",
            "F1 Score: 0.49\n"
          ]
        }
      ],
      "source": [
        "# Teacher Model Metrics\n",
        "print(\"Teacher Model Performance:\")\n",
        "teacher_conf_matrix = confusion_matrix(y_true, teacher_preds)\n",
        "teacher_class_report = classification_report(y_true, teacher_preds, target_names=['relax', 'low_fear', 'medium_fear', 'high_fear'])\n",
        "teacher_accuracy = accuracy_score(y_true, teacher_preds)\n",
        "teacher_f1 = f1_score(y_true, teacher_preds, average='weighted')\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", teacher_conf_matrix)\n",
        "print(\"\\nClassification Report:\\n\", teacher_class_report)\n",
        "print(\"Accuracy: {:.2f}%\".format(teacher_accuracy * 100))\n",
        "print(\"F1 Score: {:.2f}\".format(teacher_f1))\n",
        "\n",
        "# Student Model Metrics\n",
        "print(\"\\nStudent Model Performance:\")\n",
        "student_conf_matrix = confusion_matrix(y_true, student_preds)\n",
        "student_class_report = classification_report(y_true, student_preds, target_names=['relax', 'low_fear', 'medium_fear', 'high_fear'])\n",
        "student_accuracy = accuracy_score(y_true, student_preds)\n",
        "student_f1 = f1_score(y_true, student_preds, average='weighted')\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", student_conf_matrix)\n",
        "print(\"\\nClassification Report:\\n\", student_class_report)\n",
        "print(\"Accuracy: {:.2f}%\".format(student_accuracy * 100))\n",
        "print(\"F1 Score: {:.2f}\".format(student_f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Cross Validation"
      ],
      "metadata": {
        "id": "OH9-s4Nmk2ND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, losses, optimizers\n",
        "\n",
        "def create_teacher_model():\n",
        "    input_eeg = layers.Input(shape=(32,))\n",
        "    input_phys = layers.Input(shape=(8,))\n",
        "\n",
        "    # CNN branch for EEG signals\n",
        "    x_eeg = layers.Reshape((32, 1))(input_eeg)\n",
        "    x_eeg = layers.Conv1D(64, kernel_size=3, activation='relu')(x_eeg)\n",
        "    x_eeg = layers.MaxPooling1D(pool_size=2)(x_eeg)\n",
        "    x_eeg = layers.Conv1D(128, kernel_size=3, activation='relu')(x_eeg)\n",
        "    x_eeg = layers.MaxPooling1D(pool_size=2)(x_eeg)\n",
        "    x_eeg = layers.Flatten()(x_eeg)\n",
        "\n",
        "    # LSTM branch for physiological signals\n",
        "    x_phys = layers.Reshape((8, 1))(input_phys)\n",
        "    x_phys = layers.LSTM(64, return_sequences=False)(x_phys)\n",
        "\n",
        "    # Combine both branches\n",
        "    combined = layers.Concatenate()([x_eeg, x_phys])\n",
        "    combined = layers.Dense(128, activation='relu')(combined)\n",
        "    output = layers.Dense(4, activation='softmax')(combined)\n",
        "\n",
        "    model = models.Model(inputs=[input_eeg, input_phys], outputs=output)\n",
        "    return model\n",
        "\n",
        "teacher_model = create_teacher_model()\n",
        "teacher_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "OKn_zOtHlF0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "# Assuming teacher_model is already defined and compiled\n",
        "\n",
        "# Define 5-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Prepare arrays to store the results\n",
        "fold_accuracies = []\n",
        "fold_losses = []\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(eeg_signals_train)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    # Split the data into training and validation sets for this fold\n",
        "    eeg_train_fold = eeg_signals_train[train_idx]\n",
        "    phys_train_fold = phys_signals_train[train_idx]\n",
        "    y_train_fold = y_train[train_idx]\n",
        "\n",
        "    eeg_val_fold = eeg_signals_train[val_idx]\n",
        "    phys_val_fold = phys_signals_train[val_idx]\n",
        "    y_val_fold = y_train[val_idx]\n",
        "\n",
        "    # Train the model on the current fold\n",
        "    history = teacher_model.fit(\n",
        "        [eeg_train_fold, phys_train_fold], y_train_fold,\n",
        "        epochs=100,\n",
        "        validation_data=([eeg_val_fold, phys_val_fold], y_val_fold),\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Store the validation accuracy and loss\n",
        "    fold_accuracies.append(history.history['val_accuracy'][-1])\n",
        "    fold_losses.append(history.history['val_loss'][-1])\n",
        "\n",
        "# Calculate and print the average accuracy and loss across all folds\n",
        "mean_accuracy = np.mean(fold_accuracies)\n",
        "mean_loss = np.mean(fold_losses)\n",
        "\n",
        "print(f\"Average accuracy across 5 folds: {mean_accuracy}\")\n",
        "print(f\"Average loss across 5 folds: {mean_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQXKswR7k5St",
        "outputId": "40f81295-7510-4d77-81bf-09358d55e5d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training fold 1...\n",
            "Epoch 1/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.3899 - loss: 1.2393 - val_accuracy: 0.4946 - val_loss: 1.1006\n",
            "Epoch 2/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.5156 - loss: 1.0659 - val_accuracy: 0.5451 - val_loss: 1.0146\n",
            "Epoch 3/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5706 - loss: 0.9817 - val_accuracy: 0.5415 - val_loss: 0.9689\n",
            "Epoch 4/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6286 - loss: 0.8940 - val_accuracy: 0.5812 - val_loss: 0.9225\n",
            "Epoch 5/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6869 - loss: 0.8070 - val_accuracy: 0.6065 - val_loss: 0.8749\n",
            "Epoch 6/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6658 - loss: 0.7931 - val_accuracy: 0.6679 - val_loss: 0.8183\n",
            "Epoch 7/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7397 - loss: 0.7056 - val_accuracy: 0.7220 - val_loss: 0.7071\n",
            "Epoch 8/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7592 - loss: 0.6465 - val_accuracy: 0.7365 - val_loss: 0.7588\n",
            "Epoch 9/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7647 - loss: 0.6558 - val_accuracy: 0.6715 - val_loss: 0.7474\n",
            "Epoch 10/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7624 - loss: 0.6069 - val_accuracy: 0.7148 - val_loss: 0.6721\n",
            "Epoch 11/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7964 - loss: 0.5327 - val_accuracy: 0.6895 - val_loss: 0.7515\n",
            "Epoch 12/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7985 - loss: 0.5418 - val_accuracy: 0.7365 - val_loss: 0.6619\n",
            "Epoch 13/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8115 - loss: 0.5176 - val_accuracy: 0.7292 - val_loss: 0.6473\n",
            "Epoch 14/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8316 - loss: 0.4544 - val_accuracy: 0.7509 - val_loss: 0.5923\n",
            "Epoch 15/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8526 - loss: 0.4117 - val_accuracy: 0.7545 - val_loss: 0.5952\n",
            "Epoch 16/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8431 - loss: 0.4176 - val_accuracy: 0.7653 - val_loss: 0.6231\n",
            "Epoch 17/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8596 - loss: 0.3909 - val_accuracy: 0.7437 - val_loss: 0.6096\n",
            "Epoch 18/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8815 - loss: 0.3553 - val_accuracy: 0.7581 - val_loss: 0.5692\n",
            "Epoch 19/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8784 - loss: 0.3272 - val_accuracy: 0.7690 - val_loss: 0.5505\n",
            "Epoch 20/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8783 - loss: 0.3335 - val_accuracy: 0.7726 - val_loss: 0.5605\n",
            "Epoch 21/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9081 - loss: 0.3008 - val_accuracy: 0.7870 - val_loss: 0.5542\n",
            "Epoch 22/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8863 - loss: 0.3164 - val_accuracy: 0.7726 - val_loss: 0.6284\n",
            "Epoch 23/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9003 - loss: 0.2857 - val_accuracy: 0.7834 - val_loss: 0.4985\n",
            "Epoch 24/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9101 - loss: 0.2484 - val_accuracy: 0.7870 - val_loss: 0.5407\n",
            "Epoch 25/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9168 - loss: 0.2487 - val_accuracy: 0.7762 - val_loss: 0.5824\n",
            "Epoch 26/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9257 - loss: 0.2448 - val_accuracy: 0.8123 - val_loss: 0.5296\n",
            "Epoch 27/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9346 - loss: 0.2283 - val_accuracy: 0.8195 - val_loss: 0.5210\n",
            "Epoch 28/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9261 - loss: 0.2539 - val_accuracy: 0.7906 - val_loss: 0.5339\n",
            "Epoch 29/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9459 - loss: 0.1955 - val_accuracy: 0.8051 - val_loss: 0.5418\n",
            "Epoch 30/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9366 - loss: 0.2630 - val_accuracy: 0.8159 - val_loss: 0.5262\n",
            "Epoch 31/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9198 - loss: 0.2243 - val_accuracy: 0.8231 - val_loss: 0.5001\n",
            "Epoch 32/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9415 - loss: 0.1977 - val_accuracy: 0.7906 - val_loss: 0.5740\n",
            "Epoch 33/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9492 - loss: 0.1897 - val_accuracy: 0.8051 - val_loss: 0.5159\n",
            "Epoch 34/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9353 - loss: 0.1946 - val_accuracy: 0.8123 - val_loss: 0.5271\n",
            "Epoch 35/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9552 - loss: 0.1651 - val_accuracy: 0.8267 - val_loss: 0.5041\n",
            "Epoch 36/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9512 - loss: 0.1607 - val_accuracy: 0.8231 - val_loss: 0.5252\n",
            "Epoch 37/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9434 - loss: 0.1909 - val_accuracy: 0.8051 - val_loss: 0.5567\n",
            "Epoch 38/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9614 - loss: 0.1312 - val_accuracy: 0.8339 - val_loss: 0.5578\n",
            "Epoch 39/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9660 - loss: 0.1203 - val_accuracy: 0.8339 - val_loss: 0.5387\n",
            "Epoch 40/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9531 - loss: 0.1281 - val_accuracy: 0.8339 - val_loss: 0.5297\n",
            "Epoch 41/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9534 - loss: 0.1417 - val_accuracy: 0.8339 - val_loss: 0.5061\n",
            "Epoch 42/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9756 - loss: 0.1106 - val_accuracy: 0.8303 - val_loss: 0.5485\n",
            "Epoch 43/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9742 - loss: 0.1011 - val_accuracy: 0.8231 - val_loss: 0.5953\n",
            "Epoch 44/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9678 - loss: 0.1265 - val_accuracy: 0.8195 - val_loss: 0.5604\n",
            "Epoch 45/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9538 - loss: 0.1551 - val_accuracy: 0.8556 - val_loss: 0.5261\n",
            "Epoch 46/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9737 - loss: 0.0934 - val_accuracy: 0.8484 - val_loss: 0.4937\n",
            "Epoch 47/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9717 - loss: 0.0875 - val_accuracy: 0.8375 - val_loss: 0.5014\n",
            "Epoch 48/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9778 - loss: 0.0941 - val_accuracy: 0.8339 - val_loss: 0.5662\n",
            "Epoch 49/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9750 - loss: 0.1061 - val_accuracy: 0.8448 - val_loss: 0.5693\n",
            "Epoch 50/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9770 - loss: 0.1171 - val_accuracy: 0.8484 - val_loss: 0.5447\n",
            "Epoch 51/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9737 - loss: 0.0894 - val_accuracy: 0.8592 - val_loss: 0.5024\n",
            "Epoch 52/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9814 - loss: 0.0811 - val_accuracy: 0.8195 - val_loss: 0.5719\n",
            "Epoch 53/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9784 - loss: 0.0819 - val_accuracy: 0.8339 - val_loss: 0.5842\n",
            "Epoch 54/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9826 - loss: 0.0668 - val_accuracy: 0.8484 - val_loss: 0.5536\n",
            "Epoch 55/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9749 - loss: 0.0965 - val_accuracy: 0.8448 - val_loss: 0.5600\n",
            "Epoch 56/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9845 - loss: 0.0615 - val_accuracy: 0.8556 - val_loss: 0.5468\n",
            "Epoch 57/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9871 - loss: 0.0535 - val_accuracy: 0.8484 - val_loss: 0.5692\n",
            "Epoch 58/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9892 - loss: 0.0495 - val_accuracy: 0.8339 - val_loss: 0.5888\n",
            "Epoch 59/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9823 - loss: 0.0661 - val_accuracy: 0.8736 - val_loss: 0.5285\n",
            "Epoch 60/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9817 - loss: 0.0612 - val_accuracy: 0.8339 - val_loss: 0.6508\n",
            "Epoch 61/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9729 - loss: 0.0769 - val_accuracy: 0.8412 - val_loss: 0.6761\n",
            "Epoch 62/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9890 - loss: 0.0637 - val_accuracy: 0.8520 - val_loss: 0.5637\n",
            "Epoch 63/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9915 - loss: 0.0403 - val_accuracy: 0.8664 - val_loss: 0.5315\n",
            "Epoch 64/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9893 - loss: 0.0538 - val_accuracy: 0.8628 - val_loss: 0.5735\n",
            "Epoch 65/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9811 - loss: 0.0565 - val_accuracy: 0.8664 - val_loss: 0.5622\n",
            "Epoch 66/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9886 - loss: 0.0628 - val_accuracy: 0.8556 - val_loss: 0.6165\n",
            "Epoch 67/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9821 - loss: 0.0845 - val_accuracy: 0.8159 - val_loss: 0.8825\n",
            "Epoch 68/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9620 - loss: 0.1394 - val_accuracy: 0.8484 - val_loss: 0.5673\n",
            "Epoch 69/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9815 - loss: 0.0652 - val_accuracy: 0.8520 - val_loss: 0.6573\n",
            "Epoch 70/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9865 - loss: 0.0576 - val_accuracy: 0.8592 - val_loss: 0.5536\n",
            "Epoch 71/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9951 - loss: 0.0316 - val_accuracy: 0.8628 - val_loss: 0.5683\n",
            "Epoch 72/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9963 - loss: 0.0313 - val_accuracy: 0.8303 - val_loss: 0.5858\n",
            "Epoch 73/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9932 - loss: 0.0379 - val_accuracy: 0.8592 - val_loss: 0.6379\n",
            "Epoch 74/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9928 - loss: 0.0414 - val_accuracy: 0.8339 - val_loss: 0.5569\n",
            "Epoch 75/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9904 - loss: 0.0292 - val_accuracy: 0.8520 - val_loss: 0.5699\n",
            "Epoch 76/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9948 - loss: 0.0299 - val_accuracy: 0.8592 - val_loss: 0.5671\n",
            "Epoch 77/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9878 - loss: 0.0356 - val_accuracy: 0.8628 - val_loss: 0.5734\n",
            "Epoch 78/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9939 - loss: 0.0379 - val_accuracy: 0.8773 - val_loss: 0.5460\n",
            "Epoch 79/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9912 - loss: 0.0351 - val_accuracy: 0.8448 - val_loss: 0.6459\n",
            "Epoch 80/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9873 - loss: 0.0369 - val_accuracy: 0.8520 - val_loss: 0.6105\n",
            "Epoch 81/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9944 - loss: 0.0220 - val_accuracy: 0.8592 - val_loss: 0.5718\n",
            "Epoch 82/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9958 - loss: 0.0270 - val_accuracy: 0.8664 - val_loss: 0.6126\n",
            "Epoch 83/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9974 - loss: 0.0192 - val_accuracy: 0.8484 - val_loss: 0.5949\n",
            "Epoch 84/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9901 - loss: 0.0489 - val_accuracy: 0.8700 - val_loss: 0.6045\n",
            "Epoch 85/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9991 - loss: 0.0145 - val_accuracy: 0.8700 - val_loss: 0.6567\n",
            "Epoch 86/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9935 - loss: 0.0265 - val_accuracy: 0.8628 - val_loss: 0.6078\n",
            "Epoch 87/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9970 - loss: 0.0178 - val_accuracy: 0.8592 - val_loss: 0.6046\n",
            "Epoch 88/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9972 - loss: 0.0172 - val_accuracy: 0.8664 - val_loss: 0.6482\n",
            "Epoch 89/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9964 - loss: 0.0158 - val_accuracy: 0.8700 - val_loss: 0.6340\n",
            "Epoch 90/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9965 - loss: 0.0182 - val_accuracy: 0.8736 - val_loss: 0.5914\n",
            "Epoch 91/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9965 - loss: 0.0184 - val_accuracy: 0.8664 - val_loss: 0.6410\n",
            "Epoch 92/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9956 - loss: 0.0132 - val_accuracy: 0.8592 - val_loss: 0.6238\n",
            "Epoch 93/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9950 - loss: 0.0188 - val_accuracy: 0.8592 - val_loss: 0.6212\n",
            "Epoch 94/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9995 - loss: 0.0078 - val_accuracy: 0.8664 - val_loss: 0.6670\n",
            "Epoch 95/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9966 - loss: 0.0115 - val_accuracy: 0.8520 - val_loss: 0.7258\n",
            "Epoch 96/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9920 - loss: 0.0264 - val_accuracy: 0.8628 - val_loss: 0.7221\n",
            "Epoch 97/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.8592 - val_loss: 0.6663\n",
            "Epoch 98/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9992 - loss: 0.0101 - val_accuracy: 0.8736 - val_loss: 0.7246\n",
            "Epoch 99/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9976 - loss: 0.0090 - val_accuracy: 0.8700 - val_loss: 0.6421\n",
            "Epoch 100/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9994 - loss: 0.0090 - val_accuracy: 0.8736 - val_loss: 0.6751\n",
            "Training fold 2...\n",
            "Epoch 1/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9629 - loss: 0.1624 - val_accuracy: 0.8520 - val_loss: 0.4260\n",
            "Epoch 2/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8877 - loss: 0.3635 - val_accuracy: 0.9314 - val_loss: 0.2486\n",
            "Epoch 3/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9303 - loss: 0.1882 - val_accuracy: 0.9314 - val_loss: 0.1669\n",
            "Epoch 4/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9655 - loss: 0.0939 - val_accuracy: 0.9458 - val_loss: 0.1297\n",
            "Epoch 5/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9684 - loss: 0.1045 - val_accuracy: 0.9386 - val_loss: 0.1401\n",
            "Epoch 6/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9767 - loss: 0.0711 - val_accuracy: 0.9458 - val_loss: 0.1374\n",
            "Epoch 7/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9883 - loss: 0.0522 - val_accuracy: 0.9386 - val_loss: 0.1483\n",
            "Epoch 8/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9919 - loss: 0.0376 - val_accuracy: 0.9531 - val_loss: 0.1476\n",
            "Epoch 9/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9906 - loss: 0.0404 - val_accuracy: 0.9531 - val_loss: 0.1206\n",
            "Epoch 10/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9934 - loss: 0.0358 - val_accuracy: 0.9567 - val_loss: 0.1109\n",
            "Epoch 11/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9950 - loss: 0.0239 - val_accuracy: 0.9567 - val_loss: 0.1143\n",
            "Epoch 12/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9908 - loss: 0.0320 - val_accuracy: 0.9531 - val_loss: 0.1204\n",
            "Epoch 13/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9957 - loss: 0.0259 - val_accuracy: 0.9495 - val_loss: 0.1204\n",
            "Epoch 14/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9907 - loss: 0.0347 - val_accuracy: 0.9495 - val_loss: 0.1217\n",
            "Epoch 15/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9885 - loss: 0.0347 - val_accuracy: 0.9567 - val_loss: 0.1089\n",
            "Epoch 16/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9913 - loss: 0.0272 - val_accuracy: 0.9531 - val_loss: 0.1253\n",
            "Epoch 17/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9966 - loss: 0.0175 - val_accuracy: 0.9531 - val_loss: 0.1140\n",
            "Epoch 18/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9960 - loss: 0.0223 - val_accuracy: 0.9747 - val_loss: 0.1049\n",
            "Epoch 19/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9907 - loss: 0.0274 - val_accuracy: 0.9458 - val_loss: 0.1320\n",
            "Epoch 20/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9921 - loss: 0.0201 - val_accuracy: 0.9531 - val_loss: 0.1165\n",
            "Epoch 21/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9973 - loss: 0.0154 - val_accuracy: 0.9495 - val_loss: 0.1420\n",
            "Epoch 22/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9932 - loss: 0.0247 - val_accuracy: 0.9495 - val_loss: 0.1494\n",
            "Epoch 23/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9950 - loss: 0.0203 - val_accuracy: 0.9567 - val_loss: 0.1125\n",
            "Epoch 24/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9942 - loss: 0.0167 - val_accuracy: 0.9567 - val_loss: 0.1083\n",
            "Epoch 25/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9930 - loss: 0.0185 - val_accuracy: 0.9386 - val_loss: 0.1486\n",
            "Epoch 26/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9938 - loss: 0.0191 - val_accuracy: 0.9422 - val_loss: 0.1388\n",
            "Epoch 27/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9955 - loss: 0.0141 - val_accuracy: 0.9531 - val_loss: 0.1345\n",
            "Epoch 28/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9955 - loss: 0.0121 - val_accuracy: 0.9603 - val_loss: 0.1171\n",
            "Epoch 29/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9951 - loss: 0.0107 - val_accuracy: 0.9495 - val_loss: 0.1326\n",
            "Epoch 30/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9940 - loss: 0.0136 - val_accuracy: 0.9458 - val_loss: 0.1373\n",
            "Epoch 31/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9965 - loss: 0.0107 - val_accuracy: 0.9458 - val_loss: 0.1375\n",
            "Epoch 32/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9945 - loss: 0.0184 - val_accuracy: 0.9495 - val_loss: 0.1246\n",
            "Epoch 33/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9919 - loss: 0.0207 - val_accuracy: 0.9458 - val_loss: 0.1417\n",
            "Epoch 34/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9979 - loss: 0.0081 - val_accuracy: 0.9531 - val_loss: 0.1354\n",
            "Epoch 35/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9962 - loss: 0.0102 - val_accuracy: 0.9567 - val_loss: 0.1333\n",
            "Epoch 36/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9983 - loss: 0.0081 - val_accuracy: 0.9567 - val_loss: 0.1375\n",
            "Epoch 37/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9966 - loss: 0.0113 - val_accuracy: 0.9567 - val_loss: 0.1389\n",
            "Epoch 38/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9974 - loss: 0.0123 - val_accuracy: 0.9531 - val_loss: 0.1348\n",
            "Epoch 39/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9994 - loss: 0.0054 - val_accuracy: 0.9531 - val_loss: 0.1358\n",
            "Epoch 40/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9941 - loss: 0.0128 - val_accuracy: 0.9531 - val_loss: 0.1440\n",
            "Epoch 41/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9958 - loss: 0.0144 - val_accuracy: 0.9531 - val_loss: 0.1343\n",
            "Epoch 42/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9986 - loss: 0.0051 - val_accuracy: 0.9422 - val_loss: 0.1486\n",
            "Epoch 43/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9957 - loss: 0.0171 - val_accuracy: 0.9458 - val_loss: 0.1586\n",
            "Epoch 44/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9961 - loss: 0.0227 - val_accuracy: 0.9495 - val_loss: 0.1355\n",
            "Epoch 45/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9958 - loss: 0.0095 - val_accuracy: 0.9531 - val_loss: 0.1447\n",
            "Epoch 46/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9986 - loss: 0.0060 - val_accuracy: 0.9386 - val_loss: 0.1635\n",
            "Epoch 47/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9940 - loss: 0.0123 - val_accuracy: 0.9495 - val_loss: 0.1597\n",
            "Epoch 48/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9953 - loss: 0.0086 - val_accuracy: 0.9495 - val_loss: 0.1619\n",
            "Epoch 49/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9969 - loss: 0.0086 - val_accuracy: 0.9422 - val_loss: 0.1677\n",
            "Epoch 50/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9956 - loss: 0.0156 - val_accuracy: 0.9422 - val_loss: 0.1657\n",
            "Epoch 51/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9988 - loss: 0.0078 - val_accuracy: 0.9531 - val_loss: 0.1448\n",
            "Epoch 52/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9961 - loss: 0.0116 - val_accuracy: 0.9531 - val_loss: 0.1235\n",
            "Epoch 53/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9988 - loss: 0.0107 - val_accuracy: 0.9495 - val_loss: 0.1525\n",
            "Epoch 54/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9942 - loss: 0.0187 - val_accuracy: 0.9567 - val_loss: 0.1441\n",
            "Epoch 55/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9958 - loss: 0.0113 - val_accuracy: 0.9639 - val_loss: 0.1396\n",
            "Epoch 56/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9976 - loss: 0.0086 - val_accuracy: 0.9603 - val_loss: 0.1365\n",
            "Epoch 57/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9998 - loss: 0.0043 - val_accuracy: 0.9531 - val_loss: 0.1514\n",
            "Epoch 58/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9973 - loss: 0.0117 - val_accuracy: 0.9495 - val_loss: 0.1632\n",
            "Epoch 59/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9989 - loss: 0.0066 - val_accuracy: 0.9495 - val_loss: 0.1503\n",
            "Epoch 60/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9970 - loss: 0.0124 - val_accuracy: 0.9278 - val_loss: 0.1942\n",
            "Epoch 61/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9962 - loss: 0.0116 - val_accuracy: 0.9567 - val_loss: 0.1449\n",
            "Epoch 62/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9982 - loss: 0.0074 - val_accuracy: 0.9314 - val_loss: 0.1955\n",
            "Epoch 63/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9957 - loss: 0.0108 - val_accuracy: 0.9350 - val_loss: 0.2165\n",
            "Epoch 64/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.9350 - val_loss: 0.1812\n",
            "Epoch 65/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9973 - loss: 0.0113 - val_accuracy: 0.9278 - val_loss: 0.2941\n",
            "Epoch 66/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9916 - loss: 0.0363 - val_accuracy: 0.9134 - val_loss: 0.3469\n",
            "Epoch 67/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9837 - loss: 0.0474 - val_accuracy: 0.8917 - val_loss: 0.2793\n",
            "Epoch 68/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9743 - loss: 0.0661 - val_accuracy: 0.9242 - val_loss: 0.2673\n",
            "Epoch 69/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9656 - loss: 0.1094 - val_accuracy: 0.8700 - val_loss: 0.4451\n",
            "Epoch 70/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9639 - loss: 0.1224 - val_accuracy: 0.8989 - val_loss: 0.2803\n",
            "Epoch 71/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9715 - loss: 0.0727 - val_accuracy: 0.9242 - val_loss: 0.1885\n",
            "Epoch 72/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9873 - loss: 0.0610 - val_accuracy: 0.9350 - val_loss: 0.1896\n",
            "Epoch 73/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9909 - loss: 0.0277 - val_accuracy: 0.9278 - val_loss: 0.2475\n",
            "Epoch 74/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9925 - loss: 0.0224 - val_accuracy: 0.9170 - val_loss: 0.2027\n",
            "Epoch 75/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9985 - loss: 0.0063 - val_accuracy: 0.9278 - val_loss: 0.1950\n",
            "Epoch 76/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9982 - loss: 0.0076 - val_accuracy: 0.9278 - val_loss: 0.2091\n",
            "Epoch 77/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9964 - loss: 0.0122 - val_accuracy: 0.9386 - val_loss: 0.2146\n",
            "Epoch 78/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 0.0091 - val_accuracy: 0.9350 - val_loss: 0.2166\n",
            "Epoch 79/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9988 - loss: 0.0061 - val_accuracy: 0.9386 - val_loss: 0.2030\n",
            "Epoch 80/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9977 - loss: 0.0088 - val_accuracy: 0.9206 - val_loss: 0.2064\n",
            "Epoch 81/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9983 - loss: 0.0061 - val_accuracy: 0.9314 - val_loss: 0.2179\n",
            "Epoch 82/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9979 - loss: 0.0052 - val_accuracy: 0.9242 - val_loss: 0.2146\n",
            "Epoch 83/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9932 - loss: 0.0235 - val_accuracy: 0.9350 - val_loss: 0.1986\n",
            "Epoch 84/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9973 - loss: 0.0105 - val_accuracy: 0.9314 - val_loss: 0.1953\n",
            "Epoch 85/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9977 - loss: 0.0067 - val_accuracy: 0.9350 - val_loss: 0.1968\n",
            "Epoch 86/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9989 - loss: 0.0045 - val_accuracy: 0.9350 - val_loss: 0.2151\n",
            "Epoch 87/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9958 - loss: 0.0069 - val_accuracy: 0.9278 - val_loss: 0.2173\n",
            "Epoch 88/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9977 - loss: 0.0093 - val_accuracy: 0.9278 - val_loss: 0.2210\n",
            "Epoch 89/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9968 - loss: 0.0086 - val_accuracy: 0.9314 - val_loss: 0.2156\n",
            "Epoch 90/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9973 - loss: 0.0095 - val_accuracy: 0.9278 - val_loss: 0.2223\n",
            "Epoch 91/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9998 - loss: 0.0044 - val_accuracy: 0.9278 - val_loss: 0.2203\n",
            "Epoch 92/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9988 - loss: 0.0059 - val_accuracy: 0.9314 - val_loss: 0.2084\n",
            "Epoch 93/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 0.9314 - val_loss: 0.2246\n",
            "Epoch 94/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9996 - loss: 0.0027 - val_accuracy: 0.9386 - val_loss: 0.2255\n",
            "Epoch 95/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9981 - loss: 0.0043 - val_accuracy: 0.9350 - val_loss: 0.2186\n",
            "Epoch 96/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.9386 - val_loss: 0.2274\n",
            "Epoch 97/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9977 - loss: 0.0057 - val_accuracy: 0.9386 - val_loss: 0.2261\n",
            "Epoch 98/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9978 - loss: 0.0039 - val_accuracy: 0.9386 - val_loss: 0.2290\n",
            "Epoch 99/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9964 - loss: 0.0138 - val_accuracy: 0.9350 - val_loss: 0.2155\n",
            "Epoch 100/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9986 - loss: 0.0027 - val_accuracy: 0.9350 - val_loss: 0.2174\n",
            "Training fold 3...\n",
            "Epoch 1/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9680 - loss: 0.1481 - val_accuracy: 0.9312 - val_loss: 0.2064\n",
            "Epoch 2/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9543 - loss: 0.1700 - val_accuracy: 0.9384 - val_loss: 0.1513\n",
            "Epoch 3/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9697 - loss: 0.0887 - val_accuracy: 0.9348 - val_loss: 0.1772\n",
            "Epoch 4/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9732 - loss: 0.0734 - val_accuracy: 0.9601 - val_loss: 0.1213\n",
            "Epoch 5/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9814 - loss: 0.0618 - val_accuracy: 0.9601 - val_loss: 0.1121\n",
            "Epoch 6/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9956 - loss: 0.0233 - val_accuracy: 0.9674 - val_loss: 0.0880\n",
            "Epoch 7/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9946 - loss: 0.0165 - val_accuracy: 0.9638 - val_loss: 0.0990\n",
            "Epoch 8/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9955 - loss: 0.0144 - val_accuracy: 0.9674 - val_loss: 0.0796\n",
            "Epoch 9/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9974 - loss: 0.0173 - val_accuracy: 0.9529 - val_loss: 0.1097\n",
            "Epoch 10/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9979 - loss: 0.0075 - val_accuracy: 0.9710 - val_loss: 0.0801\n",
            "Epoch 11/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9975 - loss: 0.0075 - val_accuracy: 0.9529 - val_loss: 0.1014\n",
            "Epoch 12/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9977 - loss: 0.0082 - val_accuracy: 0.9674 - val_loss: 0.0768\n",
            "Epoch 13/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9996 - loss: 0.0080 - val_accuracy: 0.9638 - val_loss: 0.0787\n",
            "Epoch 14/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9903 - loss: 0.0125 - val_accuracy: 0.9674 - val_loss: 0.0729\n",
            "Epoch 15/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9987 - loss: 0.0058 - val_accuracy: 0.9601 - val_loss: 0.0783\n",
            "Epoch 16/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9970 - loss: 0.0099 - val_accuracy: 0.9638 - val_loss: 0.0746\n",
            "Epoch 17/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9975 - loss: 0.0069 - val_accuracy: 0.9638 - val_loss: 0.0753\n",
            "Epoch 18/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9985 - loss: 0.0090 - val_accuracy: 0.9493 - val_loss: 0.1189\n",
            "Epoch 19/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9965 - loss: 0.0119 - val_accuracy: 0.9674 - val_loss: 0.0754\n",
            "Epoch 20/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9982 - loss: 0.0109 - val_accuracy: 0.9638 - val_loss: 0.0831\n",
            "Epoch 21/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9963 - loss: 0.0106 - val_accuracy: 0.9529 - val_loss: 0.1049\n",
            "Epoch 22/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9565 - val_loss: 0.0862\n",
            "Epoch 23/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9995 - loss: 0.0030 - val_accuracy: 0.9601 - val_loss: 0.0924\n",
            "Epoch 24/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9998 - loss: 0.0039 - val_accuracy: 0.9529 - val_loss: 0.0863\n",
            "Epoch 25/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9999 - loss: 0.0037 - val_accuracy: 0.9529 - val_loss: 0.0888\n",
            "Epoch 26/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9987 - loss: 0.0054 - val_accuracy: 0.9529 - val_loss: 0.0924\n",
            "Epoch 27/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9990 - loss: 0.0037 - val_accuracy: 0.9601 - val_loss: 0.0828\n",
            "Epoch 28/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.9529 - val_loss: 0.1051\n",
            "Epoch 29/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9994 - loss: 0.0055 - val_accuracy: 0.9529 - val_loss: 0.0790\n",
            "Epoch 30/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9982 - loss: 0.0067 - val_accuracy: 0.9601 - val_loss: 0.0833\n",
            "Epoch 31/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9952 - loss: 0.0130 - val_accuracy: 0.9565 - val_loss: 0.0908\n",
            "Epoch 32/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9995 - loss: 0.0028 - val_accuracy: 0.9529 - val_loss: 0.1044\n",
            "Epoch 33/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9980 - loss: 0.0046 - val_accuracy: 0.9565 - val_loss: 0.0904\n",
            "Epoch 34/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9955 - loss: 0.0089 - val_accuracy: 0.9493 - val_loss: 0.1082\n",
            "Epoch 35/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9984 - loss: 0.0064 - val_accuracy: 0.9601 - val_loss: 0.0952\n",
            "Epoch 36/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9974 - loss: 0.0055 - val_accuracy: 0.9529 - val_loss: 0.0968\n",
            "Epoch 37/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9998 - loss: 0.0033 - val_accuracy: 0.9493 - val_loss: 0.0987\n",
            "Epoch 38/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9976 - loss: 0.0063 - val_accuracy: 0.9529 - val_loss: 0.0927\n",
            "Epoch 39/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9965 - loss: 0.0074 - val_accuracy: 0.9529 - val_loss: 0.1037\n",
            "Epoch 40/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9986 - loss: 0.0041 - val_accuracy: 0.9529 - val_loss: 0.0895\n",
            "Epoch 41/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9968 - loss: 0.0095 - val_accuracy: 0.9565 - val_loss: 0.0877\n",
            "Epoch 42/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9493 - val_loss: 0.1133\n",
            "Epoch 43/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9998 - loss: 0.0020 - val_accuracy: 0.9493 - val_loss: 0.1040\n",
            "Epoch 44/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9493 - val_loss: 0.1005\n",
            "Epoch 45/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9985 - loss: 0.0039 - val_accuracy: 0.9493 - val_loss: 0.0991\n",
            "Epoch 46/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.9493 - val_loss: 0.1146\n",
            "Epoch 47/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9987 - loss: 0.0059 - val_accuracy: 0.9529 - val_loss: 0.1007\n",
            "Epoch 48/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9978 - loss: 0.0059 - val_accuracy: 0.9493 - val_loss: 0.1029\n",
            "Epoch 49/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.9529 - val_loss: 0.1033\n",
            "Epoch 50/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9969 - loss: 0.0041 - val_accuracy: 0.9457 - val_loss: 0.1183\n",
            "Epoch 51/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9988 - loss: 0.0029 - val_accuracy: 0.9457 - val_loss: 0.0979\n",
            "Epoch 52/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9493 - val_loss: 0.1103\n",
            "Epoch 53/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9493 - val_loss: 0.1159\n",
            "Epoch 54/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.9529 - val_loss: 0.0919\n",
            "Epoch 55/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9980 - loss: 0.0057 - val_accuracy: 0.9529 - val_loss: 0.1020\n",
            "Epoch 56/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9981 - loss: 0.0035 - val_accuracy: 0.9493 - val_loss: 0.1144\n",
            "Epoch 57/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9976 - loss: 0.0055 - val_accuracy: 0.9565 - val_loss: 0.0961\n",
            "Epoch 58/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9970 - loss: 0.0050 - val_accuracy: 0.9493 - val_loss: 0.0978\n",
            "Epoch 59/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.9457 - val_loss: 0.1284\n",
            "Epoch 60/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9420 - val_loss: 0.1250\n",
            "Epoch 61/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9986 - loss: 0.0037 - val_accuracy: 0.9565 - val_loss: 0.0952\n",
            "Epoch 62/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9977 - loss: 0.0052 - val_accuracy: 0.9493 - val_loss: 0.1098\n",
            "Epoch 63/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9972 - loss: 0.0147 - val_accuracy: 0.9493 - val_loss: 0.0924\n",
            "Epoch 64/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9565 - val_loss: 0.1001\n",
            "Epoch 65/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9976 - loss: 0.0055 - val_accuracy: 0.9457 - val_loss: 0.1036\n",
            "Epoch 66/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9919 - loss: 0.0240 - val_accuracy: 0.8949 - val_loss: 0.3255\n",
            "Epoch 67/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9640 - loss: 0.1149 - val_accuracy: 0.8659 - val_loss: 0.4308\n",
            "Epoch 68/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9661 - loss: 0.1003 - val_accuracy: 0.9312 - val_loss: 0.2541\n",
            "Epoch 69/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9683 - loss: 0.0874 - val_accuracy: 0.9058 - val_loss: 0.2706\n",
            "Epoch 70/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9644 - loss: 0.1047 - val_accuracy: 0.8913 - val_loss: 0.3372\n",
            "Epoch 71/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9890 - loss: 0.0371 - val_accuracy: 0.9022 - val_loss: 0.2621\n",
            "Epoch 72/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9954 - loss: 0.0125 - val_accuracy: 0.9239 - val_loss: 0.2073\n",
            "Epoch 73/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9944 - loss: 0.0166 - val_accuracy: 0.9130 - val_loss: 0.2575\n",
            "Epoch 74/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9916 - loss: 0.0268 - val_accuracy: 0.9167 - val_loss: 0.2366\n",
            "Epoch 75/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9955 - loss: 0.0130 - val_accuracy: 0.9167 - val_loss: 0.2439\n",
            "Epoch 76/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9203 - val_loss: 0.2322\n",
            "Epoch 77/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9239 - val_loss: 0.2331\n",
            "Epoch 78/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9203 - val_loss: 0.2344\n",
            "Epoch 79/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9203 - val_loss: 0.2419\n",
            "Epoch 80/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9203 - val_loss: 0.2411\n",
            "Epoch 81/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9203 - val_loss: 0.2430\n",
            "Epoch 82/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9203 - val_loss: 0.2424\n",
            "Epoch 83/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9203 - val_loss: 0.2420\n",
            "Epoch 84/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9203 - val_loss: 0.2418\n",
            "Epoch 85/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.9203 - val_loss: 0.2604\n",
            "Epoch 86/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9203 - val_loss: 0.2372\n",
            "Epoch 87/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9203 - val_loss: 0.2371\n",
            "Epoch 88/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 0.0018 - val_accuracy: 0.9203 - val_loss: 0.2404\n",
            "Epoch 89/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9965 - loss: 0.0137 - val_accuracy: 0.9203 - val_loss: 0.2398\n",
            "Epoch 90/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9203 - val_loss: 0.2356\n",
            "Epoch 91/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9239 - val_loss: 0.2360\n",
            "Epoch 92/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9203 - val_loss: 0.2496\n",
            "Epoch 93/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9239 - val_loss: 0.2339\n",
            "Epoch 94/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9203 - val_loss: 0.2562\n",
            "Epoch 95/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9239 - val_loss: 0.2492\n",
            "Epoch 96/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9239 - val_loss: 0.2434\n",
            "Epoch 97/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9993 - loss: 0.0032 - val_accuracy: 0.9239 - val_loss: 0.2442\n",
            "Epoch 98/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9975 - loss: 0.0056 - val_accuracy: 0.9239 - val_loss: 0.2293\n",
            "Epoch 99/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9239 - val_loss: 0.2374\n",
            "Epoch 100/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9239 - val_loss: 0.2341\n",
            "Training fold 4...\n",
            "Epoch 1/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9812 - loss: 0.0573 - val_accuracy: 0.9710 - val_loss: 0.0884\n",
            "Epoch 2/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9665 - loss: 0.1229 - val_accuracy: 0.9493 - val_loss: 0.2301\n",
            "Epoch 3/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9734 - loss: 0.0884 - val_accuracy: 0.9819 - val_loss: 0.0923\n",
            "Epoch 4/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9913 - loss: 0.0290 - val_accuracy: 0.9783 - val_loss: 0.0891\n",
            "Epoch 5/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9936 - loss: 0.0207 - val_accuracy: 0.9891 - val_loss: 0.0610\n",
            "Epoch 6/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9981 - loss: 0.0101 - val_accuracy: 0.9928 - val_loss: 0.0516\n",
            "Epoch 7/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9996 - loss: 0.0053 - val_accuracy: 0.9855 - val_loss: 0.0582\n",
            "Epoch 8/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9997 - loss: 0.0041 - val_accuracy: 0.9928 - val_loss: 0.0529\n",
            "Epoch 9/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9855 - val_loss: 0.0569\n",
            "Epoch 10/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9891 - val_loss: 0.0543\n",
            "Epoch 11/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9928 - val_loss: 0.0504\n",
            "Epoch 12/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9891 - val_loss: 0.0519\n",
            "Epoch 13/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.9855 - val_loss: 0.0552\n",
            "Epoch 14/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9997 - loss: 0.0033 - val_accuracy: 0.9891 - val_loss: 0.0527\n",
            "Epoch 15/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9981 - loss: 0.0053 - val_accuracy: 0.9928 - val_loss: 0.0472\n",
            "Epoch 16/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9855 - val_loss: 0.0480\n",
            "Epoch 17/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.9928 - val_loss: 0.0479\n",
            "Epoch 18/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9891 - val_loss: 0.0482\n",
            "Epoch 19/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9928 - val_loss: 0.0477\n",
            "Epoch 20/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9928 - val_loss: 0.0474\n",
            "Epoch 21/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9928 - val_loss: 0.0473\n",
            "Epoch 22/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9891 - val_loss: 0.0464\n",
            "Epoch 23/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9928 - val_loss: 0.0468\n",
            "Epoch 24/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9980 - loss: 0.0040 - val_accuracy: 0.9891 - val_loss: 0.0467\n",
            "Epoch 25/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9982 - loss: 0.0026 - val_accuracy: 0.9928 - val_loss: 0.0459\n",
            "Epoch 26/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9891 - val_loss: 0.0451\n",
            "Epoch 27/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9985 - loss: 0.0036 - val_accuracy: 0.9928 - val_loss: 0.0459\n",
            "Epoch 28/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.9855 - val_loss: 0.0524\n",
            "Epoch 29/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9965 - loss: 0.0088 - val_accuracy: 0.9891 - val_loss: 0.0499\n",
            "Epoch 30/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9891 - val_loss: 0.0487\n",
            "Epoch 31/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9891 - val_loss: 0.0486\n",
            "Epoch 32/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9891 - val_loss: 0.0486\n",
            "Epoch 33/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9891 - val_loss: 0.0488\n",
            "Epoch 34/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9891 - val_loss: 0.0496\n",
            "Epoch 35/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9891 - val_loss: 0.0491\n",
            "Epoch 36/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 7.5284e-04 - val_accuracy: 0.9891 - val_loss: 0.0499\n",
            "Epoch 37/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 9.0336e-04 - val_accuracy: 0.9891 - val_loss: 0.0494\n",
            "Epoch 38/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9891 - val_loss: 0.0488\n",
            "Epoch 39/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9891 - val_loss: 0.0494\n",
            "Epoch 40/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9891 - val_loss: 0.0495\n",
            "Epoch 41/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 8.4268e-04 - val_accuracy: 0.9891 - val_loss: 0.0505\n",
            "Epoch 42/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 9.0228e-04 - val_accuracy: 0.9891 - val_loss: 0.0509\n",
            "Epoch 43/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 6.8436e-04 - val_accuracy: 0.9891 - val_loss: 0.0506\n",
            "Epoch 44/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.9361e-04 - val_accuracy: 0.9891 - val_loss: 0.0516\n",
            "Epoch 45/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 9.4916e-04 - val_accuracy: 0.9891 - val_loss: 0.0502\n",
            "Epoch 46/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 7.2180e-04 - val_accuracy: 0.9891 - val_loss: 0.0502\n",
            "Epoch 47/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 5.4508e-04 - val_accuracy: 0.9891 - val_loss: 0.0505\n",
            "Epoch 48/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 8.3888e-04 - val_accuracy: 0.9891 - val_loss: 0.0511\n",
            "Epoch 49/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.0973e-04 - val_accuracy: 0.9891 - val_loss: 0.0505\n",
            "Epoch 50/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 5.2350e-04 - val_accuracy: 0.9891 - val_loss: 0.0499\n",
            "Epoch 51/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.0713e-04 - val_accuracy: 0.9891 - val_loss: 0.0509\n",
            "Epoch 52/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 7.6072e-04 - val_accuracy: 0.9891 - val_loss: 0.0506\n",
            "Epoch 53/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 7.3132e-04 - val_accuracy: 0.9891 - val_loss: 0.0488\n",
            "Epoch 54/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.4554e-04 - val_accuracy: 0.9891 - val_loss: 0.0499\n",
            "Epoch 55/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.0242e-04 - val_accuracy: 0.9891 - val_loss: 0.0496\n",
            "Epoch 56/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 3.9989e-04 - val_accuracy: 0.9891 - val_loss: 0.0488\n",
            "Epoch 57/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.5771e-04 - val_accuracy: 0.9891 - val_loss: 0.0494\n",
            "Epoch 58/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 3.7796e-04 - val_accuracy: 0.9891 - val_loss: 0.0492\n",
            "Epoch 59/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.1442e-04 - val_accuracy: 0.9891 - val_loss: 0.0487\n",
            "Epoch 60/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.2755e-04 - val_accuracy: 0.9891 - val_loss: 0.0478\n",
            "Epoch 61/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.6949e-04 - val_accuracy: 0.9891 - val_loss: 0.0492\n",
            "Epoch 62/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 8.2732e-04 - val_accuracy: 0.9891 - val_loss: 0.0478\n",
            "Epoch 63/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.5561e-04 - val_accuracy: 0.9891 - val_loss: 0.0455\n",
            "Epoch 64/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 6.6200e-04 - val_accuracy: 0.9891 - val_loss: 0.0485\n",
            "Epoch 65/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.4689e-04 - val_accuracy: 0.9891 - val_loss: 0.0469\n",
            "Epoch 66/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 2.7921e-04 - val_accuracy: 0.9891 - val_loss: 0.0475\n",
            "Epoch 67/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.4878e-04 - val_accuracy: 0.9891 - val_loss: 0.0450\n",
            "Epoch 68/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.2760e-04 - val_accuracy: 0.9891 - val_loss: 0.0462\n",
            "Epoch 69/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.3840e-04 - val_accuracy: 0.9891 - val_loss: 0.0446\n",
            "Epoch 70/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.8000e-04 - val_accuracy: 0.9891 - val_loss: 0.0460\n",
            "Epoch 71/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9891 - val_loss: 0.0457\n",
            "Epoch 72/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9999 - loss: 4.4562e-04 - val_accuracy: 0.9891 - val_loss: 0.0455\n",
            "Epoch 73/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9966 - loss: 0.0279 - val_accuracy: 0.9746 - val_loss: 0.0877\n",
            "Epoch 74/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9914 - loss: 0.0210 - val_accuracy: 0.9674 - val_loss: 0.1574\n",
            "Epoch 75/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9834 - loss: 0.0574 - val_accuracy: 0.9457 - val_loss: 0.1556\n",
            "Epoch 76/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9522 - loss: 0.1628 - val_accuracy: 0.9384 - val_loss: 0.1680\n",
            "Epoch 77/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9625 - loss: 0.1121 - val_accuracy: 0.9275 - val_loss: 0.2138\n",
            "Epoch 78/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9809 - loss: 0.0558 - val_accuracy: 0.9674 - val_loss: 0.0876\n",
            "Epoch 79/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9947 - loss: 0.0207 - val_accuracy: 0.9783 - val_loss: 0.0838\n",
            "Epoch 80/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9917 - loss: 0.0182 - val_accuracy: 0.9746 - val_loss: 0.0629\n",
            "Epoch 81/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9995 - loss: 0.0043 - val_accuracy: 0.9783 - val_loss: 0.0665\n",
            "Epoch 82/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9986 - loss: 0.0055 - val_accuracy: 0.9783 - val_loss: 0.0661\n",
            "Epoch 83/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9982 - loss: 0.0052 - val_accuracy: 0.9855 - val_loss: 0.0543\n",
            "Epoch 84/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9819 - val_loss: 0.0587\n",
            "Epoch 85/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9993 - loss: 0.0039 - val_accuracy: 0.9819 - val_loss: 0.0555\n",
            "Epoch 86/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9855 - val_loss: 0.0598\n",
            "Epoch 87/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9783 - val_loss: 0.0665\n",
            "Epoch 88/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9981 - loss: 0.0081 - val_accuracy: 0.9891 - val_loss: 0.0513\n",
            "Epoch 89/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.9855 - val_loss: 0.0523\n",
            "Epoch 90/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9819 - val_loss: 0.0624\n",
            "Epoch 91/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9855 - val_loss: 0.0579\n",
            "Epoch 92/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9982 - loss: 0.0039 - val_accuracy: 0.9855 - val_loss: 0.0560\n",
            "Epoch 93/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9855 - val_loss: 0.0634\n",
            "Epoch 94/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9855 - val_loss: 0.0615\n",
            "Epoch 95/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9855 - val_loss: 0.0639\n",
            "Epoch 96/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9855 - val_loss: 0.0662\n",
            "Epoch 97/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9855 - val_loss: 0.0587\n",
            "Epoch 98/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9984 - loss: 0.0075 - val_accuracy: 0.9819 - val_loss: 0.0709\n",
            "Epoch 99/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.9986 - loss: 0.0063 - val_accuracy: 0.9855 - val_loss: 0.0567\n",
            "Epoch 100/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9932 - loss: 0.0209 - val_accuracy: 0.9746 - val_loss: 0.0521\n",
            "Training fold 5...\n",
            "Epoch 1/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9880 - loss: 0.0334 - val_accuracy: 0.9674 - val_loss: 0.0910\n",
            "Epoch 2/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9707 - loss: 0.0824 - val_accuracy: 0.9964 - val_loss: 0.0158\n",
            "Epoch 3/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9857 - loss: 0.0389 - val_accuracy: 0.9891 - val_loss: 0.0465\n",
            "Epoch 4/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9875 - loss: 0.0370 - val_accuracy: 0.9928 - val_loss: 0.0163\n",
            "Epoch 5/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9924 - loss: 0.0139 - val_accuracy: 1.0000 - val_loss: 0.0062\n",
            "Epoch 6/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9955 - loss: 0.0106 - val_accuracy: 0.9928 - val_loss: 0.0201\n",
            "Epoch 7/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9963 - loss: 0.0138 - val_accuracy: 0.9928 - val_loss: 0.0213\n",
            "Epoch 8/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9974 - loss: 0.0109 - val_accuracy: 0.9964 - val_loss: 0.0175\n",
            "Epoch 9/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9982 - loss: 0.0079 - val_accuracy: 0.9891 - val_loss: 0.0368\n",
            "Epoch 10/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9982 - loss: 0.0084 - val_accuracy: 1.0000 - val_loss: 0.0056\n",
            "Epoch 11/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 0.0074\n",
            "Epoch 12/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9993 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 0.0051\n",
            "Epoch 13/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 0.0045\n",
            "Epoch 14/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9998 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0042\n",
            "Epoch 15/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0048\n",
            "Epoch 16/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9991 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
            "Epoch 17/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
            "Epoch 18/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0052\n",
            "Epoch 19/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9985 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
            "Epoch 20/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0043\n",
            "Epoch 21/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
            "Epoch 22/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0046\n",
            "Epoch 23/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
            "Epoch 24/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 9.4619e-04 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
            "Epoch 25/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9986 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0045\n",
            "Epoch 26/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9995 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
            "Epoch 27/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9972 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0050\n",
            "Epoch 28/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 29/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
            "Epoch 30/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
            "Epoch 31/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 7.5698e-04 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 32/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 7.5288e-04 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
            "Epoch 33/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 7.1585e-04 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 34/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 9.4773e-04 - val_accuracy: 1.0000 - val_loss: 0.0045\n",
            "Epoch 35/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
            "Epoch 36/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.7172e-04 - val_accuracy: 1.0000 - val_loss: 0.0046\n",
            "Epoch 37/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 0.0043\n",
            "Epoch 38/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 6.5465e-04 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
            "Epoch 39/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
            "Epoch 40/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9994 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
            "Epoch 41/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9972 - loss: 0.0110 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
            "Epoch 42/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9987 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
            "Epoch 43/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0047\n",
            "Epoch 44/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
            "Epoch 45/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9993 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 0.0046\n",
            "Epoch 46/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9957 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0047\n",
            "Epoch 47/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
            "Epoch 48/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9989 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
            "Epoch 49/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0042\n",
            "Epoch 50/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 8.0841e-04 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
            "Epoch 51/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 52/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9964 - val_loss: 0.0061\n",
            "Epoch 53/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.5603e-04 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
            "Epoch 54/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.9249e-04 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
            "Epoch 55/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.1695e-04 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
            "Epoch 56/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.6376e-04 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
            "Epoch 57/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.2606e-04 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
            "Epoch 58/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 3.3397e-04 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
            "Epoch 59/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.6218e-04 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 60/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.1739e-04 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
            "Epoch 61/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.9391e-04 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
            "Epoch 62/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 4.2851e-04 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
            "Epoch 63/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 3.2225e-04 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
            "Epoch 64/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 2.7945e-04 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
            "Epoch 65/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.2078e-04 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
            "Epoch 66/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.1104e-04 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
            "Epoch 67/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.5510e-04 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
            "Epoch 68/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 5.0982e-04 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
            "Epoch 69/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.7534e-04 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
            "Epoch 70/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.6898e-04 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
            "Epoch 71/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.3807e-04 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 72/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.1890e-04 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
            "Epoch 73/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.0377e-04 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
            "Epoch 74/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.1417e-04 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
            "Epoch 75/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 8.9401e-04 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
            "Epoch 76/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 2.5328e-04 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
            "Epoch 77/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.1555e-04 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
            "Epoch 78/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9999 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
            "Epoch 79/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
            "Epoch 80/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9964 - loss: 0.0144 - val_accuracy: 0.9928 - val_loss: 0.0249\n",
            "Epoch 81/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9956 - loss: 0.0206 - val_accuracy: 0.9891 - val_loss: 0.0427\n",
            "Epoch 82/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9627 - loss: 0.1400 - val_accuracy: 0.9565 - val_loss: 0.1902\n",
            "Epoch 83/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9477 - loss: 0.1722 - val_accuracy: 0.9420 - val_loss: 0.1575\n",
            "Epoch 84/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9666 - loss: 0.0731 - val_accuracy: 0.9746 - val_loss: 0.0681\n",
            "Epoch 85/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9932 - loss: 0.0333 - val_accuracy: 0.9783 - val_loss: 0.0486\n",
            "Epoch 86/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9968 - loss: 0.0281 - val_accuracy: 0.9855 - val_loss: 0.0712\n",
            "Epoch 87/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9972 - loss: 0.0088 - val_accuracy: 0.9891 - val_loss: 0.0592\n",
            "Epoch 88/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9974 - loss: 0.0073 - val_accuracy: 0.9855 - val_loss: 0.0628\n",
            "Epoch 89/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9999 - loss: 0.0048 - val_accuracy: 0.9891 - val_loss: 0.0647\n",
            "Epoch 90/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9997 - loss: 0.0028 - val_accuracy: 0.9891 - val_loss: 0.0561\n",
            "Epoch 91/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9992 - loss: 0.0057 - val_accuracy: 0.9819 - val_loss: 0.0707\n",
            "Epoch 92/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9891 - val_loss: 0.0590\n",
            "Epoch 93/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9891 - val_loss: 0.0584\n",
            "Epoch 94/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9891 - val_loss: 0.0568\n",
            "Epoch 95/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9891 - val_loss: 0.0563\n",
            "Epoch 96/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9891 - val_loss: 0.0565\n",
            "Epoch 97/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 8.7845e-04 - val_accuracy: 0.9891 - val_loss: 0.0554\n",
            "Epoch 98/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 6.6342e-04 - val_accuracy: 0.9891 - val_loss: 0.0552\n",
            "Epoch 99/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 7.3137e-04 - val_accuracy: 0.9891 - val_loss: 0.0546\n",
            "Epoch 100/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 6.4701e-04 - val_accuracy: 0.9891 - val_loss: 0.0546\n",
            "Average accuracy across 5 folds: 0.9392690896987915\n",
            "Average loss across 5 folds: 0.24665688052773477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "y_pred = teacher_model.predict([eeg_signals_test, phys_signals_test])\n",
        "\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "# y_true_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "test_accuracy = accuracy_score(y_test, y_pred_labels)\n",
        "\n",
        "# Calculate F1 score (for multi-class, set average='weighted' or 'macro' depending on your preference)\n",
        "test_f1_score = f1_score(y_test, y_pred_labels, average='weighted')\n",
        "\n",
        "# Print the classification report\n",
        "class_report = classification_report(y_test, y_pred_labels)\n",
        "\n",
        "# Output the results\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "print(f\"Test F1 Score: {test_f1_score}\")\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "#teacher model\n",
        "# Test Accuracy: 0.9190751445086706\n",
        "# Test F1 Score: 0.9202961422338729"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPy0WWXAmJRs",
        "outputId": "395389cb-b29c-442f-80c1-e882a56efbef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Test Accuracy: 0.9190751445086706\n",
            "Test F1 Score: 0.9202961422338729\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.88      0.90        16\n",
            "         1.0       0.99      0.91      0.94       151\n",
            "         2.0       0.92      0.93      0.92       105\n",
            "         3.0       0.81      0.93      0.87        74\n",
            "\n",
            "    accuracy                           0.92       346\n",
            "   macro avg       0.91      0.91      0.91       346\n",
            "weighted avg       0.92      0.92      0.92       346\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_model = create_student_model_dnn300()\n",
        "student_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgN8KCr_l-vr",
        "outputId": "a0d7364d-000d-4700-fbf2-d65305dee97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(teacher_model.summary())\n",
        "print(student_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "O7quwPkGohs4",
        "outputId": "8dbaa84c-175b-46f3-a8d1-57f6449cd101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_128\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_128\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_31            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_3 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ input_layer_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_26 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m256\u001b[0m │ reshape_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_27 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m24,704\u001b[0m │ max_pooling1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_32            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_4 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ input_layer_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_12 (\u001b[38;5;33mFlatten\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ max_pooling1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m16,896\u001b[0m │ reshape_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m832\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ flatten_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_97 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m106,624\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_98 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m516\u001b[0m │ dense_97[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_31            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ reshape_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ max_pooling1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_32            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │ reshape_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">106,624</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ dense_97[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m446,990\u001b[0m (1.71 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">446,990</span> (1.71 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m148,996\u001b[0m (582.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">148,996</span> (582.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m297,994\u001b[0m (1.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">297,994</span> (1.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_45\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_45\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_169 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m12,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_170 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_171 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m90,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_172 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │           \u001b[38;5;34m1,204\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_169 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_170 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_171 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_172 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,204</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m582,314\u001b[0m (2.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">582,314</span> (2.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m194,104\u001b[0m (758.22 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">194,104</span> (758.22 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m388,210\u001b[0m (1.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">388,210</span> (1.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_student_model():\n",
        "    model = Sequential()\n",
        "    # Only using 8 physiological signals as input\n",
        "    model.add(Dense(300, input_dim=40, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
        "    # Output layer remains same since we have 4 classes\n",
        "    model.add(Dense(4, kernel_initializer='normal', activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "student_model = create_student_model()\n",
        "student_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7XU8Teup94C",
        "outputId": "976152f4-d319-46bd-885d-a17751350a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "soft_targets = teacher_model.predict([eeg_signals_train, phys_signals_train])\n",
        "\n",
        "# Define 5-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Prepare arrays to store the results for each fold\n",
        "fold_accuracies = []\n",
        "fold_f1_scores = []\n",
        "student_model = create_student_model()\n",
        "student_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#note: sparse_categorical_crossentropy - for y_test, categorical_crossentropy - for soft targets\n",
        "\n",
        "# Perform 5-fold cross-validation for the student model\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(phys_signals_train)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    # Split the physiological data and corresponding labels\n",
        "    phys_train_fold = phys_signals_train[train_idx]\n",
        "    phys_val_fold = phys_signals_train[val_idx]\n",
        "\n",
        "    y_train_fold = y_train[train_idx]\n",
        "    y_train_val = y_train[val_idx]\n",
        "\n",
        "    # Generate soft targets from the teacher model on the training data\n",
        "    # soft_targets_train = teacher_model.predict([eeg_signals_train[train_idx], phys_signals_train[train_idx]])\n",
        "\n",
        "    # # Generate soft targets for the validation data (teacher model predictions)\n",
        "    # soft_targets_val = teacher_model.predict([eeg_signals_train[val_idx], phys_signals_train[val_idx]])\n",
        "\n",
        "    # Train the student model using physiological signals and soft targets\n",
        "    # student_model.fit(phys_train_fold, soft_targets_train, epochs=100, batch_size=20, verbose=1, validation_data=(phys_val_fold, soft_targets_val))\n",
        "    student_model.fit(phys_train_fold, y_train_fold, epochs=100, batch_size=20, verbose=1, validation_data=(phys_val_fold, y_train_val))\n",
        "\n",
        "    # Evaluate the student model on the validation set\n",
        "    y_pred = student_model.predict(phys_val_fold)\n",
        "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    # Calculate accuracy and F1 score for this fold\n",
        "    # accuracy = accuracy_score(np.argmax(soft_targets_val, axis=1), y_pred_labels)\n",
        "    # f1 = f1_score(np.argmax(soft_targets_val, axis=1), y_pred_labels, average='weighted')\n",
        "\n",
        "    accuracy = accuracy_score(y_train_val, y_pred_labels)\n",
        "    f1 = f1_score(y_train_val, y_pred_labels, average='weighted')\n",
        "\n",
        "    fold_accuracies.append(accuracy)\n",
        "    fold_f1_scores.append(f1)\n",
        "\n",
        "    print(f\"Fold {fold + 1} Accuracy: {accuracy}\")\n",
        "    print(f\"Fold {fold + 1} F1 Score: {f1}\")\n",
        "\n",
        "# Calculate and print the average accuracy and F1 score across all folds\n",
        "mean_accuracy = np.mean(fold_accuracies)\n",
        "mean_f1_score = np.mean(fold_f1_scores)\n",
        "\n",
        "print(f\"Average Accuracy across 5 folds: {mean_accuracy}\")\n",
        "print(f\"Average F1 Score across 5 folds: {mean_f1_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGNjjSGWmdPW",
        "outputId": "4e74818c-e775-47f8-e4f0-e99e446796e1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training fold 1...\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.3665 - loss: 124.8094 - val_accuracy: 0.4729 - val_loss: 25.4003\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4392 - loss: 25.1377 - val_accuracy: 0.4332 - val_loss: 18.5386\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5163 - loss: 15.3126 - val_accuracy: 0.4874 - val_loss: 10.6539\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4837 - loss: 9.2923 - val_accuracy: 0.5487 - val_loss: 6.4580\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5297 - loss: 7.3718 - val_accuracy: 0.4910 - val_loss: 4.7044\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5054 - loss: 7.8260 - val_accuracy: 0.5162 - val_loss: 2.9038\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5457 - loss: 2.4813 - val_accuracy: 0.5343 - val_loss: 4.6546\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5399 - loss: 3.8749 - val_accuracy: 0.5054 - val_loss: 4.2954\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5892 - loss: 3.0219 - val_accuracy: 0.5199 - val_loss: 2.0006\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5996 - loss: 1.8427 - val_accuracy: 0.5704 - val_loss: 3.7879\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5658 - loss: 3.7359 - val_accuracy: 0.5993 - val_loss: 2.9953\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5367 - loss: 3.0461 - val_accuracy: 0.5596 - val_loss: 2.9065\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5853 - loss: 2.7063 - val_accuracy: 0.5740 - val_loss: 1.2299\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6251 - loss: 1.1378 - val_accuracy: 0.5812 - val_loss: 1.7962\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6158 - loss: 1.0492 - val_accuracy: 0.5090 - val_loss: 1.1939\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6210 - loss: 0.9459 - val_accuracy: 0.5848 - val_loss: 1.1803\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6294 - loss: 0.8880 - val_accuracy: 0.6101 - val_loss: 1.1390\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6472 - loss: 0.8548 - val_accuracy: 0.5560 - val_loss: 1.1603\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6475 - loss: 0.8381 - val_accuracy: 0.5668 - val_loss: 1.1302\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6565 - loss: 0.7644 - val_accuracy: 0.5740 - val_loss: 1.2194\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6270 - loss: 0.9306 - val_accuracy: 0.5740 - val_loss: 1.1157\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6202 - loss: 0.8342 - val_accuracy: 0.5740 - val_loss: 1.0978\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6262 - loss: 0.8707 - val_accuracy: 0.6282 - val_loss: 1.0945\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6697 - loss: 0.7841 - val_accuracy: 0.5957 - val_loss: 1.2394\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6616 - loss: 0.8004 - val_accuracy: 0.5812 - val_loss: 1.4299\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6443 - loss: 0.8663 - val_accuracy: 0.5921 - val_loss: 1.3292\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6733 - loss: 0.8123 - val_accuracy: 0.5848 - val_loss: 1.1485\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6469 - loss: 0.8504 - val_accuracy: 0.5379 - val_loss: 1.2706\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6480 - loss: 1.0433 - val_accuracy: 0.5776 - val_loss: 2.0381\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6339 - loss: 1.0082 - val_accuracy: 0.5632 - val_loss: 1.2574\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6519 - loss: 0.7997 - val_accuracy: 0.5812 - val_loss: 1.1183\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6134 - loss: 0.8612 - val_accuracy: 0.5596 - val_loss: 1.2214\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6019 - loss: 0.8770 - val_accuracy: 0.5596 - val_loss: 1.2840\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6257 - loss: 0.7909 - val_accuracy: 0.5812 - val_loss: 1.1923\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6368 - loss: 0.8346 - val_accuracy: 0.5632 - val_loss: 1.3640\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6317 - loss: 1.0457 - val_accuracy: 0.5993 - val_loss: 1.2889\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6688 - loss: 0.7512 - val_accuracy: 0.5523 - val_loss: 1.8773\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6541 - loss: 0.9092 - val_accuracy: 0.5560 - val_loss: 1.2106\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6700 - loss: 0.7348 - val_accuracy: 0.5957 - val_loss: 1.7532\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6846 - loss: 0.8446 - val_accuracy: 0.5812 - val_loss: 1.1633\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6644 - loss: 0.8591 - val_accuracy: 0.5848 - val_loss: 1.1352\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6435 - loss: 0.7854 - val_accuracy: 0.5740 - val_loss: 1.0298\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6510 - loss: 0.7926 - val_accuracy: 0.5704 - val_loss: 1.1394\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6555 - loss: 0.7888 - val_accuracy: 0.5957 - val_loss: 1.2746\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6499 - loss: 0.8343 - val_accuracy: 0.5740 - val_loss: 1.2467\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6342 - loss: 0.8604 - val_accuracy: 0.5884 - val_loss: 1.4090\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6303 - loss: 0.9604 - val_accuracy: 0.5632 - val_loss: 1.4808\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6460 - loss: 0.9168 - val_accuracy: 0.5632 - val_loss: 1.0436\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6518 - loss: 0.8233 - val_accuracy: 0.5379 - val_loss: 1.2367\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5963 - loss: 0.8813 - val_accuracy: 0.5776 - val_loss: 0.9422\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6442 - loss: 0.8177 - val_accuracy: 0.5523 - val_loss: 1.0260\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6421 - loss: 0.7830 - val_accuracy: 0.5596 - val_loss: 1.0277\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6291 - loss: 0.7869 - val_accuracy: 0.5487 - val_loss: 1.0655\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6418 - loss: 0.7788 - val_accuracy: 0.5451 - val_loss: 1.0476\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6276 - loss: 0.7812 - val_accuracy: 0.5235 - val_loss: 1.0648\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6206 - loss: 0.8691 - val_accuracy: 0.5487 - val_loss: 1.1081\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6259 - loss: 0.9616 - val_accuracy: 0.5523 - val_loss: 1.1010\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6329 - loss: 0.8547 - val_accuracy: 0.5848 - val_loss: 1.3966\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5893 - loss: 1.1891 - val_accuracy: 0.5704 - val_loss: 1.1771\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6349 - loss: 0.8382 - val_accuracy: 0.5523 - val_loss: 1.0383\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6463 - loss: 0.7935 - val_accuracy: 0.5632 - val_loss: 1.0222\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6370 - loss: 0.8169 - val_accuracy: 0.5523 - val_loss: 1.0489\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6551 - loss: 0.7916 - val_accuracy: 0.5632 - val_loss: 1.0818\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6282 - loss: 0.8197 - val_accuracy: 0.5271 - val_loss: 1.1735\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6114 - loss: 0.8283 - val_accuracy: 0.5271 - val_loss: 1.1439\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6014 - loss: 0.8260 - val_accuracy: 0.5271 - val_loss: 1.2169\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6324 - loss: 0.8040 - val_accuracy: 0.5271 - val_loss: 1.3294\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6094 - loss: 0.8062 - val_accuracy: 0.5307 - val_loss: 1.3400\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5789 - loss: 0.8376 - val_accuracy: 0.5307 - val_loss: 1.2247\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6028 - loss: 0.8546 - val_accuracy: 0.5343 - val_loss: 1.6213\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5815 - loss: 1.0625 - val_accuracy: 0.5307 - val_loss: 1.2600\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6078 - loss: 0.8199 - val_accuracy: 0.5307 - val_loss: 1.0265\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5898 - loss: 0.9835 - val_accuracy: 0.5307 - val_loss: 1.1335\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5961 - loss: 0.9037 - val_accuracy: 0.5451 - val_loss: 1.1794\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6002 - loss: 0.9201 - val_accuracy: 0.5235 - val_loss: 1.1373\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5789 - loss: 0.9222 - val_accuracy: 0.5415 - val_loss: 1.1362\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5912 - loss: 0.8884 - val_accuracy: 0.5379 - val_loss: 1.2227\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5631 - loss: 0.9233 - val_accuracy: 0.5162 - val_loss: 1.1490\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6017 - loss: 0.9104 - val_accuracy: 0.5307 - val_loss: 1.3047\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6099 - loss: 0.8669 - val_accuracy: 0.5379 - val_loss: 1.1687\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5954 - loss: 0.8544 - val_accuracy: 0.5415 - val_loss: 1.3561\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6106 - loss: 0.8283 - val_accuracy: 0.5271 - val_loss: 1.2196\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6119 - loss: 0.8269 - val_accuracy: 0.5451 - val_loss: 1.5263\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5977 - loss: 0.9564 - val_accuracy: 0.5596 - val_loss: 1.1097\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6383 - loss: 0.8614 - val_accuracy: 0.5343 - val_loss: 1.2339\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5817 - loss: 0.8750 - val_accuracy: 0.5199 - val_loss: 1.1681\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5804 - loss: 0.8938 - val_accuracy: 0.4982 - val_loss: 1.1845\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6135 - loss: 0.8947 - val_accuracy: 0.5090 - val_loss: 1.3034\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5468 - loss: 1.0067 - val_accuracy: 0.5090 - val_loss: 1.4959\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5608 - loss: 1.0493 - val_accuracy: 0.5054 - val_loss: 1.4435\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5640 - loss: 1.1124 - val_accuracy: 0.5162 - val_loss: 1.3035\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5785 - loss: 0.9104 - val_accuracy: 0.5271 - val_loss: 1.0520\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5749 - loss: 0.8886 - val_accuracy: 0.5379 - val_loss: 0.9618\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5890 - loss: 0.8668 - val_accuracy: 0.5271 - val_loss: 1.0094\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5750 - loss: 0.9121 - val_accuracy: 0.5307 - val_loss: 1.0238\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6013 - loss: 0.8394 - val_accuracy: 0.5307 - val_loss: 1.1238\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6005 - loss: 0.8637 - val_accuracy: 0.5307 - val_loss: 1.1215\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6048 - loss: 0.8248 - val_accuracy: 0.5271 - val_loss: 1.4063\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5988 - loss: 0.9707 - val_accuracy: 0.5235 - val_loss: 1.1716\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5710 - loss: 0.9028 - val_accuracy: 0.5307 - val_loss: 1.1550\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Fold 1 Accuracy: 0.5306859205776173\n",
            "Fold 1 F1 Score: 0.468756431388255\n",
            "Training fold 2...\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5732 - loss: 0.9211 - val_accuracy: 0.5487 - val_loss: 0.9579\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5815 - loss: 0.9794 - val_accuracy: 0.5668 - val_loss: 0.8977\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5877 - loss: 0.9809 - val_accuracy: 0.5343 - val_loss: 0.9623\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5760 - loss: 1.0424 - val_accuracy: 0.5451 - val_loss: 1.1964\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5765 - loss: 1.0092 - val_accuracy: 0.5379 - val_loss: 0.9544\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5724 - loss: 0.9843 - val_accuracy: 0.5271 - val_loss: 1.0752\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5825 - loss: 0.9965 - val_accuracy: 0.5379 - val_loss: 0.9805\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5826 - loss: 0.9076 - val_accuracy: 0.5451 - val_loss: 0.9580\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5973 - loss: 0.8753 - val_accuracy: 0.5596 - val_loss: 1.4038\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6092 - loss: 0.9554 - val_accuracy: 0.5596 - val_loss: 0.9324\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5903 - loss: 0.9217 - val_accuracy: 0.5560 - val_loss: 0.9341\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5679 - loss: 0.9021 - val_accuracy: 0.5523 - val_loss: 0.9569\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5948 - loss: 0.8929 - val_accuracy: 0.5632 - val_loss: 0.9251\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5893 - loss: 0.8800 - val_accuracy: 0.5451 - val_loss: 1.0124\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5779 - loss: 0.9704 - val_accuracy: 0.5162 - val_loss: 1.0001\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5926 - loss: 0.9349 - val_accuracy: 0.5126 - val_loss: 0.9962\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5797 - loss: 0.9690 - val_accuracy: 0.5307 - val_loss: 0.9809\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5793 - loss: 0.8943 - val_accuracy: 0.5343 - val_loss: 0.9807\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5814 - loss: 0.8830 - val_accuracy: 0.5235 - val_loss: 0.9871\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5532 - loss: 0.9484 - val_accuracy: 0.5271 - val_loss: 0.9809\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6013 - loss: 0.8914 - val_accuracy: 0.5199 - val_loss: 1.0155\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5700 - loss: 0.9273 - val_accuracy: 0.5307 - val_loss: 1.1232\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5815 - loss: 0.9017 - val_accuracy: 0.5126 - val_loss: 1.0189\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5561 - loss: 0.8990 - val_accuracy: 0.4982 - val_loss: 1.0542\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5915 - loss: 0.9864 - val_accuracy: 0.4368 - val_loss: 26.4763\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5399 - loss: 4.1499 - val_accuracy: 0.5054 - val_loss: 1.0548\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5714 - loss: 0.8873 - val_accuracy: 0.5054 - val_loss: 1.0105\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5760 - loss: 0.9220 - val_accuracy: 0.5126 - val_loss: 1.0045\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5679 - loss: 0.9149 - val_accuracy: 0.5235 - val_loss: 1.0026\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5415 - loss: 0.9856 - val_accuracy: 0.5162 - val_loss: 1.0058\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5623 - loss: 0.9172 - val_accuracy: 0.5162 - val_loss: 1.0482\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5853 - loss: 1.0432 - val_accuracy: 0.5235 - val_loss: 1.0871\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5752 - loss: 1.0291 - val_accuracy: 0.5235 - val_loss: 1.0627\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5657 - loss: 0.9629 - val_accuracy: 0.5235 - val_loss: 1.0314\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5586 - loss: 0.9354 - val_accuracy: 0.5307 - val_loss: 1.0347\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5892 - loss: 0.8979 - val_accuracy: 0.5271 - val_loss: 1.0491\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5665 - loss: 0.9098 - val_accuracy: 0.5307 - val_loss: 1.0303\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5754 - loss: 0.9094 - val_accuracy: 0.5271 - val_loss: 1.0242\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5634 - loss: 0.9122 - val_accuracy: 0.5271 - val_loss: 1.0326\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6044 - loss: 0.8722 - val_accuracy: 0.5235 - val_loss: 0.9725\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5801 - loss: 1.0104 - val_accuracy: 0.5126 - val_loss: 1.0692\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5612 - loss: 0.9903 - val_accuracy: 0.5054 - val_loss: 1.0941\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5691 - loss: 0.9297 - val_accuracy: 0.5126 - val_loss: 1.0806\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5301 - loss: 1.0234 - val_accuracy: 0.5162 - val_loss: 1.0527\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5722 - loss: 0.9448 - val_accuracy: 0.5126 - val_loss: 1.1315\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5694 - loss: 0.9299 - val_accuracy: 0.5235 - val_loss: 1.0572\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5515 - loss: 1.2130 - val_accuracy: 0.5126 - val_loss: 1.0577\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5871 - loss: 0.8733 - val_accuracy: 0.5162 - val_loss: 1.0429\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5638 - loss: 0.9138 - val_accuracy: 0.5199 - val_loss: 1.0882\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5444 - loss: 0.9434 - val_accuracy: 0.5090 - val_loss: 1.0365\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5500 - loss: 0.9127 - val_accuracy: 0.5162 - val_loss: 1.0157\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5740 - loss: 0.9030 - val_accuracy: 0.5054 - val_loss: 1.0847\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5839 - loss: 0.8771 - val_accuracy: 0.5126 - val_loss: 1.0616\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5735 - loss: 0.9196 - val_accuracy: 0.5199 - val_loss: 3.6828\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5492 - loss: 1.0598 - val_accuracy: 0.5126 - val_loss: 1.0061\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5958 - loss: 0.8819 - val_accuracy: 0.5199 - val_loss: 1.0157\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5555 - loss: 1.4320 - val_accuracy: 0.5054 - val_loss: 1.1647\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5370 - loss: 1.1580 - val_accuracy: 0.5162 - val_loss: 1.0061\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5771 - loss: 1.2374 - val_accuracy: 0.5235 - val_loss: 0.9928\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5597 - loss: 0.9925 - val_accuracy: 0.5235 - val_loss: 1.0006\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5514 - loss: 0.9388 - val_accuracy: 0.5235 - val_loss: 1.0117\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5720 - loss: 0.9539 - val_accuracy: 0.5126 - val_loss: 1.0671\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5815 - loss: 0.9160 - val_accuracy: 0.5235 - val_loss: 1.0015\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5852 - loss: 0.9054 - val_accuracy: 0.5162 - val_loss: 1.0069\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5578 - loss: 0.8747 - val_accuracy: 0.5235 - val_loss: 0.9996\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5714 - loss: 0.8952 - val_accuracy: 0.5162 - val_loss: 1.0221\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5892 - loss: 0.8835 - val_accuracy: 0.5235 - val_loss: 1.0692\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5726 - loss: 0.9258 - val_accuracy: 0.5090 - val_loss: 1.0364\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5858 - loss: 0.8857 - val_accuracy: 0.5126 - val_loss: 1.0320\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5639 - loss: 0.9102 - val_accuracy: 0.5090 - val_loss: 1.0364\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6062 - loss: 0.8668 - val_accuracy: 0.5162 - val_loss: 1.0345\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5815 - loss: 0.8915 - val_accuracy: 0.5126 - val_loss: 1.0392\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5634 - loss: 0.9211 - val_accuracy: 0.5162 - val_loss: 1.0410\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5639 - loss: 0.9149 - val_accuracy: 0.5162 - val_loss: 1.0429\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5944 - loss: 0.9053 - val_accuracy: 0.5162 - val_loss: 1.0336\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5725 - loss: 0.9216 - val_accuracy: 0.5162 - val_loss: 1.0651\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5919 - loss: 0.8999 - val_accuracy: 0.5126 - val_loss: 1.0491\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5915 - loss: 0.8872 - val_accuracy: 0.5126 - val_loss: 1.0540\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5608 - loss: 0.8999 - val_accuracy: 0.5126 - val_loss: 1.0562\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5755 - loss: 0.9009 - val_accuracy: 0.5126 - val_loss: 1.0560\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5928 - loss: 0.8719 - val_accuracy: 0.5162 - val_loss: 1.0652\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5772 - loss: 0.8779 - val_accuracy: 0.5162 - val_loss: 1.0633\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5878 - loss: 0.8766 - val_accuracy: 0.5126 - val_loss: 1.0618\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5837 - loss: 0.9278 - val_accuracy: 0.5054 - val_loss: 1.1649\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5799 - loss: 0.9311 - val_accuracy: 0.5018 - val_loss: 1.2090\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5555 - loss: 1.0779 - val_accuracy: 0.5126 - val_loss: 1.1948\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5625 - loss: 1.1026 - val_accuracy: 0.5162 - val_loss: 1.0633\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5549 - loss: 0.9311 - val_accuracy: 0.5126 - val_loss: 1.0830\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5666 - loss: 0.9493 - val_accuracy: 0.5126 - val_loss: 1.0783\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5320 - loss: 1.0299 - val_accuracy: 0.5018 - val_loss: 1.0711\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5492 - loss: 1.0483 - val_accuracy: 0.5126 - val_loss: 1.0437\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5556 - loss: 1.0736 - val_accuracy: 0.5162 - val_loss: 1.2514\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5831 - loss: 0.9720 - val_accuracy: 0.5126 - val_loss: 1.0792\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5930 - loss: 0.8838 - val_accuracy: 0.5162 - val_loss: 1.0784\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5821 - loss: 0.9108 - val_accuracy: 0.5199 - val_loss: 1.0604\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5747 - loss: 0.9379 - val_accuracy: 0.5235 - val_loss: 1.0571\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5850 - loss: 0.8893 - val_accuracy: 0.5235 - val_loss: 1.0586\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5637 - loss: 0.9410 - val_accuracy: 0.5235 - val_loss: 1.0600\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5808 - loss: 0.9042 - val_accuracy: 0.5199 - val_loss: 1.0635\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5738 - loss: 0.9475 - val_accuracy: 0.5126 - val_loss: 1.0771\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Fold 2 Accuracy: 0.5126353790613718\n",
            "Fold 2 F1 Score: 0.4376369483477535\n",
            "Training fold 3...\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5674 - loss: 0.9680 - val_accuracy: 0.5833 - val_loss: 0.9093\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5595 - loss: 0.9913 - val_accuracy: 0.5543 - val_loss: 1.0586\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5516 - loss: 0.9931 - val_accuracy: 0.5725 - val_loss: 0.8999\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5647 - loss: 0.9224 - val_accuracy: 0.5761 - val_loss: 0.8991\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5794 - loss: 0.9343 - val_accuracy: 0.5761 - val_loss: 0.8962\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5764 - loss: 0.9025 - val_accuracy: 0.5761 - val_loss: 0.8957\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5897 - loss: 0.9043 - val_accuracy: 0.5797 - val_loss: 0.8943\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5680 - loss: 0.9379 - val_accuracy: 0.5761 - val_loss: 0.8992\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5640 - loss: 0.9560 - val_accuracy: 0.5797 - val_loss: 0.8916\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5758 - loss: 0.9304 - val_accuracy: 0.5797 - val_loss: 0.8868\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5855 - loss: 0.9009 - val_accuracy: 0.5797 - val_loss: 0.8811\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5736 - loss: 0.9290 - val_accuracy: 0.5797 - val_loss: 0.8782\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5833 - loss: 0.9147 - val_accuracy: 0.5725 - val_loss: 0.8900\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5699 - loss: 0.9927 - val_accuracy: 0.5688 - val_loss: 0.9042\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5791 - loss: 0.9247 - val_accuracy: 0.5652 - val_loss: 0.9085\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5658 - loss: 0.9407 - val_accuracy: 0.5688 - val_loss: 0.9131\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5600 - loss: 0.9450 - val_accuracy: 0.5580 - val_loss: 0.9130\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5443 - loss: 0.9470 - val_accuracy: 0.5254 - val_loss: 6.9227\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5360 - loss: 1.8744 - val_accuracy: 0.5435 - val_loss: 1.0539\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5381 - loss: 1.0143 - val_accuracy: 0.5362 - val_loss: 1.0716\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5608 - loss: 0.9473 - val_accuracy: 0.5471 - val_loss: 1.0155\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5269 - loss: 1.0639 - val_accuracy: 0.5580 - val_loss: 0.9386\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5562 - loss: 0.9562 - val_accuracy: 0.5616 - val_loss: 0.9349\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5912 - loss: 0.9264 - val_accuracy: 0.5652 - val_loss: 0.9278\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5777 - loss: 0.9136 - val_accuracy: 0.5616 - val_loss: 0.9307\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5747 - loss: 0.9137 - val_accuracy: 0.5652 - val_loss: 0.9294\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5800 - loss: 0.9085 - val_accuracy: 0.5580 - val_loss: 0.9276\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5523 - loss: 0.9262 - val_accuracy: 0.5616 - val_loss: 0.9298\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5732 - loss: 0.9034 - val_accuracy: 0.5580 - val_loss: 0.9303\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5614 - loss: 0.9142 - val_accuracy: 0.5580 - val_loss: 0.9312\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5632 - loss: 1.0391 - val_accuracy: 0.5471 - val_loss: 0.9882\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5707 - loss: 0.9500 - val_accuracy: 0.5507 - val_loss: 0.9677\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5773 - loss: 0.9152 - val_accuracy: 0.5507 - val_loss: 0.9581\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5808 - loss: 0.8910 - val_accuracy: 0.5507 - val_loss: 0.9753\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5692 - loss: 0.9194 - val_accuracy: 0.5616 - val_loss: 0.9349\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5482 - loss: 0.9521 - val_accuracy: 0.5616 - val_loss: 0.9535\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5706 - loss: 0.9334 - val_accuracy: 0.5616 - val_loss: 0.9618\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5608 - loss: 0.9146 - val_accuracy: 0.5580 - val_loss: 0.9692\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5790 - loss: 0.9082 - val_accuracy: 0.5580 - val_loss: 0.9702\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5612 - loss: 0.9399 - val_accuracy: 0.5471 - val_loss: 0.9977\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5359 - loss: 1.1766 - val_accuracy: 0.5435 - val_loss: 1.0186\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5557 - loss: 0.9755 - val_accuracy: 0.5543 - val_loss: 1.1686\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5442 - loss: 1.0682 - val_accuracy: 0.5507 - val_loss: 0.9682\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5553 - loss: 0.9596 - val_accuracy: 0.5543 - val_loss: 0.9495\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5578 - loss: 0.9494 - val_accuracy: 0.5507 - val_loss: 0.9748\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5724 - loss: 0.9453 - val_accuracy: 0.5580 - val_loss: 0.9469\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5852 - loss: 0.9163 - val_accuracy: 0.5580 - val_loss: 0.9515\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5369 - loss: 0.9445 - val_accuracy: 0.5543 - val_loss: 0.9665\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5618 - loss: 0.9071 - val_accuracy: 0.5543 - val_loss: 0.9678\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5583 - loss: 0.9406 - val_accuracy: 0.5543 - val_loss: 0.9700\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5601 - loss: 0.9552 - val_accuracy: 0.5543 - val_loss: 0.9702\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5617 - loss: 0.9428 - val_accuracy: 0.5580 - val_loss: 0.9689\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5605 - loss: 0.9195 - val_accuracy: 0.5543 - val_loss: 0.9799\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5875 - loss: 0.9017 - val_accuracy: 0.5543 - val_loss: 0.9755\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5516 - loss: 0.9443 - val_accuracy: 0.5543 - val_loss: 0.9716\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5411 - loss: 0.9793 - val_accuracy: 0.5543 - val_loss: 0.9804\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5479 - loss: 0.9332 - val_accuracy: 0.5543 - val_loss: 0.9826\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5752 - loss: 0.9077 - val_accuracy: 0.5543 - val_loss: 0.9838\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5549 - loss: 0.9299 - val_accuracy: 0.5543 - val_loss: 0.9848\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5610 - loss: 0.9229 - val_accuracy: 0.5543 - val_loss: 0.9829\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5710 - loss: 0.8974 - val_accuracy: 0.5543 - val_loss: 0.9928\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5509 - loss: 0.9120 - val_accuracy: 0.5543 - val_loss: 0.9844\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5665 - loss: 0.9717 - val_accuracy: 0.5543 - val_loss: 1.0044\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5644 - loss: 0.9514 - val_accuracy: 0.5616 - val_loss: 0.9559\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5672 - loss: 0.9190 - val_accuracy: 0.5616 - val_loss: 0.9588\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5668 - loss: 0.9000 - val_accuracy: 0.5616 - val_loss: 0.9583\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5639 - loss: 0.9323 - val_accuracy: 0.5616 - val_loss: 0.9576\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5980 - loss: 0.8788 - val_accuracy: 0.5616 - val_loss: 0.9631\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5838 - loss: 0.9238 - val_accuracy: 0.5616 - val_loss: 0.9648\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5652 - loss: 0.9071 - val_accuracy: 0.5616 - val_loss: 0.9647\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5594 - loss: 0.9167 - val_accuracy: 0.5580 - val_loss: 0.9649\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5630 - loss: 0.9213 - val_accuracy: 0.5616 - val_loss: 0.9660\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5363 - loss: 0.9582 - val_accuracy: 0.5580 - val_loss: 0.9681\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5440 - loss: 0.9322 - val_accuracy: 0.5580 - val_loss: 0.9669\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5797 - loss: 0.9002 - val_accuracy: 0.5580 - val_loss: 0.9680\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5813 - loss: 0.8937 - val_accuracy: 0.5580 - val_loss: 0.9675\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5564 - loss: 0.9253 - val_accuracy: 0.5580 - val_loss: 0.9668\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5537 - loss: 0.9419 - val_accuracy: 0.5580 - val_loss: 0.9663\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5723 - loss: 0.9099 - val_accuracy: 0.5580 - val_loss: 0.9687\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5510 - loss: 0.9391 - val_accuracy: 0.5580 - val_loss: 0.9686\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5775 - loss: 0.9133 - val_accuracy: 0.5580 - val_loss: 0.9684\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5567 - loss: 0.9085 - val_accuracy: 0.5580 - val_loss: 0.9546\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5858 - loss: 0.9325 - val_accuracy: 0.5362 - val_loss: 1.0763\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5564 - loss: 0.9634 - val_accuracy: 0.5507 - val_loss: 1.5832\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5339 - loss: 1.4312 - val_accuracy: 0.5326 - val_loss: 1.7309\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5174 - loss: 1.1969 - val_accuracy: 0.5145 - val_loss: 1.1510\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5398 - loss: 1.1129 - val_accuracy: 0.5543 - val_loss: 0.9747\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5376 - loss: 0.9910 - val_accuracy: 0.5326 - val_loss: 1.0139\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5367 - loss: 1.0093 - val_accuracy: 0.5399 - val_loss: 1.4153\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5278 - loss: 1.2387 - val_accuracy: 0.5326 - val_loss: 1.0574\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5282 - loss: 1.0059 - val_accuracy: 0.5507 - val_loss: 0.9875\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5503 - loss: 0.9264 - val_accuracy: 0.5507 - val_loss: 0.9719\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5437 - loss: 0.9645 - val_accuracy: 0.5507 - val_loss: 0.9696\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5642 - loss: 1.0323 - val_accuracy: 0.5435 - val_loss: 1.0795\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5549 - loss: 0.9657 - val_accuracy: 0.5507 - val_loss: 0.9853\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5464 - loss: 0.9484 - val_accuracy: 0.5435 - val_loss: 0.9882\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5899 - loss: 0.8968 - val_accuracy: 0.5399 - val_loss: 1.0176\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5559 - loss: 0.9112 - val_accuracy: 0.5435 - val_loss: 1.0263\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5354 - loss: 0.9477 - val_accuracy: 0.5435 - val_loss: 1.0359\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5605 - loss: 0.9511 - val_accuracy: 0.5435 - val_loss: 1.0424\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Fold 3 Accuracy: 0.5434782608695652\n",
            "Fold 3 F1 Score: 0.4779038594255986\n",
            "Training fold 4...\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5546 - loss: 1.0069 - val_accuracy: 0.5870 - val_loss: 0.9391\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5216 - loss: 1.0484 - val_accuracy: 0.5652 - val_loss: 1.1796\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5380 - loss: 1.0825 - val_accuracy: 0.5725 - val_loss: 0.9925\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5300 - loss: 0.9928 - val_accuracy: 0.5833 - val_loss: 0.9490\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5460 - loss: 0.9233 - val_accuracy: 0.5906 - val_loss: 0.9552\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5568 - loss: 0.9768 - val_accuracy: 0.5688 - val_loss: 0.9827\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5489 - loss: 0.9690 - val_accuracy: 0.5833 - val_loss: 0.9569\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5653 - loss: 0.9279 - val_accuracy: 0.5870 - val_loss: 0.9577\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5386 - loss: 0.9457 - val_accuracy: 0.5870 - val_loss: 0.9554\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5283 - loss: 0.9592 - val_accuracy: 0.5870 - val_loss: 0.9676\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5571 - loss: 0.9146 - val_accuracy: 0.5870 - val_loss: 0.9684\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5393 - loss: 0.9479 - val_accuracy: 0.5870 - val_loss: 0.9697\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5624 - loss: 0.8924 - val_accuracy: 0.5870 - val_loss: 0.9752\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5563 - loss: 0.9230 - val_accuracy: 0.5833 - val_loss: 0.9769\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5527 - loss: 0.9254 - val_accuracy: 0.5870 - val_loss: 0.9681\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5707 - loss: 0.8896 - val_accuracy: 0.5870 - val_loss: 0.9590\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5370 - loss: 0.9510 - val_accuracy: 0.5833 - val_loss: 0.9805\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5452 - loss: 0.9435 - val_accuracy: 0.5870 - val_loss: 0.9724\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5593 - loss: 0.9280 - val_accuracy: 0.5833 - val_loss: 0.9900\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5605 - loss: 0.8986 - val_accuracy: 0.5797 - val_loss: 0.9898\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5661 - loss: 0.9040 - val_accuracy: 0.5833 - val_loss: 0.9841\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5548 - loss: 0.8842 - val_accuracy: 0.5797 - val_loss: 1.0187\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5403 - loss: 0.9372 - val_accuracy: 0.5761 - val_loss: 1.0341\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5564 - loss: 0.9169 - val_accuracy: 0.5797 - val_loss: 0.9842\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5821 - loss: 0.8738 - val_accuracy: 0.5797 - val_loss: 0.9724\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5845 - loss: 0.8710 - val_accuracy: 0.5833 - val_loss: 0.9736\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5254 - loss: 0.9545 - val_accuracy: 0.5761 - val_loss: 0.9822\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5511 - loss: 0.9087 - val_accuracy: 0.5761 - val_loss: 0.9772\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5747 - loss: 0.9351 - val_accuracy: 0.5725 - val_loss: 1.0062\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5384 - loss: 0.9826 - val_accuracy: 0.5797 - val_loss: 0.9906\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5308 - loss: 0.9990 - val_accuracy: 0.5725 - val_loss: 1.0693\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5354 - loss: 1.0656 - val_accuracy: 0.5543 - val_loss: 1.0720\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5494 - loss: 0.9289 - val_accuracy: 0.5797 - val_loss: 1.0253\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5416 - loss: 0.9539 - val_accuracy: 0.5906 - val_loss: 0.9588\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5733 - loss: 0.9255 - val_accuracy: 0.5725 - val_loss: 0.9784\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5610 - loss: 0.9275 - val_accuracy: 0.5797 - val_loss: 0.9653\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5583 - loss: 0.9370 - val_accuracy: 0.5761 - val_loss: 0.9855\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5461 - loss: 0.9396 - val_accuracy: 0.5725 - val_loss: 1.0003\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5441 - loss: 0.9195 - val_accuracy: 0.5652 - val_loss: 1.0101\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5290 - loss: 0.9284 - val_accuracy: 0.5688 - val_loss: 1.0182\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5542 - loss: 0.9145 - val_accuracy: 0.5652 - val_loss: 1.0264\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5544 - loss: 0.9100 - val_accuracy: 0.5652 - val_loss: 1.0254\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5397 - loss: 0.9566 - val_accuracy: 0.5652 - val_loss: 1.0396\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5656 - loss: 0.8953 - val_accuracy: 0.5652 - val_loss: 1.0417\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5391 - loss: 0.9142 - val_accuracy: 0.5652 - val_loss: 1.0355\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5457 - loss: 0.9143 - val_accuracy: 0.5652 - val_loss: 1.0438\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5784 - loss: 0.8972 - val_accuracy: 0.5652 - val_loss: 1.0463\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5655 - loss: 0.9095 - val_accuracy: 0.5652 - val_loss: 1.0470\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5556 - loss: 0.9078 - val_accuracy: 0.5652 - val_loss: 1.0564\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5546 - loss: 0.9185 - val_accuracy: 0.5688 - val_loss: 1.0628\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5445 - loss: 0.9575 - val_accuracy: 0.5652 - val_loss: 1.0180\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5409 - loss: 0.9373 - val_accuracy: 0.5761 - val_loss: 0.9846\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5571 - loss: 0.9129 - val_accuracy: 0.5725 - val_loss: 0.9994\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5301 - loss: 0.9452 - val_accuracy: 0.5761 - val_loss: 0.9813\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5428 - loss: 0.9377 - val_accuracy: 0.5761 - val_loss: 0.9900\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5275 - loss: 0.9376 - val_accuracy: 0.5688 - val_loss: 1.0014\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5658 - loss: 0.9037 - val_accuracy: 0.5688 - val_loss: 1.0226\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5430 - loss: 0.9196 - val_accuracy: 0.5725 - val_loss: 1.0421\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5554 - loss: 0.9345 - val_accuracy: 0.5725 - val_loss: 1.0513\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5445 - loss: 0.9322 - val_accuracy: 0.5688 - val_loss: 1.0750\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5755 - loss: 0.9164 - val_accuracy: 0.5688 - val_loss: 1.0809\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5559 - loss: 0.9392 - val_accuracy: 0.5652 - val_loss: 1.0954\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5275 - loss: 0.9363 - val_accuracy: 0.5616 - val_loss: 1.0968\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5687 - loss: 0.9271 - val_accuracy: 0.5652 - val_loss: 1.1099\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5670 - loss: 0.8924 - val_accuracy: 0.5652 - val_loss: 1.1145\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5523 - loss: 0.9028 - val_accuracy: 0.5652 - val_loss: 1.1178\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5625 - loss: 0.8836 - val_accuracy: 0.5688 - val_loss: 1.0386\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5682 - loss: 0.9093 - val_accuracy: 0.5652 - val_loss: 1.0797\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5802 - loss: 0.8855 - val_accuracy: 0.5688 - val_loss: 1.0524\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5425 - loss: 1.0310 - val_accuracy: 0.5580 - val_loss: 1.0138\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5222 - loss: 0.9928 - val_accuracy: 0.5435 - val_loss: 1.6041\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5256 - loss: 1.2453 - val_accuracy: 0.5543 - val_loss: 1.1964\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5439 - loss: 1.1234 - val_accuracy: 0.5399 - val_loss: 1.3243\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5220 - loss: 0.9714 - val_accuracy: 0.5507 - val_loss: 1.1298\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5666 - loss: 1.0255 - val_accuracy: 0.5471 - val_loss: 1.2564\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5428 - loss: 1.0040 - val_accuracy: 0.5652 - val_loss: 5.0859\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5616 - loss: 1.0075 - val_accuracy: 0.5616 - val_loss: 1.1020\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5670 - loss: 0.9082 - val_accuracy: 0.5580 - val_loss: 1.1521\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5587 - loss: 0.9148 - val_accuracy: 0.5507 - val_loss: 1.1058\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5565 - loss: 0.9960 - val_accuracy: 0.5652 - val_loss: 1.2497\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5487 - loss: 0.9766 - val_accuracy: 0.5580 - val_loss: 1.0724\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5514 - loss: 0.9258 - val_accuracy: 0.5616 - val_loss: 1.0914\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5659 - loss: 0.9255 - val_accuracy: 0.5616 - val_loss: 1.0925\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5979 - loss: 0.8933 - val_accuracy: 0.5652 - val_loss: 1.1129\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5526 - loss: 0.9430 - val_accuracy: 0.5580 - val_loss: 1.1219\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5844 - loss: 0.9668 - val_accuracy: 0.5616 - val_loss: 1.1212\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5634 - loss: 0.9094 - val_accuracy: 0.5616 - val_loss: 1.1623\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5335 - loss: 0.9452 - val_accuracy: 0.5616 - val_loss: 1.0356\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5485 - loss: 0.9474 - val_accuracy: 0.5543 - val_loss: 1.0590\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5695 - loss: 0.8926 - val_accuracy: 0.5543 - val_loss: 1.0554\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5814 - loss: 0.8971 - val_accuracy: 0.5543 - val_loss: 1.0567\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5750 - loss: 0.9213 - val_accuracy: 0.5652 - val_loss: 1.0663\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5694 - loss: 0.9133 - val_accuracy: 0.5652 - val_loss: 1.0831\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5757 - loss: 0.9033 - val_accuracy: 0.5652 - val_loss: 1.0618\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5513 - loss: 0.9397 - val_accuracy: 0.5616 - val_loss: 1.1250\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5523 - loss: 0.9592 - val_accuracy: 0.5399 - val_loss: 1.1718\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5760 - loss: 0.9476 - val_accuracy: 0.5471 - val_loss: 1.1544\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5314 - loss: 0.9685 - val_accuracy: 0.5688 - val_loss: 1.1310\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5441 - loss: 1.1181 - val_accuracy: 0.5543 - val_loss: 1.8817\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5211 - loss: 1.0691 - val_accuracy: 0.5616 - val_loss: 1.0697\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Fold 4 Accuracy: 0.5615942028985508\n",
            "Fold 4 F1 Score: 0.48890541198688187\n",
            "Training fold 5...\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5404 - loss: 1.0084 - val_accuracy: 0.5435 - val_loss: 0.9724\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5528 - loss: 0.9517 - val_accuracy: 0.5507 - val_loss: 0.9438\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5514 - loss: 0.9518 - val_accuracy: 0.5435 - val_loss: 0.9555\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5421 - loss: 0.9565 - val_accuracy: 0.5362 - val_loss: 1.6293\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5699 - loss: 2.0132 - val_accuracy: 0.5290 - val_loss: 0.9662\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5793 - loss: 0.9236 - val_accuracy: 0.5399 - val_loss: 0.9682\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5641 - loss: 0.9329 - val_accuracy: 0.5435 - val_loss: 0.9741\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5693 - loss: 0.9472 - val_accuracy: 0.5399 - val_loss: 1.1925\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5505 - loss: 1.0169 - val_accuracy: 0.5399 - val_loss: 0.9813\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5593 - loss: 1.0095 - val_accuracy: 0.5254 - val_loss: 1.0349\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5698 - loss: 0.9522 - val_accuracy: 0.5362 - val_loss: 0.9846\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5555 - loss: 0.9674 - val_accuracy: 0.5399 - val_loss: 0.9762\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5309 - loss: 0.9775 - val_accuracy: 0.5326 - val_loss: 0.9985\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5416 - loss: 0.9947 - val_accuracy: 0.5399 - val_loss: 0.9728\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5716 - loss: 0.9392 - val_accuracy: 0.5399 - val_loss: 0.9656\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5441 - loss: 0.9755 - val_accuracy: 0.5471 - val_loss: 1.0014\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5672 - loss: 0.9236 - val_accuracy: 0.5435 - val_loss: 0.9856\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5684 - loss: 0.9516 - val_accuracy: 0.5435 - val_loss: 0.9850\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5733 - loss: 0.9238 - val_accuracy: 0.5399 - val_loss: 0.9896\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5602 - loss: 0.9363 - val_accuracy: 0.5362 - val_loss: 1.0334\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5610 - loss: 0.9483 - val_accuracy: 0.5217 - val_loss: 1.0772\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5299 - loss: 1.0264 - val_accuracy: 0.5290 - val_loss: 1.0378\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5756 - loss: 0.9264 - val_accuracy: 0.5217 - val_loss: 1.0368\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5598 - loss: 0.9477 - val_accuracy: 0.5290 - val_loss: 1.0301\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5506 - loss: 0.9676 - val_accuracy: 0.5326 - val_loss: 1.0382\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5716 - loss: 0.9226 - val_accuracy: 0.5326 - val_loss: 1.0437\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5745 - loss: 0.9293 - val_accuracy: 0.5326 - val_loss: 1.0476\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5422 - loss: 1.0180 - val_accuracy: 0.5326 - val_loss: 1.0036\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5597 - loss: 0.9581 - val_accuracy: 0.5399 - val_loss: 0.9954\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5627 - loss: 0.9375 - val_accuracy: 0.5362 - val_loss: 0.9978\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5691 - loss: 0.9279 - val_accuracy: 0.5362 - val_loss: 0.9937\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5447 - loss: 0.9638 - val_accuracy: 0.5362 - val_loss: 1.0008\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5466 - loss: 0.9599 - val_accuracy: 0.5326 - val_loss: 1.0034\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5643 - loss: 0.9125 - val_accuracy: 0.5362 - val_loss: 1.0073\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5363 - loss: 0.9603 - val_accuracy: 0.5399 - val_loss: 1.0094\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5588 - loss: 0.9311 - val_accuracy: 0.5362 - val_loss: 1.0141\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5288 - loss: 0.9634 - val_accuracy: 0.5362 - val_loss: 1.0162\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5784 - loss: 0.9143 - val_accuracy: 0.5399 - val_loss: 1.0142\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6191 - loss: 0.8770 - val_accuracy: 0.5399 - val_loss: 1.0144\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5419 - loss: 0.9633 - val_accuracy: 0.5435 - val_loss: 1.0153\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5810 - loss: 0.9284 - val_accuracy: 0.5435 - val_loss: 1.0158\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5821 - loss: 0.9292 - val_accuracy: 0.5399 - val_loss: 1.0167\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5368 - loss: 0.9453 - val_accuracy: 0.5399 - val_loss: 1.0199\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5556 - loss: 0.9436 - val_accuracy: 0.5326 - val_loss: 1.0466\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5591 - loss: 0.9532 - val_accuracy: 0.5471 - val_loss: 1.0225\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5700 - loss: 0.9258 - val_accuracy: 0.5435 - val_loss: 1.0207\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5636 - loss: 0.9173 - val_accuracy: 0.5399 - val_loss: 1.0247\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5695 - loss: 0.9390 - val_accuracy: 0.5471 - val_loss: 1.0209\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5508 - loss: 0.9383 - val_accuracy: 0.5435 - val_loss: 1.0245\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5543 - loss: 0.9557 - val_accuracy: 0.5435 - val_loss: 1.0475\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5635 - loss: 0.9349 - val_accuracy: 0.5399 - val_loss: 1.0281\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5720 - loss: 0.9203 - val_accuracy: 0.5399 - val_loss: 1.0251\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5482 - loss: 0.9531 - val_accuracy: 0.5471 - val_loss: 1.0294\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5625 - loss: 0.9517 - val_accuracy: 0.5507 - val_loss: 1.0494\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5736 - loss: 0.9519 - val_accuracy: 0.5435 - val_loss: 1.0539\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5462 - loss: 0.9530 - val_accuracy: 0.5543 - val_loss: 1.1240\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5709 - loss: 0.9707 - val_accuracy: 0.5507 - val_loss: 1.0184\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5542 - loss: 0.9769 - val_accuracy: 0.5181 - val_loss: 1.0865\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5111 - loss: 1.2017 - val_accuracy: 0.5145 - val_loss: 1.2416\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5383 - loss: 1.1641 - val_accuracy: 0.5145 - val_loss: 1.1427\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5459 - loss: 0.9791 - val_accuracy: 0.5217 - val_loss: 1.1369\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5577 - loss: 0.9201 - val_accuracy: 0.5326 - val_loss: 1.0939\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5761 - loss: 0.9476 - val_accuracy: 0.5471 - val_loss: 1.2908\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5510 - loss: 1.0724 - val_accuracy: 0.5362 - val_loss: 1.0368\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5331 - loss: 0.9629 - val_accuracy: 0.5507 - val_loss: 1.0154\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5351 - loss: 0.9407 - val_accuracy: 0.5471 - val_loss: 0.9933\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5650 - loss: 0.9405 - val_accuracy: 0.5471 - val_loss: 0.9928\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5714 - loss: 0.9144 - val_accuracy: 0.5471 - val_loss: 0.9930\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5678 - loss: 0.9210 - val_accuracy: 0.5471 - val_loss: 0.9932\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5449 - loss: 0.9451 - val_accuracy: 0.5435 - val_loss: 0.9968\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5456 - loss: 0.9615 - val_accuracy: 0.5435 - val_loss: 0.9990\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5711 - loss: 0.9105 - val_accuracy: 0.5471 - val_loss: 1.0001\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5486 - loss: 0.9522 - val_accuracy: 0.5471 - val_loss: 1.0013\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5913 - loss: 0.9096 - val_accuracy: 0.5399 - val_loss: 1.0059\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5673 - loss: 0.9326 - val_accuracy: 0.5435 - val_loss: 1.0002\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5696 - loss: 0.9311 - val_accuracy: 0.5399 - val_loss: 1.0040\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5386 - loss: 0.9392 - val_accuracy: 0.5471 - val_loss: 1.0038\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5643 - loss: 1.5658 - val_accuracy: 0.5109 - val_loss: 1.1293\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5514 - loss: 0.9283 - val_accuracy: 0.5145 - val_loss: 1.0958\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5563 - loss: 0.9932 - val_accuracy: 0.5254 - val_loss: 1.0840\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5581 - loss: 0.9343 - val_accuracy: 0.5435 - val_loss: 1.0177\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5677 - loss: 0.9202 - val_accuracy: 0.5181 - val_loss: 1.6136\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5464 - loss: 0.9559 - val_accuracy: 0.5326 - val_loss: 1.1789\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5376 - loss: 2.3956 - val_accuracy: 0.5217 - val_loss: 1.0713\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5586 - loss: 0.9359 - val_accuracy: 0.5254 - val_loss: 1.1282\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5276 - loss: 0.9893 - val_accuracy: 0.5145 - val_loss: 1.3252\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5767 - loss: 0.9148 - val_accuracy: 0.5181 - val_loss: 1.2440\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5272 - loss: 0.9762 - val_accuracy: 0.5254 - val_loss: 1.2847\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5290 - loss: 0.9774 - val_accuracy: 0.5254 - val_loss: 1.1729\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5572 - loss: 0.9687 - val_accuracy: 0.5254 - val_loss: 1.1533\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5553 - loss: 0.9571 - val_accuracy: 0.5254 - val_loss: 1.1599\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5544 - loss: 0.9272 - val_accuracy: 0.5217 - val_loss: 1.1630\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5569 - loss: 0.9441 - val_accuracy: 0.5217 - val_loss: 1.1763\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5762 - loss: 0.9196 - val_accuracy: 0.5290 - val_loss: 1.1721\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5394 - loss: 0.9712 - val_accuracy: 0.5181 - val_loss: 1.1841\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5710 - loss: 0.9331 - val_accuracy: 0.5181 - val_loss: 1.1759\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5651 - loss: 0.9379 - val_accuracy: 0.5181 - val_loss: 1.1913\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5606 - loss: 0.9435 - val_accuracy: 0.5181 - val_loss: 1.2001\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5440 - loss: 0.9366 - val_accuracy: 0.5217 - val_loss: 1.2054\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5442 - loss: 0.9415 - val_accuracy: 0.5181 - val_loss: 1.1736\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Fold 5 Accuracy: 0.5181159420289855\n",
            "Fold 5 F1 Score: 0.473759947384799\n",
            "Average Accuracy across 5 folds: 0.5333019410872181\n",
            "Average F1 Score across 5 folds: 0.4693925197066576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Create the student model\n",
        "student_model = create_student_model()\n",
        "student_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# Define 5-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# Assuming teacher model is trained and ready\n",
        "soft_targets_train = teacher_model.predict([eeg_signals_train, phys_signals_train])\n",
        "\n",
        "# Prepare arrays to store results\n",
        "fold_accuracies = []\n",
        "fold_f1_scores = []\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    # Split the data into training and validation sets for this fold\n",
        "    X_train_fold = X_train[train_idx]  # Update for 40 channels\n",
        "    X_val_fold = X_train[val_idx]  # Update for 40 channels\n",
        "    y_train_fold = y_train[train_idx]\n",
        "    y_train_val = y_train[val_idx]\n",
        "\n",
        "    student_model.fit(X_train_fold, y_train_fold, epochs=100, batch_size=20, verbose=1, validation_data=(X_val_fold, y_train_val))\n",
        "\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    y_pred = student_model.predict(X_val_fold)\n",
        "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    # # Calculate accuracy and F1 score\n",
        "    accuracy = accuracy_score(y_train_val, y_pred_labels)\n",
        "    f1 = f1_score(y_train_val, y_pred_labels, average='weighted')\n",
        "\n",
        "    fold_accuracies.append(accuracy)\n",
        "    fold_f1_scores.append(f1)\n",
        "\n",
        "# Calculate and print the average accuracy and F1 score across all folds\n",
        "mean_accuracy = np.mean(fold_accuracies)\n",
        "mean_f1_score = np.mean(fold_f1_scores)\n",
        "\n",
        "print(f\"Average accuracy across 5 folds: {mean_accuracy}\")\n",
        "print(f\"Average F1 score across 5 folds: {mean_f1_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVIR8yHn0Da8",
        "outputId": "cc7e1b0c-2d96-48ac-d12b-8c6fdcad8a97",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
            "Training fold 1...\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.3674 - loss: 94.0300 - val_accuracy: 0.4440 - val_loss: 41.8559\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4599 - loss: 30.7545 - val_accuracy: 0.4838 - val_loss: 24.5189\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4710 - loss: 11.5646 - val_accuracy: 0.5199 - val_loss: 7.6514\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5103 - loss: 7.3179 - val_accuracy: 0.5343 - val_loss: 6.4900\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5285 - loss: 7.0227 - val_accuracy: 0.5451 - val_loss: 7.9021\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5483 - loss: 6.2341 - val_accuracy: 0.5162 - val_loss: 4.2731\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5296 - loss: 3.5650 - val_accuracy: 0.4946 - val_loss: 4.6530\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5213 - loss: 4.7228 - val_accuracy: 0.5162 - val_loss: 4.4831\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5123 - loss: 3.3934 - val_accuracy: 0.5415 - val_loss: 2.9845\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5781 - loss: 2.4133 - val_accuracy: 0.5523 - val_loss: 2.7237\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5896 - loss: 1.4883 - val_accuracy: 0.6101 - val_loss: 1.5438\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6234 - loss: 0.9847 - val_accuracy: 0.5957 - val_loss: 1.5355\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6405 - loss: 0.8935 - val_accuracy: 0.5487 - val_loss: 1.9831\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6347 - loss: 0.9619 - val_accuracy: 0.5307 - val_loss: 1.7374\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5833 - loss: 1.0118 - val_accuracy: 0.5776 - val_loss: 1.6419\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6388 - loss: 0.8324 - val_accuracy: 0.5884 - val_loss: 1.7458\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6655 - loss: 0.9085 - val_accuracy: 0.5812 - val_loss: 1.6517\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6621 - loss: 0.8382 - val_accuracy: 0.5993 - val_loss: 1.6285\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6794 - loss: 0.7984 - val_accuracy: 0.5415 - val_loss: 2.4377\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6091 - loss: 1.8371 - val_accuracy: 0.5523 - val_loss: 1.6533\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6077 - loss: 1.0113 - val_accuracy: 0.5596 - val_loss: 1.6750\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6407 - loss: 1.7382 - val_accuracy: 0.5776 - val_loss: 2.3116\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5905 - loss: 5.0689 - val_accuracy: 0.5199 - val_loss: 2.0611\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5995 - loss: 1.5328 - val_accuracy: 0.5812 - val_loss: 1.8028\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6301 - loss: 0.9149 - val_accuracy: 0.5668 - val_loss: 1.9474\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6091 - loss: 0.9931 - val_accuracy: 0.5415 - val_loss: 1.4372\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6235 - loss: 0.8347 - val_accuracy: 0.5487 - val_loss: 1.2708\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6387 - loss: 0.8348 - val_accuracy: 0.5596 - val_loss: 1.3815\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5937 - loss: 0.8594 - val_accuracy: 0.5596 - val_loss: 1.4904\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6287 - loss: 0.8206 - val_accuracy: 0.5668 - val_loss: 1.3500\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6326 - loss: 0.7933 - val_accuracy: 0.5704 - val_loss: 1.3668\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6068 - loss: 0.8648 - val_accuracy: 0.5704 - val_loss: 1.2564\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6442 - loss: 0.8306 - val_accuracy: 0.5415 - val_loss: 1.4152\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6097 - loss: 0.8834 - val_accuracy: 0.5199 - val_loss: 1.5789\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6153 - loss: 0.9710 - val_accuracy: 0.5162 - val_loss: 1.8652\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5869 - loss: 0.8685 - val_accuracy: 0.5271 - val_loss: 1.4414\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5868 - loss: 0.8605 - val_accuracy: 0.5162 - val_loss: 1.4525\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5784 - loss: 0.8506 - val_accuracy: 0.5126 - val_loss: 1.5067\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5972 - loss: 0.8345 - val_accuracy: 0.5162 - val_loss: 1.5279\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6035 - loss: 0.8781 - val_accuracy: 0.5271 - val_loss: 1.2536\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6054 - loss: 0.8401 - val_accuracy: 0.5199 - val_loss: 1.2771\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5989 - loss: 0.8622 - val_accuracy: 0.5235 - val_loss: 1.6635\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5988 - loss: 0.8860 - val_accuracy: 0.5307 - val_loss: 1.3732\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6173 - loss: 0.8324 - val_accuracy: 0.5126 - val_loss: 1.5952\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6196 - loss: 0.9600 - val_accuracy: 0.5199 - val_loss: 1.7241\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5627 - loss: 0.9345 - val_accuracy: 0.4729 - val_loss: 1.3154\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5630 - loss: 1.0075 - val_accuracy: 0.4765 - val_loss: 1.3310\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5606 - loss: 0.9659 - val_accuracy: 0.5090 - val_loss: 1.2482\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5897 - loss: 0.9229 - val_accuracy: 0.5271 - val_loss: 1.2476\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5980 - loss: 0.8890 - val_accuracy: 0.5379 - val_loss: 1.1891\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5973 - loss: 0.8747 - val_accuracy: 0.5235 - val_loss: 1.1627\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5823 - loss: 0.8694 - val_accuracy: 0.5018 - val_loss: 1.1083\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5988 - loss: 0.8521 - val_accuracy: 0.5307 - val_loss: 1.1974\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6112 - loss: 0.8394 - val_accuracy: 0.5271 - val_loss: 1.4003\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6158 - loss: 0.8305 - val_accuracy: 0.5162 - val_loss: 1.1914\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5821 - loss: 0.8554 - val_accuracy: 0.5343 - val_loss: 1.2554\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6056 - loss: 0.8749 - val_accuracy: 0.5271 - val_loss: 1.0996\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6196 - loss: 0.8066 - val_accuracy: 0.5307 - val_loss: 1.3298\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6040 - loss: 0.8589 - val_accuracy: 0.5199 - val_loss: 1.1575\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6109 - loss: 0.8184 - val_accuracy: 0.5054 - val_loss: 1.6029\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5891 - loss: 0.8900 - val_accuracy: 0.5090 - val_loss: 1.6692\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5871 - loss: 1.0276 - val_accuracy: 0.5199 - val_loss: 1.4305\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5812 - loss: 0.8730 - val_accuracy: 0.5271 - val_loss: 1.2602\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5712 - loss: 0.8750 - val_accuracy: 0.5271 - val_loss: 1.2160\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5620 - loss: 0.8959 - val_accuracy: 0.5054 - val_loss: 1.1930\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5838 - loss: 2.1929 - val_accuracy: 0.5054 - val_loss: 2.3808\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5704 - loss: 0.9324 - val_accuracy: 0.5018 - val_loss: 1.7750\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5910 - loss: 0.9280 - val_accuracy: 0.5199 - val_loss: 1.4564\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6140 - loss: 0.8686 - val_accuracy: 0.5199 - val_loss: 1.7613\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5716 - loss: 0.8894 - val_accuracy: 0.5090 - val_loss: 1.3364\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5914 - loss: 0.8687 - val_accuracy: 0.5199 - val_loss: 1.2756\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5949 - loss: 0.8933 - val_accuracy: 0.5090 - val_loss: 1.2579\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5667 - loss: 0.9061 - val_accuracy: 0.5199 - val_loss: 1.2615\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6224 - loss: 0.8716 - val_accuracy: 0.5271 - val_loss: 1.2475\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5591 - loss: 0.9251 - val_accuracy: 0.5199 - val_loss: 1.5610\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5904 - loss: 0.9100 - val_accuracy: 0.5126 - val_loss: 1.4585\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5947 - loss: 0.8663 - val_accuracy: 0.5199 - val_loss: 1.3022\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5860 - loss: 0.8712 - val_accuracy: 0.5199 - val_loss: 1.3003\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5689 - loss: 0.9036 - val_accuracy: 0.5235 - val_loss: 1.3530\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5994 - loss: 0.8603 - val_accuracy: 0.5199 - val_loss: 1.3735\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5886 - loss: 0.8779 - val_accuracy: 0.5090 - val_loss: 1.5643\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5735 - loss: 0.9207 - val_accuracy: 0.5126 - val_loss: 1.5487\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5824 - loss: 0.8593 - val_accuracy: 0.5199 - val_loss: 1.5765\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5749 - loss: 0.8625 - val_accuracy: 0.5235 - val_loss: 1.5571\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5991 - loss: 0.8706 - val_accuracy: 0.5162 - val_loss: 1.5137\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5674 - loss: 0.9223 - val_accuracy: 0.5054 - val_loss: 1.6649\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5464 - loss: 0.9694 - val_accuracy: 0.5199 - val_loss: 2.1610\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5433 - loss: 1.0185 - val_accuracy: 0.5090 - val_loss: 1.1837\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5688 - loss: 0.9338 - val_accuracy: 0.5307 - val_loss: 1.1731\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5644 - loss: 1.5319 - val_accuracy: 0.5199 - val_loss: 1.1846\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5706 - loss: 0.9070 - val_accuracy: 0.5162 - val_loss: 1.3759\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5797 - loss: 0.9070 - val_accuracy: 0.5199 - val_loss: 1.4387\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5921 - loss: 0.8541 - val_accuracy: 0.5126 - val_loss: 1.4754\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5947 - loss: 0.8620 - val_accuracy: 0.5199 - val_loss: 1.6166\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5929 - loss: 0.8974 - val_accuracy: 0.5162 - val_loss: 1.4755\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5671 - loss: 0.8874 - val_accuracy: 0.5126 - val_loss: 1.4253\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5930 - loss: 0.8625 - val_accuracy: 0.5162 - val_loss: 1.6649\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5973 - loss: 0.8657 - val_accuracy: 0.5126 - val_loss: 1.3007\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6082 - loss: 0.8577 - val_accuracy: 0.5162 - val_loss: 1.2222\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5801 - loss: 0.8777 - val_accuracy: 0.5126 - val_loss: 1.2365\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Training fold 2...\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5843 - loss: 0.9369 - val_accuracy: 0.5307 - val_loss: 0.9717\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5693 - loss: 1.1069 - val_accuracy: 0.5415 - val_loss: 0.9801\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5853 - loss: 0.9067 - val_accuracy: 0.5487 - val_loss: 0.9420\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5317 - loss: 0.9729 - val_accuracy: 0.5343 - val_loss: 0.9718\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6005 - loss: 0.8881 - val_accuracy: 0.5487 - val_loss: 0.9331\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5680 - loss: 0.8699 - val_accuracy: 0.5487 - val_loss: 0.9204\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5608 - loss: 0.9129 - val_accuracy: 0.5379 - val_loss: 0.9468\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5880 - loss: 0.8760 - val_accuracy: 0.5343 - val_loss: 0.9578\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5638 - loss: 0.8840 - val_accuracy: 0.5379 - val_loss: 0.9501\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5874 - loss: 1.0669 - val_accuracy: 0.5415 - val_loss: 0.9520\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5814 - loss: 0.9400 - val_accuracy: 0.5307 - val_loss: 0.9612\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5808 - loss: 0.9775 - val_accuracy: 0.5235 - val_loss: 1.0948\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5797 - loss: 1.0657 - val_accuracy: 0.5235 - val_loss: 0.9768\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5611 - loss: 0.9344 - val_accuracy: 0.5343 - val_loss: 0.9723\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5641 - loss: 0.9249 - val_accuracy: 0.5343 - val_loss: 0.9664\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5595 - loss: 0.9267 - val_accuracy: 0.5235 - val_loss: 0.9741\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5428 - loss: 0.9357 - val_accuracy: 0.5343 - val_loss: 0.9710\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5634 - loss: 0.8888 - val_accuracy: 0.5271 - val_loss: 0.9696\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6008 - loss: 0.8510 - val_accuracy: 0.5235 - val_loss: 0.9836\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5393 - loss: 0.9327 - val_accuracy: 0.5271 - val_loss: 0.9700\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6026 - loss: 0.8748 - val_accuracy: 0.5307 - val_loss: 0.9549\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5782 - loss: 0.9283 - val_accuracy: 0.5235 - val_loss: 0.9790\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5869 - loss: 0.9176 - val_accuracy: 0.5343 - val_loss: 0.9662\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5689 - loss: 0.9428 - val_accuracy: 0.5379 - val_loss: 2.5763\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5871 - loss: 0.9178 - val_accuracy: 0.5307 - val_loss: 1.5392\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5611 - loss: 0.9532 - val_accuracy: 0.5343 - val_loss: 0.9730\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5672 - loss: 0.9008 - val_accuracy: 0.5415 - val_loss: 0.9445\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5544 - loss: 1.0535 - val_accuracy: 0.5162 - val_loss: 1.0453\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5535 - loss: 0.9755 - val_accuracy: 0.5235 - val_loss: 1.0079\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5550 - loss: 1.0019 - val_accuracy: 0.5271 - val_loss: 0.9848\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5679 - loss: 0.9401 - val_accuracy: 0.5379 - val_loss: 0.9722\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5793 - loss: 0.8955 - val_accuracy: 0.5379 - val_loss: 0.9961\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5569 - loss: 0.9022 - val_accuracy: 0.5343 - val_loss: 0.9751\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5920 - loss: 0.8897 - val_accuracy: 0.5343 - val_loss: 0.9757\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5510 - loss: 0.9499 - val_accuracy: 0.5343 - val_loss: 0.9776\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5877 - loss: 0.8945 - val_accuracy: 0.5379 - val_loss: 0.9756\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5693 - loss: 0.8942 - val_accuracy: 0.5379 - val_loss: 0.9772\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5771 - loss: 0.8986 - val_accuracy: 0.5379 - val_loss: 0.9843\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5852 - loss: 0.8947 - val_accuracy: 0.5199 - val_loss: 1.0412\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5402 - loss: 0.9516 - val_accuracy: 0.5271 - val_loss: 1.1659\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5512 - loss: 1.6060 - val_accuracy: 0.5235 - val_loss: 1.0272\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5846 - loss: 0.9041 - val_accuracy: 0.5307 - val_loss: 1.0056\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5689 - loss: 0.8912 - val_accuracy: 0.5343 - val_loss: 0.9914\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5901 - loss: 0.8775 - val_accuracy: 0.5162 - val_loss: 1.0084\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5604 - loss: 0.9124 - val_accuracy: 0.5199 - val_loss: 1.0218\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5531 - loss: 0.9281 - val_accuracy: 0.5235 - val_loss: 1.0197\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5742 - loss: 0.9115 - val_accuracy: 0.5235 - val_loss: 1.0195\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5774 - loss: 0.9159 - val_accuracy: 0.5271 - val_loss: 1.0051\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5870 - loss: 0.8658 - val_accuracy: 0.5271 - val_loss: 1.0050\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5919 - loss: 0.8742 - val_accuracy: 0.5271 - val_loss: 1.0019\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5985 - loss: 0.8683 - val_accuracy: 0.5271 - val_loss: 1.0012\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5936 - loss: 0.8820 - val_accuracy: 0.5271 - val_loss: 1.0013\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5802 - loss: 0.8781 - val_accuracy: 0.5271 - val_loss: 1.0187\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5722 - loss: 0.9117 - val_accuracy: 0.5162 - val_loss: 1.0303\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5821 - loss: 0.9206 - val_accuracy: 0.5018 - val_loss: 1.1131\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5380 - loss: 1.1665 - val_accuracy: 0.4874 - val_loss: 1.2231\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5421 - loss: 1.0914 - val_accuracy: 0.4874 - val_loss: 1.1137\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5612 - loss: 0.9382 - val_accuracy: 0.5090 - val_loss: 1.0691\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5385 - loss: 0.9541 - val_accuracy: 0.5090 - val_loss: 1.0413\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5830 - loss: 0.9421 - val_accuracy: 0.5090 - val_loss: 1.0443\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5453 - loss: 0.9347 - val_accuracy: 0.5162 - val_loss: 1.0189\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5533 - loss: 0.9478 - val_accuracy: 0.5162 - val_loss: 1.0211\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6024 - loss: 0.8892 - val_accuracy: 0.5235 - val_loss: 1.0066\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5982 - loss: 0.8847 - val_accuracy: 0.5235 - val_loss: 1.0232\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5646 - loss: 0.9189 - val_accuracy: 0.5162 - val_loss: 1.0263\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5927 - loss: 0.9055 - val_accuracy: 0.5235 - val_loss: 0.9938\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5581 - loss: 0.8964 - val_accuracy: 0.5235 - val_loss: 0.9964\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5642 - loss: 0.9241 - val_accuracy: 0.5126 - val_loss: 0.9890\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5556 - loss: 1.1884 - val_accuracy: 0.5126 - val_loss: 1.0442\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5643 - loss: 0.9475 - val_accuracy: 0.5162 - val_loss: 1.0857\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5610 - loss: 1.0347 - val_accuracy: 0.5126 - val_loss: 1.1137\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5422 - loss: 1.0793 - val_accuracy: 0.5307 - val_loss: 1.0519\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5431 - loss: 1.0320 - val_accuracy: 0.5235 - val_loss: 1.0523\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5642 - loss: 0.9334 - val_accuracy: 0.5235 - val_loss: 1.0760\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5695 - loss: 0.9219 - val_accuracy: 0.5199 - val_loss: 1.1130\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5818 - loss: 0.9063 - val_accuracy: 0.5235 - val_loss: 1.0590\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5842 - loss: 0.9062 - val_accuracy: 0.5126 - val_loss: 1.0496\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5641 - loss: 0.9398 - val_accuracy: 0.5126 - val_loss: 1.0608\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5786 - loss: 0.9086 - val_accuracy: 0.5126 - val_loss: 1.0335\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5587 - loss: 0.9225 - val_accuracy: 0.5162 - val_loss: 1.0306\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5663 - loss: 0.8960 - val_accuracy: 0.5199 - val_loss: 1.0253\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5969 - loss: 0.9039 - val_accuracy: 0.5199 - val_loss: 1.0241\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5864 - loss: 0.9206 - val_accuracy: 0.5199 - val_loss: 1.0217\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5545 - loss: 0.9247 - val_accuracy: 0.5199 - val_loss: 1.0199\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5737 - loss: 0.8810 - val_accuracy: 0.5162 - val_loss: 1.0198\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5797 - loss: 0.8967 - val_accuracy: 0.5199 - val_loss: 1.0166\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5511 - loss: 0.9243 - val_accuracy: 0.5199 - val_loss: 1.0134\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5713 - loss: 0.9077 - val_accuracy: 0.5235 - val_loss: 1.0142\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5716 - loss: 0.9301 - val_accuracy: 0.5235 - val_loss: 1.0144\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5718 - loss: 0.9059 - val_accuracy: 0.5235 - val_loss: 1.0145\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5792 - loss: 0.8912 - val_accuracy: 0.5271 - val_loss: 1.0348\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5793 - loss: 0.9269 - val_accuracy: 0.5199 - val_loss: 1.1594\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5702 - loss: 1.0928 - val_accuracy: 0.5126 - val_loss: 1.2955\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5667 - loss: 1.0613 - val_accuracy: 0.5235 - val_loss: 1.0208\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5527 - loss: 0.9137 - val_accuracy: 0.5199 - val_loss: 1.0369\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5896 - loss: 0.8682 - val_accuracy: 0.5162 - val_loss: 1.0620\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5471 - loss: 0.9596 - val_accuracy: 0.5271 - val_loss: 1.0248\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5781 - loss: 0.9447 - val_accuracy: 0.5271 - val_loss: 1.2701\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5754 - loss: 0.9820 - val_accuracy: 0.5271 - val_loss: 1.0758\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5987 - loss: 0.9410 - val_accuracy: 0.5126 - val_loss: 1.0906\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Training fold 3...\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5507 - loss: 0.9625 - val_accuracy: 0.5507 - val_loss: 1.0213\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5439 - loss: 0.9888 - val_accuracy: 0.5652 - val_loss: 0.9571\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5569 - loss: 0.9209 - val_accuracy: 0.5688 - val_loss: 2.4045\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5584 - loss: 1.1395 - val_accuracy: 0.5652 - val_loss: 1.1012\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5481 - loss: 0.9924 - val_accuracy: 0.5580 - val_loss: 0.9483\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5171 - loss: 1.0570 - val_accuracy: 0.5725 - val_loss: 0.9155\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5714 - loss: 0.9380 - val_accuracy: 0.5761 - val_loss: 0.9017\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5656 - loss: 0.9457 - val_accuracy: 0.5761 - val_loss: 0.9033\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5455 - loss: 0.9415 - val_accuracy: 0.5725 - val_loss: 0.9204\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5749 - loss: 0.9108 - val_accuracy: 0.5688 - val_loss: 0.9007\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5791 - loss: 0.9186 - val_accuracy: 0.5725 - val_loss: 0.9053\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5727 - loss: 0.9130 - val_accuracy: 0.5688 - val_loss: 0.9114\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5622 - loss: 0.9323 - val_accuracy: 0.5725 - val_loss: 0.9064\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5498 - loss: 0.9448 - val_accuracy: 0.5725 - val_loss: 0.9107\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5652 - loss: 0.9688 - val_accuracy: 0.5725 - val_loss: 0.9056\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5622 - loss: 0.9257 - val_accuracy: 0.5616 - val_loss: 0.9098\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5896 - loss: 0.8717 - val_accuracy: 0.5616 - val_loss: 0.9106\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5662 - loss: 0.9063 - val_accuracy: 0.5688 - val_loss: 0.9092\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5794 - loss: 0.8954 - val_accuracy: 0.5688 - val_loss: 0.9128\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5710 - loss: 0.9033 - val_accuracy: 0.5688 - val_loss: 0.9173\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5745 - loss: 0.9035 - val_accuracy: 0.5688 - val_loss: 0.9163\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5720 - loss: 0.9235 - val_accuracy: 0.5688 - val_loss: 0.9204\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5575 - loss: 0.9346 - val_accuracy: 0.5688 - val_loss: 0.9203\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5535 - loss: 0.9173 - val_accuracy: 0.5688 - val_loss: 0.9224\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5476 - loss: 0.9367 - val_accuracy: 0.5688 - val_loss: 0.9271\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5655 - loss: 0.9260 - val_accuracy: 0.5688 - val_loss: 10.6073\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5248 - loss: 2.3394 - val_accuracy: 0.5072 - val_loss: 2.1254\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5306 - loss: 1.4522 - val_accuracy: 0.5399 - val_loss: 1.0739\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5483 - loss: 1.0184 - val_accuracy: 0.5507 - val_loss: 0.9977\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5464 - loss: 0.9755 - val_accuracy: 0.5580 - val_loss: 0.9683\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5565 - loss: 0.9604 - val_accuracy: 0.5580 - val_loss: 1.0279\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5737 - loss: 0.9193 - val_accuracy: 0.5543 - val_loss: 1.0213\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5802 - loss: 0.9350 - val_accuracy: 0.5580 - val_loss: 1.0091\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5713 - loss: 0.9250 - val_accuracy: 0.5580 - val_loss: 1.0223\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5706 - loss: 0.9142 - val_accuracy: 0.5580 - val_loss: 1.0287\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5660 - loss: 0.9271 - val_accuracy: 0.5543 - val_loss: 1.0387\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5712 - loss: 0.9043 - val_accuracy: 0.5543 - val_loss: 1.0440\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5496 - loss: 1.2165 - val_accuracy: 0.5435 - val_loss: 1.0228\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5426 - loss: 1.1092 - val_accuracy: 0.5362 - val_loss: 1.2821\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5299 - loss: 1.1978 - val_accuracy: 0.5471 - val_loss: 1.0090\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5327 - loss: 1.0157 - val_accuracy: 0.5471 - val_loss: 1.0213\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5329 - loss: 1.0610 - val_accuracy: 0.5399 - val_loss: 0.9703\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5603 - loss: 0.9359 - val_accuracy: 0.5471 - val_loss: 1.0178\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5587 - loss: 0.9672 - val_accuracy: 0.5399 - val_loss: 0.9718\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5399 - loss: 0.9280 - val_accuracy: 0.5471 - val_loss: 1.0043\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5421 - loss: 1.0365 - val_accuracy: 0.5507 - val_loss: 0.9593\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5707 - loss: 0.9013 - val_accuracy: 0.5543 - val_loss: 0.9366\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5422 - loss: 1.1535 - val_accuracy: 0.5616 - val_loss: 0.9551\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5583 - loss: 0.9591 - val_accuracy: 0.5399 - val_loss: 1.0145\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5326 - loss: 1.0418 - val_accuracy: 0.5290 - val_loss: 1.1217\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5293 - loss: 0.9858 - val_accuracy: 0.5435 - val_loss: 1.0001\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5474 - loss: 0.9494 - val_accuracy: 0.5435 - val_loss: 0.9765\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5490 - loss: 0.9436 - val_accuracy: 0.5471 - val_loss: 0.9701\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5368 - loss: 0.9590 - val_accuracy: 0.5471 - val_loss: 0.9778\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5560 - loss: 1.0042 - val_accuracy: 0.5362 - val_loss: 0.9962\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5656 - loss: 0.9174 - val_accuracy: 0.5507 - val_loss: 0.9944\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5662 - loss: 0.9412 - val_accuracy: 0.5362 - val_loss: 1.0000\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5502 - loss: 0.9478 - val_accuracy: 0.5399 - val_loss: 0.9902\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5736 - loss: 0.8896 - val_accuracy: 0.5507 - val_loss: 0.9851\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5514 - loss: 0.9336 - val_accuracy: 0.5507 - val_loss: 0.9828\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5561 - loss: 0.9246 - val_accuracy: 0.5471 - val_loss: 0.9792\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5775 - loss: 0.8934 - val_accuracy: 0.5507 - val_loss: 0.9764\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5656 - loss: 0.9014 - val_accuracy: 0.5471 - val_loss: 0.9763\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5842 - loss: 0.8935 - val_accuracy: 0.5471 - val_loss: 0.9767\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5618 - loss: 0.9008 - val_accuracy: 0.5471 - val_loss: 0.9771\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5496 - loss: 0.9192 - val_accuracy: 0.5471 - val_loss: 0.9765\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5529 - loss: 0.9397 - val_accuracy: 0.5471 - val_loss: 0.9823\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5695 - loss: 0.9129 - val_accuracy: 0.5471 - val_loss: 0.9847\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5886 - loss: 0.8922 - val_accuracy: 0.5471 - val_loss: 0.9847\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5618 - loss: 0.9097 - val_accuracy: 0.5471 - val_loss: 0.9996\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5653 - loss: 0.9271 - val_accuracy: 0.5471 - val_loss: 1.0106\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5657 - loss: 0.9022 - val_accuracy: 0.5471 - val_loss: 1.0073\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5845 - loss: 0.9024 - val_accuracy: 0.5471 - val_loss: 1.0071\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5570 - loss: 0.9059 - val_accuracy: 0.5471 - val_loss: 1.0230\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5499 - loss: 0.9139 - val_accuracy: 0.5471 - val_loss: 1.0238\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5694 - loss: 0.8961 - val_accuracy: 0.5471 - val_loss: 1.0261\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5543 - loss: 0.9142 - val_accuracy: 0.5471 - val_loss: 1.0249\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5646 - loss: 0.8979 - val_accuracy: 0.5471 - val_loss: 1.0225\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5484 - loss: 0.9308 - val_accuracy: 0.5471 - val_loss: 1.0241\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5718 - loss: 0.8940 - val_accuracy: 0.5471 - val_loss: 1.0297\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5517 - loss: 0.9097 - val_accuracy: 0.5471 - val_loss: 1.0327\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5632 - loss: 0.8982 - val_accuracy: 0.5471 - val_loss: 1.0309\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5794 - loss: 0.8822 - val_accuracy: 0.5471 - val_loss: 1.0374\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5450 - loss: 0.9470 - val_accuracy: 0.5471 - val_loss: 1.0396\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5530 - loss: 0.9202 - val_accuracy: 0.5471 - val_loss: 1.0378\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5612 - loss: 0.9189 - val_accuracy: 0.5471 - val_loss: 1.0419\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5756 - loss: 0.9218 - val_accuracy: 0.5471 - val_loss: 1.0436\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5656 - loss: 0.9103 - val_accuracy: 0.5471 - val_loss: 1.0444\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5456 - loss: 0.9148 - val_accuracy: 0.5471 - val_loss: 1.0502\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5741 - loss: 0.8777 - val_accuracy: 0.5471 - val_loss: 1.0496\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5512 - loss: 0.9162 - val_accuracy: 0.5471 - val_loss: 1.0521\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5827 - loss: 0.8873 - val_accuracy: 0.5471 - val_loss: 1.0568\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5398 - loss: 0.9531 - val_accuracy: 0.5471 - val_loss: 1.0540\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5781 - loss: 0.8912 - val_accuracy: 0.5471 - val_loss: 1.0556\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5550 - loss: 0.9310 - val_accuracy: 0.5471 - val_loss: 1.0570\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5633 - loss: 0.9038 - val_accuracy: 0.5471 - val_loss: 1.0602\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5755 - loss: 0.9089 - val_accuracy: 0.5471 - val_loss: 1.0612\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5557 - loss: 0.9221 - val_accuracy: 0.5471 - val_loss: 1.0648\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5410 - loss: 1.0809 - val_accuracy: 0.5326 - val_loss: 1.0775\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5445 - loss: 1.0877 - val_accuracy: 0.5326 - val_loss: 1.0944\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Training fold 4...\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5380 - loss: 1.5933 - val_accuracy: 0.5688 - val_loss: 1.0704\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5305 - loss: 1.2738 - val_accuracy: 0.5616 - val_loss: 1.0733\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5224 - loss: 1.0084 - val_accuracy: 0.5833 - val_loss: 0.9947\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5824 - loss: 0.9280 - val_accuracy: 0.5797 - val_loss: 0.9934\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5272 - loss: 1.0486 - val_accuracy: 0.5797 - val_loss: 1.0507\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5607 - loss: 1.0544 - val_accuracy: 0.5761 - val_loss: 1.1848\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5531 - loss: 0.9723 - val_accuracy: 0.5725 - val_loss: 1.0541\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5485 - loss: 1.1725 - val_accuracy: 0.5870 - val_loss: 0.9846\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5408 - loss: 1.2845 - val_accuracy: 0.5761 - val_loss: 1.0488\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5389 - loss: 1.2290 - val_accuracy: 0.5797 - val_loss: 1.0012\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5681 - loss: 1.4233 - val_accuracy: 0.5761 - val_loss: 1.0087\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5515 - loss: 0.9975 - val_accuracy: 0.5797 - val_loss: 0.9979\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5337 - loss: 1.0042 - val_accuracy: 0.5725 - val_loss: 1.0615\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5485 - loss: 1.0523 - val_accuracy: 0.5725 - val_loss: 1.0042\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5278 - loss: 1.0185 - val_accuracy: 0.5833 - val_loss: 1.0014\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5440 - loss: 0.9968 - val_accuracy: 0.5797 - val_loss: 1.0069\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5213 - loss: 0.9983 - val_accuracy: 0.5761 - val_loss: 1.0139\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5303 - loss: 1.0127 - val_accuracy: 0.5761 - val_loss: 1.0168\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5448 - loss: 0.9607 - val_accuracy: 0.5761 - val_loss: 1.0137\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5539 - loss: 0.9652 - val_accuracy: 0.5761 - val_loss: 1.0206\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5597 - loss: 0.9629 - val_accuracy: 0.5725 - val_loss: 1.0292\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5249 - loss: 0.9750 - val_accuracy: 0.5725 - val_loss: 1.0298\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5392 - loss: 0.9560 - val_accuracy: 0.5725 - val_loss: 1.0466\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5371 - loss: 0.9883 - val_accuracy: 0.5688 - val_loss: 1.0141\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5586 - loss: 0.9728 - val_accuracy: 0.5725 - val_loss: 1.0209\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5393 - loss: 0.9618 - val_accuracy: 0.5725 - val_loss: 1.0221\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5480 - loss: 0.9734 - val_accuracy: 0.5688 - val_loss: 1.0368\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5349 - loss: 0.9493 - val_accuracy: 0.5761 - val_loss: 1.0156\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5497 - loss: 0.9792 - val_accuracy: 0.5761 - val_loss: 1.0129\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5609 - loss: 0.9488 - val_accuracy: 0.5761 - val_loss: 1.0117\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5492 - loss: 0.9700 - val_accuracy: 0.5761 - val_loss: 1.0154\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5474 - loss: 0.9598 - val_accuracy: 0.5761 - val_loss: 1.0140\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5629 - loss: 0.9450 - val_accuracy: 0.5761 - val_loss: 1.0147\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5372 - loss: 0.9734 - val_accuracy: 0.5761 - val_loss: 1.0156\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5715 - loss: 0.9316 - val_accuracy: 0.5725 - val_loss: 1.0166\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5390 - loss: 0.9763 - val_accuracy: 0.5725 - val_loss: 1.0177\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5674 - loss: 0.9510 - val_accuracy: 0.5725 - val_loss: 1.0171\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5754 - loss: 0.9476 - val_accuracy: 0.5761 - val_loss: 1.0133\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5438 - loss: 0.9593 - val_accuracy: 0.5725 - val_loss: 1.0450\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5449 - loss: 0.9486 - val_accuracy: 0.5725 - val_loss: 1.0103\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5457 - loss: 0.9499 - val_accuracy: 0.5761 - val_loss: 0.9915\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5315 - loss: 0.9531 - val_accuracy: 0.5725 - val_loss: 0.9972\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5275 - loss: 0.9449 - val_accuracy: 0.5725 - val_loss: 1.0474\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5200 - loss: 0.9956 - val_accuracy: 0.5725 - val_loss: 1.0310\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5461 - loss: 0.9594 - val_accuracy: 0.5797 - val_loss: 1.0380\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5406 - loss: 1.0095 - val_accuracy: 0.5906 - val_loss: 0.9694\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5462 - loss: 0.9550 - val_accuracy: 0.5833 - val_loss: 0.9726\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5470 - loss: 0.9631 - val_accuracy: 0.5870 - val_loss: 0.9684\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5341 - loss: 0.9570 - val_accuracy: 0.5870 - val_loss: 0.9631\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5490 - loss: 0.9471 - val_accuracy: 0.5906 - val_loss: 0.9621\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5208 - loss: 1.0098 - val_accuracy: 0.5797 - val_loss: 0.9923\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5538 - loss: 0.9518 - val_accuracy: 0.5870 - val_loss: 1.0074\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5362 - loss: 0.9533 - val_accuracy: 0.5870 - val_loss: 0.9949\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5735 - loss: 0.9264 - val_accuracy: 0.5942 - val_loss: 0.9511\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5407 - loss: 1.0136 - val_accuracy: 0.5978 - val_loss: 0.9304\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5404 - loss: 0.9778 - val_accuracy: 0.5870 - val_loss: 0.9496\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5404 - loss: 0.9377 - val_accuracy: 0.5833 - val_loss: 0.9549\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5592 - loss: 0.9480 - val_accuracy: 0.5833 - val_loss: 0.9570\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5434 - loss: 0.9333 - val_accuracy: 0.5906 - val_loss: 0.9665\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5486 - loss: 0.9419 - val_accuracy: 0.5870 - val_loss: 0.9622\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5737 - loss: 0.9337 - val_accuracy: 0.5942 - val_loss: 0.9455\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5526 - loss: 0.9554 - val_accuracy: 0.5978 - val_loss: 0.9479\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5629 - loss: 0.9221 - val_accuracy: 0.5942 - val_loss: 0.9448\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5656 - loss: 0.9216 - val_accuracy: 0.5942 - val_loss: 0.9443\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5480 - loss: 0.9173 - val_accuracy: 0.5942 - val_loss: 0.9455\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5531 - loss: 0.9363 - val_accuracy: 0.5978 - val_loss: 0.9424\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5765 - loss: 0.8981 - val_accuracy: 0.5942 - val_loss: 0.9477\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5509 - loss: 0.9087 - val_accuracy: 0.5942 - val_loss: 0.9454\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5557 - loss: 0.9367 - val_accuracy: 0.5906 - val_loss: 0.9448\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5549 - loss: 0.9339 - val_accuracy: 0.5906 - val_loss: 0.9380\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5534 - loss: 0.9335 - val_accuracy: 0.5906 - val_loss: 0.9413\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5426 - loss: 0.9441 - val_accuracy: 0.5906 - val_loss: 0.9416\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5657 - loss: 0.9158 - val_accuracy: 0.5906 - val_loss: 0.9464\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5467 - loss: 0.9327 - val_accuracy: 0.5906 - val_loss: 0.9496\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5376 - loss: 0.9382 - val_accuracy: 0.5906 - val_loss: 0.9489\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5610 - loss: 0.9166 - val_accuracy: 0.5906 - val_loss: 0.9521\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5372 - loss: 0.9347 - val_accuracy: 0.5906 - val_loss: 0.9561\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5681 - loss: 0.9348 - val_accuracy: 0.5906 - val_loss: 0.9558\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5613 - loss: 0.9135 - val_accuracy: 0.5906 - val_loss: 0.9576\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5641 - loss: 0.9097 - val_accuracy: 0.5906 - val_loss: 0.9613\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5580 - loss: 0.9341 - val_accuracy: 0.5906 - val_loss: 0.9608\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5465 - loss: 0.9259 - val_accuracy: 0.5906 - val_loss: 0.9654\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5510 - loss: 0.9419 - val_accuracy: 0.5870 - val_loss: 0.9879\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5604 - loss: 0.9147 - val_accuracy: 0.5870 - val_loss: 0.9659\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5513 - loss: 0.9149 - val_accuracy: 0.5833 - val_loss: 0.9802\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5583 - loss: 0.9093 - val_accuracy: 0.5870 - val_loss: 0.9677\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5554 - loss: 0.9116 - val_accuracy: 0.5870 - val_loss: 0.9670\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5599 - loss: 0.9119 - val_accuracy: 0.5942 - val_loss: 0.9639\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5454 - loss: 0.9305 - val_accuracy: 0.5906 - val_loss: 0.9725\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5466 - loss: 0.9124 - val_accuracy: 0.5870 - val_loss: 0.9861\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5446 - loss: 0.9170 - val_accuracy: 0.5906 - val_loss: 0.9755\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5491 - loss: 0.9121 - val_accuracy: 0.5906 - val_loss: 0.9753\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5460 - loss: 0.9219 - val_accuracy: 0.5906 - val_loss: 0.9798\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5811 - loss: 0.8989 - val_accuracy: 0.5906 - val_loss: 0.9816\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5569 - loss: 0.9218 - val_accuracy: 0.5761 - val_loss: 1.0624\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5764 - loss: 0.9326 - val_accuracy: 0.5833 - val_loss: 1.0028\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5310 - loss: 1.0003 - val_accuracy: 0.5761 - val_loss: 1.0299\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5571 - loss: 0.9474 - val_accuracy: 0.5833 - val_loss: 1.0095\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5391 - loss: 0.9611 - val_accuracy: 0.5906 - val_loss: 0.9883\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5415 - loss: 1.0645 - val_accuracy: 0.5688 - val_loss: 1.0923\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Training fold 5...\n",
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5361 - loss: 1.5788 - val_accuracy: 0.5435 - val_loss: 1.0629\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5630 - loss: 0.9943 - val_accuracy: 0.5688 - val_loss: 0.9523\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5606 - loss: 1.0769 - val_accuracy: 0.5543 - val_loss: 0.9465\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5653 - loss: 0.9479 - val_accuracy: 0.5507 - val_loss: 0.9788\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5647 - loss: 0.9576 - val_accuracy: 0.5616 - val_loss: 0.9509\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5797 - loss: 0.9122 - val_accuracy: 0.5688 - val_loss: 0.9339\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5629 - loss: 0.9491 - val_accuracy: 0.5688 - val_loss: 0.9345\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5427 - loss: 0.9660 - val_accuracy: 0.5688 - val_loss: 0.9374\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5760 - loss: 0.9223 - val_accuracy: 0.5688 - val_loss: 0.9372\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5542 - loss: 0.9534 - val_accuracy: 0.5688 - val_loss: 0.9371\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5413 - loss: 0.9660 - val_accuracy: 0.5688 - val_loss: 0.9360\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5379 - loss: 0.9880 - val_accuracy: 0.5688 - val_loss: 0.9403\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5613 - loss: 0.9302 - val_accuracy: 0.5652 - val_loss: 0.9578\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5669 - loss: 0.9522 - val_accuracy: 0.5652 - val_loss: 0.9587\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5576 - loss: 0.9421 - val_accuracy: 0.5688 - val_loss: 0.9448\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5433 - loss: 0.9806 - val_accuracy: 0.5290 - val_loss: 3.4727\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5763 - loss: 1.0555 - val_accuracy: 0.5435 - val_loss: 1.0141\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5610 - loss: 1.0294 - val_accuracy: 0.5580 - val_loss: 0.9398\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5609 - loss: 0.9484 - val_accuracy: 0.5543 - val_loss: 0.9393\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5602 - loss: 0.9359 - val_accuracy: 0.5688 - val_loss: 0.9379\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5707 - loss: 0.9385 - val_accuracy: 0.5688 - val_loss: 0.9412\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5565 - loss: 0.9474 - val_accuracy: 0.5688 - val_loss: 0.9440\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5598 - loss: 0.9522 - val_accuracy: 0.5688 - val_loss: 0.9487\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5751 - loss: 0.9427 - val_accuracy: 0.5688 - val_loss: 0.9484\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5361 - loss: 0.9758 - val_accuracy: 0.5688 - val_loss: 2.0811\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5323 - loss: 1.4686 - val_accuracy: 0.5688 - val_loss: 0.9564\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5701 - loss: 0.9383 - val_accuracy: 0.5725 - val_loss: 0.9184\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5605 - loss: 0.9602 - val_accuracy: 0.5688 - val_loss: 0.9190\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5480 - loss: 0.9715 - val_accuracy: 0.5652 - val_loss: 0.9758\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5469 - loss: 0.9951 - val_accuracy: 0.5688 - val_loss: 0.9218\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5887 - loss: 0.9275 - val_accuracy: 0.5688 - val_loss: 0.9259\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5618 - loss: 0.9624 - val_accuracy: 0.5688 - val_loss: 0.9251\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5659 - loss: 0.9419 - val_accuracy: 0.5688 - val_loss: 0.9282\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5610 - loss: 0.9266 - val_accuracy: 0.5688 - val_loss: 0.9287\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5391 - loss: 0.9679 - val_accuracy: 0.5688 - val_loss: 0.9303\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5627 - loss: 0.9378 - val_accuracy: 0.5688 - val_loss: 0.9324\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5482 - loss: 0.9509 - val_accuracy: 0.5688 - val_loss: 0.9331\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5482 - loss: 0.9473 - val_accuracy: 0.5688 - val_loss: 0.9354\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5631 - loss: 0.9582 - val_accuracy: 0.5688 - val_loss: 0.9376\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5737 - loss: 0.9252 - val_accuracy: 0.5725 - val_loss: 1.2436\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5534 - loss: 1.0675 - val_accuracy: 0.5616 - val_loss: 0.9996\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5866 - loss: 0.9247 - val_accuracy: 0.5725 - val_loss: 0.9179\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5826 - loss: 0.9300 - val_accuracy: 0.5688 - val_loss: 0.9250\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5551 - loss: 0.9845 - val_accuracy: 0.5725 - val_loss: 0.9270\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5946 - loss: 0.9179 - val_accuracy: 0.5725 - val_loss: 0.9289\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5319 - loss: 0.9617 - val_accuracy: 0.5725 - val_loss: 0.9280\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5719 - loss: 0.9233 - val_accuracy: 0.5725 - val_loss: 0.9301\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5750 - loss: 0.9352 - val_accuracy: 0.5725 - val_loss: 0.9354\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5727 - loss: 0.9391 - val_accuracy: 0.5725 - val_loss: 0.9367\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5711 - loss: 0.9204 - val_accuracy: 0.5725 - val_loss: 0.9382\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5935 - loss: 0.9056 - val_accuracy: 0.5725 - val_loss: 0.9389\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5462 - loss: 0.9612 - val_accuracy: 0.5725 - val_loss: 0.9401\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5641 - loss: 0.9322 - val_accuracy: 0.5725 - val_loss: 0.9432\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5529 - loss: 0.9385 - val_accuracy: 0.5725 - val_loss: 0.9430\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5731 - loss: 0.9241 - val_accuracy: 0.5725 - val_loss: 0.9467\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5671 - loss: 0.9466 - val_accuracy: 0.5725 - val_loss: 0.9466\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5659 - loss: 0.9297 - val_accuracy: 0.5725 - val_loss: 0.9510\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5867 - loss: 0.9332 - val_accuracy: 0.5725 - val_loss: 0.9485\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5624 - loss: 0.9456 - val_accuracy: 0.5725 - val_loss: 0.9513\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5518 - loss: 0.9455 - val_accuracy: 0.5725 - val_loss: 0.9528\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5676 - loss: 0.9542 - val_accuracy: 0.5725 - val_loss: 0.9545\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5832 - loss: 0.9252 - val_accuracy: 0.5725 - val_loss: 0.9547\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5729 - loss: 0.9363 - val_accuracy: 0.5725 - val_loss: 0.9562\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5578 - loss: 0.9749 - val_accuracy: 0.5725 - val_loss: 0.9591\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5687 - loss: 0.9253 - val_accuracy: 0.5725 - val_loss: 0.9600\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5445 - loss: 0.9479 - val_accuracy: 0.5725 - val_loss: 0.9636\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5663 - loss: 0.9203 - val_accuracy: 0.5725 - val_loss: 0.9634\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5650 - loss: 0.9408 - val_accuracy: 0.5725 - val_loss: 0.9651\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5776 - loss: 0.9057 - val_accuracy: 0.5725 - val_loss: 0.9667\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5741 - loss: 0.9315 - val_accuracy: 0.5725 - val_loss: 0.9670\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5570 - loss: 0.9461 - val_accuracy: 0.5725 - val_loss: 0.9675\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5206 - loss: 0.9725 - val_accuracy: 0.5725 - val_loss: 0.9689\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5695 - loss: 0.9296 - val_accuracy: 0.5725 - val_loss: 0.9707\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5461 - loss: 0.9629 - val_accuracy: 0.5725 - val_loss: 0.9713\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5665 - loss: 0.9623 - val_accuracy: 0.5725 - val_loss: 0.9722\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5846 - loss: 0.9389 - val_accuracy: 0.5725 - val_loss: 0.9731\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.5814 - loss: 0.9353 - val_accuracy: 0.5725 - val_loss: 0.9749\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5397 - loss: 0.9733 - val_accuracy: 0.5725 - val_loss: 0.9741\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5528 - loss: 0.9340 - val_accuracy: 0.5725 - val_loss: 0.9760\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.5780 - loss: 0.9109 - val_accuracy: 0.5725 - val_loss: 0.9758\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5811 - loss: 0.8938 - val_accuracy: 0.5725 - val_loss: 0.9781\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5523 - loss: 0.9307 - val_accuracy: 0.5761 - val_loss: 0.9775\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5687 - loss: 0.9285 - val_accuracy: 0.5725 - val_loss: 0.9743\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5386 - loss: 0.9765 - val_accuracy: 0.5616 - val_loss: 1.3408\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5554 - loss: 0.9790 - val_accuracy: 0.5616 - val_loss: 0.9313\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5479 - loss: 1.0074 - val_accuracy: 0.5362 - val_loss: 1.2530\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5342 - loss: 1.5164 - val_accuracy: 0.5435 - val_loss: 1.0314\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5478 - loss: 1.1464 - val_accuracy: 0.5435 - val_loss: 1.0129\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5425 - loss: 0.9833 - val_accuracy: 0.5399 - val_loss: 1.0277\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5572 - loss: 0.9774 - val_accuracy: 0.5362 - val_loss: 1.2411\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5570 - loss: 0.9794 - val_accuracy: 0.5362 - val_loss: 1.1529\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5393 - loss: 0.9435 - val_accuracy: 0.5290 - val_loss: 1.1840\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5523 - loss: 0.9483 - val_accuracy: 0.5362 - val_loss: 1.1536\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5690 - loss: 0.9082 - val_accuracy: 0.5362 - val_loss: 1.1470\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5521 - loss: 0.9254 - val_accuracy: 0.5399 - val_loss: 1.1394\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5428 - loss: 0.9438 - val_accuracy: 0.5399 - val_loss: 1.1356\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5510 - loss: 0.9461 - val_accuracy: 0.5399 - val_loss: 1.1387\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5778 - loss: 0.9173 - val_accuracy: 0.5399 - val_loss: 1.1256\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5538 - loss: 0.9560 - val_accuracy: 0.5399 - val_loss: 1.1238\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5387 - loss: 0.9705 - val_accuracy: 0.5399 - val_loss: 1.1198\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Average accuracy across 5 folds: 0.5333150211897661\n",
            "Average F1 score across 5 folds: 0.4657649369580743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming test data: eeg_signals_test, phys_signals_test, y_test are already defined\n",
        "\n",
        "# Predict on the test set using the student model\n",
        "y_pred = student_model.predict(X_test)\n",
        "\n",
        "# Convert softmax outputs to predicted class labels\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# If y_test is one-hot encoded, convert it back to labels\n",
        "y_test_labels = y_test\n",
        "\n",
        "# Calculate accuracy\n",
        "test_accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
        "\n",
        "# Calculate F1 score (for multi-class, set average='weighted' or 'macro')\n",
        "test_f1_score = f1_score(y_test_labels, y_pred_labels, average='weighted')\n",
        "\n",
        "# Generate classification report\n",
        "class_report = classification_report(y_test_labels, y_pred_labels)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "print(f\"Test F1 Score: {test_f1_score}\")\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "#student model with 8 and with KD\n",
        "# Test Accuracy: 0.546242774566474\n",
        "# Test F1 Score: 0.47680847595252146\n",
        "\n",
        "#student model with 8 and without KD\n",
        "# Test Accuracy: 0.5317919075144508\n",
        "# Test F1 Score: 0.45824573307358923\n",
        "\n",
        "#student model with 40 and with KD\n",
        "# Test Accuracy: 0.5549132947976878\n",
        "# Test F1 Score: 0.4861927442737668\n",
        "\n",
        "#student model with 40 and without KD\n",
        "# Test Accuracy: 0.5375722543352601\n",
        "# Test F1 Score: 0.4594546975232966"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1CnWMj6vumP",
        "outputId": "b34ff659-849d-4486-a8ee-f3a160f87cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Test Accuracy: 0.5375722543352601\n",
            "Test F1 Score: 0.4594546975232966\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.12      0.21        16\n",
            "         1.0       0.50      0.99      0.67       151\n",
            "         2.0       0.85      0.16      0.27       105\n",
            "         3.0       0.67      0.24      0.36        74\n",
            "\n",
            "    accuracy                           0.54       346\n",
            "   macro avg       0.67      0.38      0.38       346\n",
            "weighted avg       0.65      0.54      0.46       346\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "UtVV_LYfe8JI",
        "m3_7OJOeraAc",
        "Ojp4KR9wsYb3",
        "YGxIYv0PlQwD",
        "sA4B8MGOrEzW",
        "BKQl9qLEsyNg",
        "iEUShNeKvRvS",
        "5gq-Qkhk09po",
        "GiNHPug3LwIF",
        "qxW9cuUJFZin",
        "GqD-2HZt4MQm"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}